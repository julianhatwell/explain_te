{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up notebook and load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for notebook plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# load what we need\n",
    "import time\n",
    "import timeit\n",
    "import numpy as np\n",
    "import CHIRPS.structures as strcts\n",
    "import CHIRPS.routines as rt\n",
    "import CHIRPS.reproducible as rp\n",
    "import CHIRPS.boosting_scratch as bs\n",
    "from CHIRPS import p_count_corrected, if_nexists_make_dir, chisq_indep_test, entropy_corrected, contingency_test, confidence_weight\n",
    "from IPython.display import Image\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from pydotplus import graph_from_dot_data\n",
    "\n",
    "# demo datasets that ship with package. all from UCI unless stated otherwise\n",
    "# import CHIRPS.datasets as ds\n",
    "# ds.adult_data, ds.adult_samp_data, ds.adult_small_samp_data Large dataset ships with manageable sub samples\n",
    "# ds.bankmark_data, ds.bankmark_samp_data\n",
    "# ds.car_data\n",
    "# ds.cardio_data this is the cardiotocography dataset\n",
    "# ds.credit_data\n",
    "# ds.german_data\n",
    "# ds.lending_data, ds.lending_samp_data, ds.lending_small_samp_data, ds.lending_tiny_samp_data from Kaggle. see datasets_from_source file for links\n",
    "# ds.nursery_data, ds.nursery_samp_data\n",
    "# ds.rcdv_data, ds.rcdv_samp_data from US government see datasets_from_source file for links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common config - can be ommitted if defaults are OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'V:\\\\whiteboxing\\\\examples' # defaults to a directory \"whiteboxing\" in the working directory\n",
    "# project_dir = 'C:\\\\Users\\\\Crutt\\\\Documents\\\\whiteboxing\\\\examples'\n",
    "random_state_splits = 123 # one off for splitting the data into test / train\n",
    "random_state = 123 # for everything else - e.g. building a new rf with same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Random Forest Model to Predict and Explain\n",
    "First, a wrapper is created for the dataset. Use one that ships with the package, or create your own.\n",
    "Then split the data into training and (hold out) test set using the convenience functions in the package. These return an object that contain the split data in various representations, such as Pandas DataFrames and encoded, sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# load one of the included datasets\n",
    "# project_dir will default to directory name CHIRPS in the working directory if not given\n",
    "# random_state will default to 123\n",
    "mydata = rp.datasets[0](random_state=random_state, project_dir=project_dir)\n",
    "meta_data = mydata.get_meta()\n",
    "save_path = meta_data['get_save_path']()\n",
    "\n",
    "# split the data. here using a basic sampling method.\n",
    "# the returned object is a wrapper class that contains\n",
    "# the train and test splits for X and y\n",
    "\n",
    "# also the the encoded versions of X_train and X_test that the rf will use\n",
    "# this is because we prefer onehot encoded over allowing categorical vars to be represented as integer\n",
    "# scikit would treat these as ordinal, which is inappropriate\n",
    "\n",
    "# also some meta-data: priors for y, the indexes from the input data\n",
    "\n",
    "# also some convenience functions for leave-one-out testing\n",
    "\n",
    "# train test split - one off hard-coded random state.\n",
    "# random state can be ommitted \n",
    "# and will default to the state held in the dataset container\n",
    "# which defaults to 123 if ommitted in the constructor\n",
    "train_index, test_index = mydata.get_tt_split_idx(random_state=random_state_splits)\n",
    "# optionally, indexes can be ommitted and will default to scikit's train_test_split method\n",
    "tt = mydata.tt_split(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over-riding previous tuning parameters. New grid tuning... (please wait)\n",
      "\n",
      "Finding best params with 10-fold CV\n",
      "0.845 (+/-0.051) for {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 400, 'subsample': 1.0}\n",
      "CV time: 4.291448663000001\n",
      "\n",
      "Tuning time elapsed: 4.2929seconds\n",
      "Best OOB Accuracy Estimate during tuning: 0.8449\n",
      "Best parameters:{'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 400, 'subsample': 1.0, 'random_state': 123}\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[538  26]\n",
      " [ 79  90]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.95 0.05]\n",
      " [0.47 0.53]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build model\n",
    "model='GBM'\n",
    "# tuning_grid = {'max_depth' : [d for d in [i for i in range(1, 5)]],\n",
    "#               'n_estimators' : [(i + 1) * 200 for i in range(2)],\n",
    "#               'learning_rate' : [i/10 for i in range(1, 11)],\n",
    "#               'subsample' : [0.25, 0.5, 0.75, 1.0]}\n",
    "\n",
    "tuning_grid = {'max_depth' : [d for d in [i for i in range(1, 2)]],\n",
    "                'n_estimators' : [(i + 1) * 200 for i in range(1, 2)],\n",
    "                'learning_rate' : [i/10 for i in range(1, 2)],\n",
    "                'subsample' : [1.0]}\n",
    "\n",
    "\n",
    "rf = rp.forest_prep(ds_container=tt,\n",
    "                    meta_data=meta_data,\n",
    "                    override_tuning=True,\n",
    "                    model=model,\n",
    "                    tuning_grid=tuning_grid,\n",
    "                    save_path=save_path,\n",
    "                    plot_cm=True, plot_cm_norm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control for async processes - each tree walk can be done in its own core\n",
    "# and so can each explanation (e.g. rule conditions merge by hill-climbing)\n",
    "# these will default to false if not passed explicitly to the explainer function\n",
    "# on a multi-core machine there should be a good speed up for large batches\n",
    "# when the batch_size advantage exceeds the overhead of setting up multi-processing\n",
    "# timings will be printed to screen so you can see if it helps\n",
    "forest_walk_async=False\n",
    "chirps_explanation_async=False\n",
    "\n",
    "# how many instances to explain in total from a test/unseen set\n",
    "n_instances = 1\n",
    "\n",
    "# this will normalise the above parameters to the size of the dataset\n",
    "n_instances = rt.n_instance_ceiling(ds_container=tt, n_instances=n_instances)\n",
    "\n",
    "# this gets the next batch out of the data_split_container according to the required number of instances\n",
    "# all formats can be extracted, depending on the requirement\n",
    "# unencoded, encoded (sparse matrix is the type returned by scikit), ordinary dense matrix also available\n",
    "instances, _, instances_enc, instances_enc_matrix, labels = tt.get_next(n_instances, which_split='test') # default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walking forest for 1 instances... (please wait)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-202e86699e24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m bp_container = f_walker.forest_walk(instances = instances_enc_matrix\n\u001b[0;32m     15\u001b[0m                         \u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;31m# we're explaining the prediction, not the true label!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                         , forest_walk_async = forest_walk_async)\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# stop the timer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py\u001b[0m in \u001b[0;36mforest_walk\u001b[1;34m(self, instances, labels, forest_walk_async)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[0mtree_pred_proba\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[0mtree_agree_maj_vote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m                 \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_structures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_instances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m                 \u001b[1;31m# walk the tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m                 _, tree_paths[i] = as_tree_walk(i, instances, labels, n_instances,\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py\u001b[0m in \u001b[0;36mtree_structures\u001b[1;34m(self, tree, instances, labels, n_instances)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[1;31m# structural objects from tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m         \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m         \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "# get all the model predictions for the test instance(s) we're looking at\n",
    "preds_idx = labels.index\n",
    "preds = rf.predict(X=instances_enc)\n",
    "\n",
    "f_walker = strcts.forest_walker(forest = rf, meta_data=meta_data)\n",
    "\n",
    "print('Walking forest for ' + str(len(labels)) + ' instances... (please wait)')\n",
    "\n",
    "# set the timer\n",
    "forest_walk_start_time = timeit.default_timer()\n",
    "\n",
    "# do the walk - returns a batch_paths_container (even for just one instance)\n",
    "# requires the X instances in a matrix (dense, ordinary numpy matrix) - this is available in the data_split_container\n",
    "bp_container = f_walker.forest_walk(instances = instances_enc_matrix\n",
    "                        , labels = preds # we're explaining the prediction, not the true label!\n",
    "                        , forest_walk_async = forest_walk_async)\n",
    "\n",
    "# stop the timer\n",
    "forest_walk_end_time = timeit.default_timer()\n",
    "forest_walk_elapsed_time = forest_walk_end_time - forest_walk_start_time\n",
    "\n",
    "print('Forest Walk with async = ' + str(forest_walk_async))\n",
    "print('Forest Walk time elapsed:', \"{:0.4f}\".format(forest_walk_elapsed_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'feature_depth': array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ...,  0., nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ...,  0., nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]]),\n",
       "  'tree_predictions': array([[ 1.08157953,  0.9195611 , -0.17664384,  0.78124787, -0.47483891,\n",
       "          -0.15465416,  0.66654263, -0.43602485, -0.14481987,  0.57922515,\n",
       "          -0.48616224,  0.47158459, -0.37137247,  0.49063605, -0.12452422,\n",
       "           0.71961405,  0.39664981, -0.41226441, -0.11433213,  0.42002546,\n",
       "          -0.09643029,  0.60101254,  0.36075543, -0.3681778 , -0.10091297,\n",
       "           0.36470758, -0.27739431, -0.08893742,  0.33002863,  0.50220282,\n",
       "           0.30594615, -0.07878275, -0.07972909, -0.3079459 ,  0.29118307,\n",
       "           0.24510782,  0.42999938, -0.0684235 , -0.07467664,  0.25536301,\n",
       "          -0.27947845, -0.05642783,  0.14977448,  0.21185908, -0.06600412,\n",
       "          -0.22459998,  0.2271267 , -0.05084351,  0.35140262, -0.05748285,\n",
       "          -0.06107078,  0.13167993,  0.20794973,  0.23233889, -0.10035327,\n",
       "           0.20192201,  0.09673541, -0.05727513, -0.04535218, -0.05049883,\n",
       "           0.1179004 ,  0.13010795, -0.05022824,  0.1788188 ,  0.1991147 ,\n",
       "          -0.04082248, -0.08786287, -0.03077886,  0.08435914,  0.16855932,\n",
       "           0.10444094, -0.04691136,  0.16317337, -0.04258839,  0.25091598,\n",
       "          -0.03660258,  0.07623162, -0.43509632,  0.13636691, -0.04461465,\n",
       "          -0.07658784,  0.0775588 ,  0.09049537,  0.16025626,  0.14139802,\n",
       "          -0.02580052, -0.03984588, -0.03302211,  0.09738182,  0.06767844,\n",
       "          -0.07714742, -0.39419626, -0.06839341,  0.06976037, -0.04419695,\n",
       "           0.08013389, -0.03441816, -0.0299753 ,  0.12382972,  0.12218701,\n",
       "          -0.03518503, -0.0714568 ,  0.06082754, -0.06181535,  0.06334969,\n",
       "           0.07333305,  0.20961556, -0.02761605,  0.38255388, -0.06704855,\n",
       "           0.11294591, -0.03259782, -0.02027928,  0.07838263,  0.12457588,\n",
       "          -0.34506222,  0.00793231, -0.05668896, -0.0040214 ,  0.02380204,\n",
       "           0.0104983 ,  0.0531883 , -0.03147135,  0.3527532 ,  0.05670309,\n",
       "          -0.0246655 ,  0.18659465,  0.06604484, -0.06109031,  0.04348882,\n",
       "           0.10019156, -0.3411235 , -0.01811514, -0.00368818, -0.02859616,\n",
       "          -0.05147526,  0.32765637,  0.01085665, -0.00349357,  0.15220903,\n",
       "          -0.3308709 , -0.05692266,  0.06812941,  0.00963094,  0.00708892,\n",
       "          -0.30911883,  0.04847242, -0.0225055 ,  0.02099963, -0.00482553,\n",
       "           0.16678808, -0.03173268,  0.05800864,  0.04947322, -0.00357125,\n",
       "          -0.30824009,  0.29989518, -0.09675732,  0.09071144, -0.02438527,\n",
       "           0.00277802, -0.04713022, -0.00554801, -0.02580685,  0.01007666,\n",
       "           0.040053  , -0.00317392,  0.02038394,  0.03726274,  0.00875183,\n",
       "          -0.02054025,  0.04334985,  0.15643762, -0.29325048,  0.1357467 ,\n",
       "           0.39888833, -0.28418863, -0.05075174,  0.00625922,  0.38533578,\n",
       "          -0.00308975,  0.05420774,  0.02172437,  0.27363619, -0.28452853,\n",
       "          -0.01523661,  0.0588449 ,  0.00263332, -0.02379256,  0.01859618,\n",
       "          -0.00410112,  0.00914616, -0.00576907,  0.07953923,  0.09328066,\n",
       "           0.00462104, -0.00494162, -0.01456683,  0.14112441, -0.02220612,\n",
       "           0.00807035, -0.00284552, -0.26598653,  0.37043521,  0.07119829,\n",
       "          -0.04706178, -0.04212363, -0.02281077,  0.01881035,  0.00263892,\n",
       "           0.04270935,  0.25534592, -0.00278507, -0.26580933,  0.02880808,\n",
       "           0.12112137, -0.04545219,  0.86280647, -0.26209615,  0.03842723,\n",
       "           0.0346375 ,  0.34684961, -0.26100009,  0.04768832,  0.35138839,\n",
       "           0.13447073,  0.00832881, -0.01362483,  0.00244936, -0.01363849,\n",
       "          -0.02211563, -0.02080815,  0.01947879, -0.00269901,  0.052157  ,\n",
       "          -0.25068377, -0.00370459,  0.01715157,  0.03133593,  0.06577773,\n",
       "          -0.00523075, -0.00446765,  0.81166506,  0.00242915,  0.01641162,\n",
       "          -0.24522821,  0.33712648, -0.0180118 ,  0.00402266,  0.02313922,\n",
       "          -0.03770216,  0.22980125,  0.00713368, -0.0421828 , -0.24051863,\n",
       "          -0.02048079, -0.00251071,  0.03201313,  0.03541641, -0.01289025,\n",
       "           0.00523242,  0.02580669,  0.12347632,  0.00225018,  0.78020251,\n",
       "          -0.02503393,  0.31009363, -0.00249968,  0.07843087, -0.24120183,\n",
       "           0.00775796, -0.0042079 ,  0.30328645, -0.01616785,  0.03682272,\n",
       "           0.01042887, -0.01181462, -0.01705831,  0.03044493, -0.22879015,\n",
       "           0.10549277,  0.06074739, -0.03004817, -0.01992871,  0.04716261,\n",
       "           0.02272432, -0.01796363,  0.00217866, -0.00334536, -0.0157192 ,\n",
       "          -0.03483277,  0.21274291, -0.22490019,  0.74962203,  0.0643837 ,\n",
       "          -0.03977958,  0.00676292, -0.00401625,  0.0414748 ,  0.00378436,\n",
       "           0.28971915, -0.01187151, -0.00458245,  0.11521422,  0.00217161,\n",
       "          -0.00231284, -0.02350179,  0.05800891, -0.02849477,  0.0732005 ,\n",
       "           0.01696851,  0.01442166, -0.22557813,  0.28578696, -0.02202157,\n",
       "           0.00723498, -0.01606415,  0.02909222, -0.21551486,  0.70826179,\n",
       "           0.00204137,  0.03185435,  0.02328386,  0.02057554, -0.01101821,\n",
       "           0.05629156, -0.01813042, -0.00228768, -0.03308577, -0.03788823,\n",
       "           0.20296085, -0.21043716, -0.02252321, -0.0112545 ,  0.00209639,\n",
       "          -0.01459239,  0.01009223, -0.00217393,  0.03326665, -0.01115402,\n",
       "           0.27069984, -0.21902758,  0.01072197,  0.10750578, -0.00306563,\n",
       "           0.02091864, -0.01529066, -0.02632118,  0.05431224, -0.01428855,\n",
       "           0.00961629,  0.26411194,  0.0420434 , -0.03579657, -0.03217171,\n",
       "           0.19216067,  0.00611323,  0.02721408, -0.01771437, -0.00365801,\n",
       "           0.00676548,  0.00347918,  0.00198486,  0.66172367, -0.20605804,\n",
       "           0.0989016 , -0.00413297,  0.00449994, -0.00356295, -0.0164657 ,\n",
       "           0.0092792 ,  0.02507714,  0.01970522,  0.01402917,  0.00190118,\n",
       "           0.01318695, -0.02087459, -0.01013533, -0.0251594 ,  0.1017243 ,\n",
       "           0.00786076, -0.01183414, -0.0021294 ,  0.00475431,  0.66172988,\n",
       "          -0.19660733,  0.01005503,  0.02890508,  0.0558398 , -0.01479132,\n",
       "           0.00577768,  0.0515424 ,  0.0210768 , -0.03413953, -0.01301741,\n",
       "           0.00888116, -0.00206095, -0.01631911, -0.00280596,  0.02570453]]),\n",
       "  'tree_pred_labels': array([[1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "          0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "          1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "          1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "          0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "          0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "          0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "          0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "          1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "          1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "          0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "          1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "          1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "          1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "          0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "          1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "          1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "          0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "          1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.]]),\n",
       "  'tree_performance': array([[1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "          0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "          1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "          1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "          0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "          0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "          0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "          0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "          1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "          1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "          0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "          1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "          1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "          1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "          0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "          1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "          1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "          0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "          1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.]]),\n",
       "  'path_lengths': array([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "          2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]])}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_walker.full_survey(instances_enc, labels)\n",
    "f_walker.tree_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.loss_._score_to_proba(rf.decision_function(instances_enc))\n",
    "#dir(rf.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(rf.decision_function(instances_enc).ravel())/(1 + np.exp(rf.decision_function(instances_enc).ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf._init_decision_function(instances_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.decision_function(instances_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get what the model predicts on the training sample\n",
    "sample_labels = rf.predict(tt.X_train_enc)\n",
    "\n",
    "# build CHIRPS and a rule for each instance represented in the batch paths container\n",
    "CHIRPS = strcts.batch_CHIRPS_explainer(bp_container,\n",
    "                                forest=rf,\n",
    "                                sample_instances=tt.X_train_enc, # any representative sample can be used\n",
    "                                # sample_labels=tt.y_train,  # any representative sample can be used\n",
    "                                sample_labels=sample_labels,\n",
    "                                meta_data=meta_data)\n",
    "\n",
    "print('Running CHIRPS on a batch of ' + str(len(labels)) + ' instances... (please wait)')\n",
    "# start a timer\n",
    "ce_start_time = timeit.default_timer()\n",
    "\n",
    "CHIRPS.batch_run_CHIRPS(chirps_explanation_async=chirps_explanation_async,\n",
    "                        paths_lengths_threshold=5,\n",
    "                        alpha_paths=0.0,\n",
    "                        support_paths=0.01,\n",
    "                        score_func=1,\n",
    "                        disc_path_bins=4,\n",
    "                        target_classes=preds,\n",
    "                        merging_bootstraps=20,\n",
    "                        pruning_bootstraps=20,\n",
    "                        delta=0.1,\n",
    "                        weighting='chisq')\n",
    "\n",
    "ce_end_time = timeit.default_timer()\n",
    "ce_elapsed_time = ce_end_time - ce_start_time\n",
    "print('CHIRPS time elapsed:', \"{:0.4f}\".format(ce_elapsed_time), 'seconds')\n",
    "print('CHIRPS with async = ' + str(chirps_explanation_async))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# iterate over all the test instances to determine the various scores using leave-one-out testing\n",
    "print('evaluating found explanations')\n",
    "print()\n",
    "results_start_time = timeit.default_timer()\n",
    "\n",
    "rt.evaluate_CHIRPS_explainers(CHIRPS, tt, labels.index, # for batch runs: tt.y_test.index,\n",
    "                              forest=rf,\n",
    "                              meta_data=meta_data,\n",
    "                              model=model,\n",
    "                              eval_start_time=results_start_time,\n",
    "                              print_to_screen=True, # set True when running single instances\n",
    "                              eval_alt_labelings=True,\n",
    "                              eval_rule_complements=True,\n",
    "                              save_results_path=save_path,\n",
    "                              dataset_name='test',\n",
    "                              save_results_file='CHIRPS' + '_rnst_' + str(random_state),\n",
    "                              save_CHIRPS=False)\n",
    "\n",
    "results_end_time = timeit.default_timer()\n",
    "results_elapsed_time = results_end_time - results_start_time\n",
    "print('CHIRPS batch results eval time elapsed:', \"{:0.4f}\".format(results_elapsed_time), 'seconds')\n",
    "# this completes the CHIRPS runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#c = bp_container.get_CHIRPS_runner(0, meta_data)\n",
    "#c.repeat_weighted_paths()\n",
    "#CHIRPS.CHIRPS_explainers[0].paths\n",
    "#np.round(CHIRPS.CHIRPS_explainers[0].paths_weights * 1/min(CHIRPS.CHIRPS_explainers[0].paths_weights))\n",
    "#CHIRPS.CHIRPS_explainers[0].paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_count_corrected([0, 1, 2, 3], [0, 1,2,3], [ 3.46192192, 78.32036219, 58.81097884, 62.69848053])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([3.35743396e-06, 4.16315283e-01, 2.07411357e-01, 3.76270003e-01])\n",
    "y = np.where(x != x[np.argmax(x)])\n",
    "x[y][np.argmax(x[y])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=np.array([[-77.14896904 , 30.46996862 , 23.13920312 , 23.5397973 ],\n",
    " [-78.17874831 , 27.48592897 , 23.07330235 , 27.61951699],\n",
    " [-52.94961755 , 53.9136018 ,  51.9856333 , -52.94961755]])\n",
    "\n",
    "arr=[1,3,1]\n",
    "print(np.shape(weights)[0])\n",
    "print(weights[range(np.shape(weights)[0]),arr])\n",
    "print(np.array(weights[range(np.shape(weights)[0]), arr]))\n",
    "\n",
    "p_count_corrected(arr, [0,1,2,3], weights=weights)['counts']\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confidence_weight(np.array([[0.1, 0.1, 0.2, 0.6], [0.05, 0.05, 0.2, 0.7], [0.1, 0.5, 0.2, 0.2], [0.1, 0.2, 0.3, 0.4]]))\n",
    "#print(cf)\n",
    "p_count_corrected([3,3,1,3], [0, 1, 2, 3], weights=cf)\n",
    "# cf[range(4), [0,1,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tt.X_test_enc[0:3,]\n",
    "pred_raw = [confidence_weight(estimator.predict_proba(X), 'proba') for estimator in rf.estimators_]\n",
    "print(np.mean(pred_raw, axis = 0))\n",
    "pred_log = [confidence_weight(estimator.predict_proba(X), 'log_proba') for estimator in rf.estimators_]\n",
    "print(np.mean(pred_log, axis = 0))\n",
    "pred = [confidence_weight(estimator.predict_proba(X), 'conf_weight') for estimator in rf.estimators_]\n",
    "print(np.mean(pred, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = [confidence_weight(estimator.predict_proba(X), 'conf_weight') for estimator in rf.estimators_]\n",
    "pred = sum(pred)\n",
    "pred /= rf.estimator_weights_.sum()\n",
    "print(pred)\n",
    "pred = pred / (len(pred[0]) - 1)\n",
    "pred = np.exp(pred)\n",
    "print(pred)\n",
    "normalizer = pred.sum(axis=1)[:, np.newaxis]\n",
    "normalizer[normalizer == 0.0] = 1.0\n",
    "print(normalizer)\n",
    "pred /= normalizer\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = [confidence_weight(estimator.predict_proba(X), 'log_proba') for estimator in rf.estimators_]\n",
    "pred = np.mean(pred, axis=0)\n",
    "#pred /= rf.estimator_weights_.sum()\n",
    "print(pred)\n",
    "pred = np.exp(pred)\n",
    "print(pred)\n",
    "normalizer = pred.sum(axis=1)[:, np.newaxis]\n",
    "normalizer[normalizer == 0.0] = 1.0\n",
    "print(normalizer)\n",
    "pred /= normalizer\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict_proba(X)\n",
    "#np.exp(rf.decision_function(X))\n",
    "# pred = rf.decision_function(X) + abs(rf.decision_function(X).min(axis=1).reshape(-1, 1))\n",
    "# normalizer = pred.sum(axis=1)[:, np.newaxis]\n",
    "# pred /= normalizer\n",
    "# pred\n",
    "#np.array(rf.decision_function(X)) * rf.estimator_weights_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([-24.05452802,  -1.01532182, -12.34344625, -12.62110368])\n",
    "x = np.array([-34.63778423,  34.47983437,   0.49546108,  -0.33751122]) / len(y)\n",
    "z = np.array([0.01626313, 0.49611181, 0.22083229, 0.26679277])\n",
    "x\n",
    "(y - np.mean(y)) * 3\n",
    "#np.exp(y) / np.sum(np.exp(y))\n",
    "# np.exp(x + np.mean(y)) / np.sum(np.exp(x + np.mean(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bp_container.path_detail[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "tree_preds, estimator_weights = [i for i in map(list, zip(*[itemgetter('pred_class', 'estimator_weight')(bp_container.path_detail[t][0]) for t in range(1)]))]\n",
    "\n",
    "p_count_corrected(tree_preds, [i for i in range(len(meta_data['class_names']))], weights=estimator_weights)\n",
    "\n",
    "tree_preds, confidence_weights = [i for i in map(list, zip(*[itemgetter('pred_class', 'confidence_weight')(bp_container.path_detail[t][0]) for t in range(1)]))]\n",
    "\n",
    "confidence_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(pred_log).sum(axis=1)[:, np.newaxis])\n",
    "print(sum(pred_log).sum(axis=1)[:, np.newaxis]/n_classes)\n",
    "print(sum(pred_log) - sum(pred_log).sum(axis=1)[:, np.newaxis]/n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_count_corrected(rf.predict(X), [i for i in range(n_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([estimator.predict(X) for estimator in rf.estimators_])\n",
    "preds = preds.reshape(1, -1)[0]\n",
    "wts = [2 if p == 1 else 1 for p in preds]\n",
    "p_count_corrected(preds, [i for i in range(n_classes)], wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(rf.estimators_[0]._abc_impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.predict_proba(tt.X_test_enc[0]))\n",
    "\n",
    "proba = rf.predict_proba(tt.X_test_enc[0])\n",
    "proba[proba < np.finfo(proba.dtype).eps] = np.finfo(proba.dtype).eps\n",
    "log_proba = np.log(proba)\n",
    "# print(log_proba)\n",
    "# print(log_proba.sum(axis=1)[:, np.newaxis])\n",
    "# print( (log_proba - (1. / n_classes)\n",
    "#                               * log_proba.sum(axis=1)[:, np.newaxis]))\n",
    "pred = (n_classes - 1) * (log_proba - (1. / n_classes)\n",
    "                              * log_proba.sum(axis=1)[:, np.newaxis]) \n",
    "print(pred)\n",
    "pred /= rf.estimator_weights_.sum()\n",
    "if n_classes == 2:\n",
    "    pred[:, 0] *= -1\n",
    "    print(pred.sum(axis=1))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (n_classes - 1) * (log_proba - (1. / n_classes)\n",
    "#                               * log_proba.sum(axis=1)[:, np.newaxis])\n",
    "\n",
    "3 * (log_proba - (1/4) * log_proba.sum(axis=1)[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sum(_samme_proba(estimator, n_classes, X)\n",
    "                       for estimator in rf.estimators_)\n",
    "print(pred)\n",
    "print(rf.estimator_weights_.sum())\n",
    "pred /= rf.estimator_weights_.sum()\n",
    "print(pred)\n",
    "\n",
    "pred = np.exp((1. / (n_classes - 1)) * pred)\n",
    "print(pred)\n",
    "normalizer = pred.sum(axis=1)[:, np.newaxis]\n",
    "normalizer[normalizer == 0.0] = 1.0\n",
    "pred /= normalizer\n",
    "print(normalizer)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(_samme_proba(estimator, n_classes, X)\n",
    "                       for estimator in self.estimators_)\n",
    "\n",
    "r_pred = [(estimator.predict(instances_enc) == rf.classes_) for estimator in rf.estimators_]\n",
    "# print(r_pred)\n",
    "rw_pred = [(estimator.predict(instances_enc) == rf.classes_).T * w for estimator, w in zip(rf.estimators_, rf.estimator_weights_)]\n",
    "# print(rw_pred)\n",
    "pred = sum((estimator.predict(instances_enc) == rf.classes_).T * w\n",
    "           for estimator, w in zip(rf.estimators_,\n",
    "                                   rf.estimator_weights_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = rf.n_classes_\n",
    "print(n_classes)\n",
    "proba = sum(estimator.predict_proba(instances_enc) * w\n",
    "                        for estimator, w in zip(rf.estimators_,\n",
    "                                                rf.estimator_weights_))\n",
    "\n",
    "print(proba)\n",
    "proba /= rf.estimator_weights_.sum()\n",
    "print(proba)\n",
    "proba = np.exp((1. / (n_classes - 1)) * proba)\n",
    "print(proba)\n",
    "normalizer = proba.sum(axis=1)[:, np.newaxis]\n",
    "normalizer[normalizer == 0.0] = 1.0\n",
    "print(normalizer)\n",
    "proba /= normalizer\n",
    "print(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if algorithm == 'SAMME.R':\n",
    "n_classes = 4\n",
    "X = tt.X_train_enc[0]\n",
    "pred = sum(_samme_proba(estimator, n_classes, X)\n",
    "                   for estimator in rf.estimators_)\n",
    "#             else:   # self.algorithm == \"SAMME\"\n",
    "#             pred = sum((estimator.predict(X) == classes).T * w\n",
    "#                        for estimator, w in zip(self.estimators_,\n",
    "#                                                self.estimator_weights_))\n",
    "\n",
    "pred /= rf.estimator_weights_.sum()\n",
    "if n_classes == 2:\n",
    "    pred[:, 0] *= -1\n",
    "\n",
    "# pred.sum(axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how is GB working to calculate the predict function\n",
    "import numpy as np\n",
    "n = 300\n",
    "gbpreds = [gb.predict(X_test[i])[0] for i in range(n)]\n",
    "reg_tots = np.empty(n)\n",
    "for i in range(n):\n",
    "    reg_tots[i] = sum([gb.estimators_[j][0].predict(X_test[i])[0] for j in range(ne)])\n",
    "\n",
    "mn = np.inf\n",
    "mx = -np.inf\n",
    "for pred, tot in zip(gbpreds, reg_tots):\n",
    "    if pred == 0:\n",
    "        if mx < tot:\n",
    "            mx = tot\n",
    "    if pred == 1:\n",
    "        if mn > tot:\n",
    "            mn = tot\n",
    "            \n",
    "print(mx, mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing unseen data\n",
    "\n",
    "Again note:\n",
    "test set has never been \"seen\" by random forest during training\n",
    "test set has been only used to assess model (random forest) accuracy - no additional tuning after this\n",
    "test set has not be involved in generating the explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optional: memory and computation cost management\n",
    "#### CHIRPS is time economical but memory intensive to compute for lots of instances at once\n",
    "option 1: choose a smaller number of instances to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control for async processes - each tree walk can be done in its own core\n",
    "# and so can each explanation (e.g. rule conditions merge by hill-climbing)\n",
    "# these will default to false if not passed explicitly to the explainer function\n",
    "# on a multi-core machine there should be a good speed up for large batches\n",
    "# when the batch_size advantage exceeds the overhead of setting up multi-processing\n",
    "# timings will be printed to screen so you can see if it helps\n",
    "forest_walk_async=False\n",
    "chirps_explanation_async=False\n",
    "\n",
    "# the number of instances can be controlled by\n",
    "# batch_size - how many instances to explain at one time\n",
    "batch_size = 1\n",
    "# how many instances to explain in total from a test/unseen set\n",
    "n_instances = 1\n",
    "\n",
    "# this will normalise the above parameters to the size of the dataset\n",
    "n_instances, n_batches = rt.batch_instance_ceiling(ds_container=tt, n_instances=n_instances, batch_size=batch_size)\n",
    "\n",
    "# this gets the next batch out of the data_split_container according to the required number of instances\n",
    "# all formats can be extracted, depending on the requirement\n",
    "# unencoded, encoded (sparse matrix is the type returned by scikit), ordinary dense matrix also available\n",
    "instances, _, instances_enc, instances_enc_matrix, labels = tt.get_next(batch_size, which_split='test') # default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 2: just run the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances = tt.X_test; instances_enc = tt.X_test_enc; instances_enc_matrix = tt.X_test_enc_matrix; labels = tt.y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions from the decision forest on the unseen data\n",
    "Important point, no compromise on model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the model predictions for the test instance(s) we're looking at\n",
    "preds_idx = labels.index\n",
    "preds = rf.predict(X=instances_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIRPS Step 1:\n",
    "## Extract Tree Prediction Paths\n",
    "### Fit a forest_walker object to the dataset and decision forest\n",
    "This is a wrapper will extracts the paths of all the given instances. For CHIRPS, we want a large sample. The whole training set or other representative sample will do.\n",
    "\n",
    "It can also report interesting statistics (treating the forest as a set of random tree-structured variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper object needs the decision forest itself and the dataset meta data (we have a convenience function for this)\n",
    "f_walker = strcts.forest_walker(forest = rf, meta_data=meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the work of extracting all the paths for each instance is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Walking forest for ' + str(len(labels)) + ' instances... (please wait)')\n",
    "\n",
    "# set the timer\n",
    "forest_walk_start_time = timeit.default_timer()\n",
    "\n",
    "# do the walk - returns a batch_paths_container (even for just one instance)\n",
    "# requires the X instances in a matrix (dense, ordinary numpy matrix) - this is available in the data_split_container\n",
    "bp_container = f_walker.forest_walk(instances = instances_enc_matrix\n",
    "                        , labels = preds # we're explaining the prediction, not the true label!\n",
    "                        , forest_walk_async = forest_walk_async)\n",
    "\n",
    "# stop the timer\n",
    "forest_walk_end_time = timeit.default_timer()\n",
    "forest_walk_elapsed_time = forest_walk_end_time - forest_walk_start_time\n",
    "\n",
    "print('Forest Walk with async = ' + str(forest_walk_async))\n",
    "print('Forest Walk time elapsed:', \"{:0.4f}\".format(forest_walk_elapsed_time), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIRPS Steps 2-4: \n",
    "## Freqent pattern mining of paths.\n",
    "## Score and sort mined path segments.\n",
    "## Merge path segments into one rule.\n",
    "\n",
    "This is a wrapper object that will execute steps 2-4 on all the instance-paths in the batch_paths_container.\n",
    "\n",
    "Note that true_divide warnings are OK. It just means that a continuous variable is unbounded in some way i.e. no greater/less than discontinuity is used in the CHIRPS explanation.\n",
    "\n",
    "Note also, here we are using the training set to create the explainers. We could use a different dataset as long as it is representative of the training set that built the decision forest. Most important that we don't use the dataset that we wish to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get what the model predicts on the training sample\n",
    "sample_labels = rf.predict(tt.X_train_enc)\n",
    "\n",
    "# build CHIRPS and a rule for each instance represented in the batch paths container\n",
    "CHIRPS = strcts.batch_CHIRPS_explainer(bp_container,\n",
    "                                forest=rf,\n",
    "                                sample_instances=tt.X_train_enc, # any representative sample can be used\n",
    "                                # sample_labels=tt.y_train,  # any representative sample can be used\n",
    "                                sample_labels=sample_labels,\n",
    "                                meta_data=meta_data)\n",
    "\n",
    "print('Running CHIRPS on a batch of ' + str(len(labels)) + ' instances... (please wait)')\n",
    "# start a timer\n",
    "ce_start_time = timeit.default_timer()\n",
    "\n",
    "CHIRPS.batch_run_CHIRPS(chirps_explanation_async=chirps_explanation_async,\n",
    "                        alpha_paths=0.9,\n",
    "                        support_paths=0.1,\n",
    "                        score_func=5,\n",
    "                        disc_path_bins=4,\n",
    "                        target_classes=preds,\n",
    "                        merging_bootstraps=20,\n",
    "                        pruning_bootstraps=20,\n",
    "                        delta=0.1,\n",
    "                        weighting='chisq')\n",
    "\n",
    "ce_end_time = timeit.default_timer()\n",
    "ce_elapsed_time = ce_end_time - ce_start_time\n",
    "print('CHIRPS time elapsed:', \"{:0.4f}\".format(ce_elapsed_time), 'seconds')\n",
    "print('CHIRPS with async = ' + str(chirps_explanation_async))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing and Evaluating CHIRPS explanations\n",
    "Evaluation is done using unseen data to see how well the explanations generalise. The data_split_container object (tt) has a  leave-one-out function that is used during the routine to ensure that the datum we are explaining is excluded from the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# iterate over all the test instances to determine the various scores using leave-one-out testing\n",
    "print('evaluating found explanations')\n",
    "print()\n",
    "results_start_time = timeit.default_timer()\n",
    "\n",
    "rt.evaluate_CHIRPS_explainers(CHIRPS, tt, tt.y_test.index,\n",
    "                              forest=rf,\n",
    "                              meta_data=meta_data,\n",
    "                              eval_start_time=results_start_time,\n",
    "                              print_to_screen=True, # set True when running single instances\n",
    "                              eval_alt_labelings=True,\n",
    "                              eval_rule_complements=True,\n",
    "                              save_results_path=save_path,\n",
    "                              dataset_name='test',\n",
    "                              save_results_file='CHIRPS' + '_rnst_' + str(random_state),\n",
    "                              save_CHIRPS=False)\n",
    "\n",
    "results_end_time = timeit.default_timer()\n",
    "results_elapsed_time = results_end_time - results_start_time\n",
    "print('CHIRPS batch results eval time elapsed:', \"{:0.4f}\".format(results_elapsed_time), 'seconds')\n",
    "# this completes the CHIRPS runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "forest = rf\n",
    "train_pred_labels = Series(forest.predict(tt.X_train_enc), index = tt.y_train.index)\n",
    "CHIRPS.CHIRPS_explainers[0].evaluate_rule(rule='pruned', sample_instances=tt.X_train_enc, sample_labels=train_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHIRPS.CHIRPS_explainers[0].posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict_proba(X=instances_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(preds) - 0.5 * np.log(preds).sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sum(_samme_proba(estimator, n_classes, X)\n",
    "                       for estimator in self.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sum(_samme_proba(estimator, 2, instances_enc)\n",
    "                       for estimator in rf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(_samme_proba(rf.estimators_[0], 2, instances_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.estimators_[0].predict(instances_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "[math.exp(ew)/(1+math.exp(ew)) - 0.5 for ew in rf.estimator_weights_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.estimator_errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.decision_function(instances_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(instances_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict_proba(instances_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "le_dict = LabelEncoder().fit(mydata.data['workclass'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [i for i, dt in enumerate(mydata.data.dtypes.values) if dt.name == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [i for i, dt in enumerate(mydata.data.dtypes.values)]\n",
    "categoricals = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_dict = OneHotEncoder(categories='auto').fit(mydata.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_dict.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_dict.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_dict.transform(mydata.data['workclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dict.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dict.transform(mydata.data['workclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.sum(np.log([0.000000000000000000000000000000001, 0.8430962343096225, 0.07322175732217619, 0.08368200836820137]) * \\\n",
    "[0.0, 0.8430962343096225, 0.07322175732217619, 0.08368200836820137])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log([0.00000000000001, 0.9999999782235003, 2.1776499755250584e-08, 0.00000000000000001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.9999999782235003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_corrected([0.95, 0.0, 0.0, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_test([0.4, 0.6], [0.9, 0.1], 'kldiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
