{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up notebook and load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for notebook plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# load what we need\n",
    "import time\n",
    "import timeit\n",
    "import numpy as np\n",
    "import CHIRPS.structures as strcts\n",
    "import CHIRPS.datasets as ds\n",
    "import CHIRPS.datasets_proprietary as dsp\n",
    "import CHIRPS.routines as rt\n",
    "\n",
    "# demo datasets that ship with package. all from UCI unless stated otherwise\n",
    "# import CHIRPS.datasets as ds\n",
    "# ds.adult_data, ds.adult_samp_data, ds.adult_small_samp_data Large dataset ships with manageable sub samples\n",
    "# ds.bankmark_data, ds.bankmark_samp_data\n",
    "# ds.car_data\n",
    "# ds.cardio_data this is the cardiotocography dataset\n",
    "# ds.credit_data\n",
    "# ds.german_data\n",
    "# ds.lending_data, ds.lending_samp_data, ds.lending_small_samp_data, ds.lending_tiny_samp_data from Kaggle. see datasets_from_source file for links\n",
    "# ds.nursery_data, ds.nursery_samp_data\n",
    "# ds.rcdv_data, ds.rcdv_samp_data from US government see datasets_from_source file for links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common config - can be ommitted if defaults are OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location to save results\n",
    "project_dir = '/datadisk/whiteboxing/examples2'\n",
    "# project_dir = 'V:\\\\whiteboxing\\\\2020' # defaults to a directory \"whiteboxing\" in the working directory\n",
    "# project_dir = 'C:\\\\Users\\\\Crutt\\\\Documents\\\\whiteboxing\\\\2020'\n",
    "\n",
    "random_state_splits = 123 # one off for splitting the data into test / train\n",
    "random_state = 123 # for everything else - e.g. building a new rf with same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Random Forest Model to Predict and Explain\n",
    "First, a wrapper is created for the dataset. Use one that ships with the package, or create your own.\n",
    "Then split the data into training and (hold out) test set using the convenience functions in the package. These return an object that contain the split data in various representations, such as Pandas DataFrames and encoded, sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/anaconda3/envs/B3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using previous tuning parameters\n",
      "Best OOB Accuracy Estimate during tuning: 0.7643\n",
      "Best parameters:{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 1600, 'subsample': 0.5, 'random_state': 123}\n",
      "\n",
      "[[176  36]\n",
      " [ 35  53]]\n"
     ]
    }
   ],
   "source": [
    "# load one of the included datasets\n",
    "# project_dir will default to directory name CHIRPS in the working directory if not given\n",
    "# random_state will default to 123\n",
    "override_tuning = False\n",
    "mydata = ds.german(random_state=random_state_splits, project_dir=project_dir)\n",
    "\n",
    "meta_data = mydata.get_meta()\n",
    "save_path = meta_data['get_save_path']()\n",
    "\n",
    "# split the data. here using a basic sampling method.\n",
    "# the returned object is a wrapper class that contains\n",
    "# the train and test splits for X and y\n",
    "\n",
    "# also the the encoded versions of X_train and X_test that the rf will use\n",
    "# this is because we prefer onehot encoded over allowing categorical vars to be represented as integer\n",
    "# scikit would treat these as ordinal, which is inappropriate\n",
    "\n",
    "# also some meta-data: priors for y, the indexes from the input data\n",
    "\n",
    "# also some convenience functions for leave-one-out testing\n",
    "\n",
    "# train test split - one off hard-coded random state.\n",
    "# random state can be ommitted \n",
    "# and will default to the state held in the dataset container\n",
    "# which defaults to 123 if ommitted in the constructor\n",
    "train_index, test_index = mydata.get_tt_split_idx(random_state=random_state_splits)\n",
    "# optionally, indexes can be ommitted and will default to scikit's train_test_split method\n",
    "tt = mydata.tt_split(train_index, test_index)\n",
    "\n",
    "# CHOOSE ONE\n",
    "# model = 'RandomForest'\n",
    "# model = 'AdaBoost1' # SAMME\n",
    "# model = 'AdaBoost2' # SAMME.R\n",
    "model = 'GBM'\n",
    "\n",
    "# decide if to run the whole tuning routine again (long for Adaboost)\n",
    "# RF routine has a default tuning grid, so can leave as None, or come up with some other options\n",
    "tuning = {'grid' : None, 'override' : override_tuning}\n",
    "if model == 'RandomForest':\n",
    "    which_trees = 'majority'\n",
    "    tuning.update({'grid' : {'n_estimators': [(i + 1) * 200 for i in range(8)],\n",
    "                            'max_depth' : [32]}})\n",
    "\n",
    "elif model in ('AdaBoost1', 'AdaBoost2'):\n",
    "    if model == 'AdaBoost1':\n",
    "        # classic (and multi-class) AdaBoost\n",
    "        algo = 'SAMME'\n",
    "        which_trees = 'majority'\n",
    "    else:\n",
    "        # real-valued AdaBoost\n",
    "        algo = 'SAMME.R'\n",
    "        which_trees = 'conf_weighted'\n",
    "    max_depth = [i for i in range(1, 5)]\n",
    "    tuning.update({'grid' : {'base_estimator' : [rt.DecisionTreeClassifier(max_depth=d) for d in max_depth],\n",
    "                            'n_estimators': [(i + 1) * 200 for i in range(8)], 'algorithm': [algo]}})\n",
    "    \n",
    "else: # GBM\n",
    "    tuning.update({'grid' : {'subsample' : [0.5],\n",
    "                        'n_estimators': [i * 200 for i in range(1, 9)],\n",
    "                        'max_depth' : [i for i in range(1, 5)],\n",
    "                        'learning_rate': np.full(4, 10.0)**[i for i in range(-3, 1)]}})\n",
    "\n",
    "rf = rt.forest_prep(ds_container=tt,\n",
    "                    meta_data=meta_data,\n",
    "                    override_tuning=override_tuning,\n",
    "                    model=model,\n",
    "                    tuning_grid=tuning['grid'],\n",
    "                    save_path=save_path,\n",
    "                    plot_cm=False, plot_cm_norm=False)\n",
    "\n",
    "# get what the model predicts on the training sample\n",
    "sample_labels = rf.predict(tt.X_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing unseen data\n",
    "\n",
    "Again note:\n",
    "test set has never been \"seen\" by random forest during training\n",
    "test set has been only used to assess model (random forest) accuracy - no additional tuning after this\n",
    "test set has not be involved in generating the explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optional: memory and computation cost management\n",
    "#### CHIRPS is time economical but memory intensive to compute for lots of instances at once\n",
    "option 1: choose a smaller number of instances to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control for async processes - each tree walk can be done in its own core\n",
    "# and so can each explanation (e.g. rule conditions merge by hill-climbing)\n",
    "# these will default to false if not passed explicitly to the explainer function\n",
    "# on a multi-core machine there should be a good speed up for large batches\n",
    "# when the batch_size advantage exceeds the overhead of setting up multi-processing\n",
    "# timings will be printed to screen so you can see if it helps\n",
    "forest_walk_async=True\n",
    "explanation_async=True\n",
    "\n",
    "# how many instances to explain in total from a test/unseen set\n",
    "# doesn't matter if you don't know how large the dataset is\n",
    "# this function prevents you maxing out, or put n_instances = None for whole dataset\n",
    "n_instances = rt.n_instance_ceiling(ds_container=tt, n_instances=30)\n",
    "\n",
    "# this gets the next batch out of the data_split_container according to the required number of instances\n",
    "# all formats can be extracted, depending on the requirement\n",
    "# unencoded, encoded (sparse matrix is the type returned by scikit), ordinary dense matrix also available\n",
    "tt.current_row_test = 0\n",
    "instances, _, instances_enc, instances_enc_matrix, labels = tt.get_next(n_instances, which_split='test') # default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 2: just run the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances = tt.X_test; instances_enc = tt.X_test_enc; instances_enc_matrix = tt.X_test_enc_matrix; labels = tt.y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions from the decision forest on the unseen data\n",
    "Important point, no compromise on model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the model predictions for the test instance(s) we're looking at\n",
    "preds_idx = labels.index\n",
    "preds = rf.predict(X=instances_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIRPS Step 1:\n",
    "## Extract Tree Prediction Paths\n",
    "### Fit a forest_walker object to the dataset and decision forest\n",
    "This is a wrapper will extracts the paths of all the given instances. For CHIRPS, we want a large sample. The whole training set or other representative sample will do.\n",
    "\n",
    "It can also report interesting statistics (treating the forest as a set of random tree-structured variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# wrapper object needs the decision forest itself and the dataset meta data \n",
    "if model == 'GBM':\n",
    "    f_walker = strcts.regression_trees_walker(forest = rf, meta_data=meta_data)\n",
    "else:\n",
    "    f_walker = strcts.classification_trees_walker(forest = rf, meta_data=meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walking forest for 30 instances... (please wait)\n",
      "Forest Walk with async = True\n",
      "Forest Walk time elapsed: 2.1279 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Walking forest for ' + str(len(labels)) + ' instances... (please wait)')\n",
    "\n",
    "# set the timer\n",
    "forest_walk_start_time = timeit.default_timer()\n",
    "\n",
    "# do the walk - creates a paths_container (even for just one instance) as a new property\n",
    "# requires the X instances in a matrix (dense, ordinary numpy matrix) - this is available in the data_split_container\n",
    "f_walker.forest_walk(instances = instances_enc_matrix\n",
    "                    , labels = preds # we're explaining the prediction, not the true label!\n",
    "                    , forest_walk_async = forest_walk_async)\n",
    "\n",
    "# stop the timer\n",
    "forest_walk_end_time = timeit.default_timer()\n",
    "forest_walk_elapsed_time = forest_walk_end_time - forest_walk_start_time\n",
    "\n",
    "print('Forest Walk with async = ' + str(forest_walk_async))\n",
    "print('Forest Walk time elapsed:', \"{:0.4f}\".format(forest_walk_elapsed_time), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIRPS Steps 2-4: \n",
    "## Freqent pattern mining of paths.\n",
    "## Score and sort mined path segments.\n",
    "## Merge path segments into one rule.\n",
    "\n",
    "This is a wrapper object that will execute steps 2-4 on all the instance-paths in the batch_paths_container.\n",
    "\n",
    "Note that true_divide warnings are OK. It just means that a continuous variable is unbounded in some way i.e. no greater/less than discontinuity is used in the CHIRPS explanation.\n",
    "\n",
    "Note also, here we are using the training set to create the explainers. We could use a different dataset as long as it is representative of the training set that built the decision forest. Most important that we don't use the dataset that we wish to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GBHIPS on a batch of 30 instances... (please wait)\n",
      "as_chirps for batch_idx 0\n",
      "\n",
      "start mining for batch_idx 0 with support = 0.05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_chirps for batch_idx 1\n",
      "start mining for batch_idx 1 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_chirps for batch_idx 2\n",
      "start mining for batch_idx 2 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_chirps for batch_idx 3\n",
      "start mining for batch_idx 3 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_chirps for batch_idx 4\n",
      "start mining for batch_idx 4 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_chirps for batch_idx 5\n",
      "start mining for batch_idx 5 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_chirps for batch_idx 6\n",
      "start mining for batch_idx 6 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_chirps for batch_idx 7\n",
      "start mining for batch_idx 7 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 88 patterns from 761 trees for batch_idx 1\n",
      "start score sort for batch_idx 1 (88) patterns\n",
      "start merge rule for batch_idx 1 (88) patterns\n",
      "found 98 patterns from 838 trees for batch_idx 2\n",
      "start score sort for batch_idx 2 (98) patterns\n",
      "start merge rule for batch_idx 2 (98) patterns\n",
      "found 96 patterns from 990 trees for batch_idx 0\n",
      "start score sort for batch_idx 0 (96) patterns\n",
      "start merge rule for batch_idx 0 (96) patterns\n",
      "found 97 patterns from 1055 trees for batch_idx 4\n",
      "start score sort for batch_idx 4 (97) patterns\n",
      "start merge rule for batch_idx 4 (97) patterns\n",
      "found 96 patterns from 796 trees for batch_idx 6\n",
      "start score sort for batch_idx 6 (96) patterns\n",
      "found 93 patterns from 1010 trees for batch_idx 3\n",
      "start score sort for batch_idx 3 (93) patterns\n",
      "start merge rule for batch_idx 6 (96) patterns\n",
      "start merge rule for batch_idx 3 (93) patterns\n",
      "found 91 patterns from 841 trees for batch_idx 7found 96 patterns from 907 trees for batch_idx 5\n",
      "\n",
      "start score sort for batch_idx 7 (91) patternsstart score sort for batch_idx 5 (96) patterns\n",
      "\n",
      "start merge rule for batch_idx 5 (96) patterns\n",
      "start merge rule for batch_idx 7 (91) patterns\n",
      "[('debt_A103', False, 0.5)]\n",
      "0.8823529411764706 0.04495021337126601 0.046917781891267676 0.031007482091632683\n",
      "merge complete for batch_idx 4 (97) patterns\n",
      "start get explainer for batch_idx 4\n",
      "as_chirps for batch_idx 8\n",
      "start mining for batch_idx 8 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dur', True, 16.60345), ('crhis_A31', True, 0.5)]\n",
      "0.9003322259136213 0.3508890469416785 0.1335678339047698 0.1344174482723094\n",
      "merge complete for batch_idx 1 (88) patterns\n",
      "start get explainer for batch_idx 1\n",
      "as_chirps for batch_idx 9\n",
      "start mining for batch_idx 9 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 95 patterns from 909 trees for batch_idx 8\n",
      "start score sort for batch_idx 8 (95) patterns\n",
      "start merge rule for batch_idx 8 (95) patterns\n",
      "[('chk_A13', False, 0.5)]\n",
      "0.9464285714285714 0.07633357041251779 0.07111993080483947 0.046035686125636195\n",
      "merge complete for batch_idx 5 (96) patterns\n",
      "start get explainer for batch_idx 5\n",
      "[('chk_A13', False, 0.5)]\n",
      "0.9464285714285714 0.07633357041251779 0.06292643007197037 0.04179123415546814\n",
      "merge complete for batch_idx 6 (96) patterns\n",
      "start get explainer for batch_idx 6\n",
      "as_chirps for batch_idx 10\n",
      "start mining for batch_idx 10 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_chirps for batch_idx 11"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start mining for batch_idx 11 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('emp_A72', False, 0.5), ('dur', False, 22.5), ('chk_A14', True, 0.5)]\n",
      "0.7878787878787878 0.043688425267372634 0.1570871058834033 0.12110773360838115\n",
      "merge complete for batch_idx 2 (98) patterns\n",
      "start get explainer for batch_idx 2\n",
      "[('chk_A14', False, 0.5), ('amt', True, 7660.23034)]\n",
      "0.974169741697417 0.37068812233285914 0.10810247293527306 0.089715766012196\n",
      "merge complete for batch_idx 3 (93) patterns\n",
      "start get explainer for batch_idx 3\n",
      "as_chirps for batch_idx 12\n",
      "found 96 patterns from 931 trees for batch_idx 9\n",
      "start score sort for batch_idx 9 (96) patterns\n",
      "start mining for batch_idx 12 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start merge rule for batch_idx 9 (96) patternsas_chirps for batch_idx 13\n",
      "\n",
      "start mining for batch_idx 13 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dur', False, 33.11538), ('chk_A14', True, 0.5), ('pps_A43', True, 0.5), ('debt_A103', True, 0.5)]\n",
      "0.7058823529411765 0.06802328644433908 0.13941368386146744 0.09601869373778718\n",
      "merge complete for batch_idx 0 (96) patterns\n",
      "start get explainer for batch_idx 0\n",
      "[('chk_A11', False, 0.5), ('age', True, 25.23626), ('dur', False, 9.5)]\n",
      "0.6666666666666666 0.05563458195037142 0.15191603511178955 0.1305515204601579\n",
      "merge complete for batch_idx 7 (91) patterns\n",
      "start get explainer for batch_idx 7\n",
      "as_chirps for batch_idx 14\n",
      "start mining for batch_idx 14 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 93 patterns from 921 trees for batch_idx 10\n",
      "start score sort for batch_idx 10 (93) patterns\n",
      "found 90 patterns from 895 trees for batch_idx 11\n",
      "start score sort for batch_idx 11 (90) patterns\n",
      "start merge rule for batch_idx 10 (93) patterns\n",
      "as_chirps for batch_idx 15\n",
      "start mining for batch_idx 15 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start merge rule for batch_idx 11 (90) patterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 95 patterns from 1142 trees for batch_idx 12\n",
      "start score sort for batch_idx 12 (95) patterns\n",
      "start merge rule for batch_idx 12 (95) patterns\n",
      "found 96 patterns from 951 trees for batch_idx 13\n",
      "start score sort for batch_idx 13 (96) patterns\n",
      "start merge rule for batch_idx 13 (96) patterns\n",
      "found 97 patterns from 928 trees for batch_idx 15\n",
      "start score sort for batch_idx 15 (97) patterns\n",
      "start merge rule for batch_idx 15 (97) patterns\n",
      "found 94 patterns from 994 trees for batch_idx 14\n",
      "start score sort for batch_idx 14 (94) patterns\n",
      "start merge rule for batch_idx 14 (94) patterns\n",
      "[('dur', True, 16.68939)]\n",
      "0.8801261829652997 0.3472617354196301 0.12892739526831545 0.10414612880396862\n",
      "merge complete for batch_idx 8 (95) patterns\n",
      "start get explainer for batch_idx 8\n",
      "as_chirps for batch_idx 16\n",
      "start mining for batch_idx 16 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chk_A11', True, 0.5)]\n",
      "0.8574144486692015 0.40529871977240395 0.14892824439265662 0.10910564652150785\n",
      "merge complete for batch_idx 9 (96) patterns\n",
      "start get explainer for batch_idx 9\n",
      "[('svng_A64', False, 0.5)]\n",
      "0.9230769230769231 0.052302631578947364 0.06938853791729446 0.054675405091459885\n",
      "merge complete for batch_idx 12 (95) patterns\n",
      "start get explainer for batch_idx 12\n",
      "as_chirps for batch_idx 17\n",
      "start mining for batch_idx 17 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_chirps for batch_idx 18\n",
      "start mining for batch_idx 18 with support = 0.05\n",
      "found 97 patterns from 1015 trees for batch_idx 16"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start score sort for batch_idx 16 (97) patterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start merge rule for batch_idx 16 (97) patterns\n",
      "[('amt', False, 11725.47059), ('emp_A74', True, 0.5)]\n",
      "0.7857142857142857 0.01703809072230125 0.11712458000648203 0.073129386913114\n",
      "merge complete for batch_idx 13 (96) patterns\n",
      "start get explainer for batch_idx 13\n",
      "as_chirps for batch_idx 19\n",
      "start mining for batch_idx 19 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('svng_A64', False, 0.5)]\n",
      "0.9230769230769231 0.052302631578947364 0.07025762177877748 0.05175484457960335\n",
      "merge complete for batch_idx 15 (97) patterns\n",
      "start get explainer for batch_idx 15\n",
      "as_chirps for batch_idx 20\n",
      "start mining for batch_idx 20 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 98 patterns from 901 trees for batch_idx 17\n",
      "start score sort for batch_idx 17 (98) patterns\n",
      "start merge rule for batch_idx 17 (98) patterns\n",
      "found 97 patterns from 977 trees for batch_idx 18\n",
      "start score sort for batch_idx 18 (97) patterns\n",
      "start merge rule for batch_idx 18 (97) patterns\n",
      "[('dur', True, 13.14394)]\n",
      "0.8876404494382022 0.3109886201991465 0.16211936505188063 0.14945363773208165\n",
      "merge complete for batch_idx 10 (93) patterns\n",
      "start get explainer for batch_idx 10\n",
      "as_chirps for batch_idx 21\n",
      "start mining for batch_idx 21 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 93 patterns from 904 trees for batch_idx 19\n",
      "start score sort for batch_idx 19 (93) patterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start merge rule for batch_idx 19 (93) patterns\n",
      "[('amt', False, 11262.48077)]\n",
      "0.7222222222222222 0.02263315947526474 0.09946290576359922 0.06267639293705192\n",
      "merge complete for batch_idx 18 (97) patterns\n",
      "start get explainer for batch_idx 18\n",
      "as_chirps for batch_idx 22\n",
      "start mining for batch_idx 22 with support = 0.05\n",
      "found 90 patterns from 953 trees for batch_idx 20\n",
      "start score sort for batch_idx 20 (90) patterns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start merge rule for batch_idx 20 (90) patterns\n",
      "[('dur', True, 11.8125)]\n",
      "0.9477611940298507 [('chk_A11', False, 0.5), ('pers_A92', False, 0.5), ('crhis_A34', True, 0.5), ('emp_A75', True, 0.5), ('debt_A103', True, 0.5)]\n",
      "0.7209302325581395 0.05724145197829408 0.12858675617794685 0.11089159499307770.18189900426742533\n",
      "merge complete for batch_idx 11 (90) patterns\n",
      "start get explainer for batch_idx 11\n",
      " 0.09619538912249552 0.07705367055126326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "merge complete for batch_idx 14 (94) patterns\n",
      "start get explainer for batch_idx 14\n",
      "as_chirps for batch_idx 23\n",
      "start mining for batch_idx 23 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_chirps for batch_idx 24\n",
      "start mining for batch_idx 24 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 96 patterns from 979 trees for batch_idx 23\n",
      "start score sort for batch_idx 23 (96) patternsfound 96 patterns from 995 trees for batch_idx 21\n",
      "\n",
      "found 97 patterns from 768 trees for batch_idx 24start score sort for batch_idx 21 (96) patterns\n",
      "\n",
      "start score sort for batch_idx 24 (97) patterns\n",
      "start merge rule for batch_idx 23 (96) patterns\n",
      "start merge rule for batch_idx 24 (97) patterns\n",
      "start merge rule for batch_idx 21 (96) patterns\n",
      "found 93 patterns from 937 trees for batch_idx 22\n",
      "start score sort for batch_idx 22 (93) patterns\n",
      "start merge rule for batch_idx 22 (93) patterns\n",
      "[('chk_A14', False, 0.5)]\n",
      "0.9479166666666666 0.3737731152204836 0.12929116581594347 0.11233689571381035\n",
      "merge complete for batch_idx 16 (97) patterns\n",
      "start get explainer for batch_idx 16\n",
      "as_chirps for batch_idx 25\n",
      "start mining for batch_idx 25 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('amt', False, 7968.1413), ('emp_A74', True, 0.5), ('pps_A41', True, 0.5)]\n",
      "0.8214285714285714 0.0367788841473052 0.11740726347195611 0.08552511876908173\n",
      "merge complete for batch_idx 19 (93) patterns\n",
      "start get explainer for batch_idx 19\n",
      "as_chirps for batch_idx 26\n",
      "start mining for batch_idx 26 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dur', False, 28.5), ('chk_A12', False, 0.5)]\n",
      "0.6382978723404256 0.062233285917496446 0.1504022376129984 0.10557205257728658\n",
      "merge complete for batch_idx 17 (98) patterns"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start get explainer for batch_idx 17\n",
      "[('chk_A14', False, 0.5)]\n",
      "0.9479166666666666 0.3737731152204836 0.13153748848623814 0.10907187636037934\n",
      "merge complete for batch_idx 20 (90) patterns\n",
      "start get explainer for batch_idx 20\n",
      "as_chirps for batch_idx 27\n",
      "start mining for batch_idx 27 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 90 patterns from 1031 trees for batch_idx 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start merge rule for batch_idx 25 (90) patternsstart score sort for batch_idx 25 (90) patterns\n",
      "as_chirps for batch_idx 28\n",
      "start mining for batch_idx 28 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('svng_A64', False, 0.5)]\n",
      "0.9230769230769231 0.052302631578947364 0.07586760547388684 0.052069916762445226\n",
      "merge complete for batch_idx 21 (96) patterns\n",
      "start get explainer for batch_idx 21\n",
      "as_chirps for batch_idx 29\n",
      "start mining for batch_idx 29 with support = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1553: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1558: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('prop_A121', False, 0.5)]\n",
      "0.8820754716981132 0.2557788051209104 0.10278431484937683 0.1020067919262398\n",
      "merge complete for batch_idx 24 (97) patterns\n",
      "start get explainer for batch_idx 24\n",
      "[('chk_A11', True, 0.5), ('amt', True, 10699.61111)]\n",
      "0.8786692759295499 0.45252489331436696 0.12078505935826428 0.12347541259629799\n",
      "merge complete for batch_idx 23 (96) patterns\n",
      "start get explainer for batch_idx 23\n",
      "found 96 patterns from 915 trees for batch_idx 26\n",
      "start score sort for batch_idx 26 (96) patterns\n",
      "found 97 patterns from 1027 trees for batch_idx 27\n",
      "start score sort for batch_idx 27 (97) patterns\n",
      "start merge rule for batch_idx 26 (96) patterns\n",
      "start merge rule for batch_idx 27 (97) patterns\n",
      "found 100 patterns from 972 trees for batch_idx 28\n",
      "start score sort for batch_idx 28 (100) patterns\n",
      "start merge rule for batch_idx 28 (100) patterns\n",
      "[('crhis_A31', False, 0.5)]\n",
      "0.525 0.05235235235235236 0.06512342916278079 0.051609275456392774\n",
      "merge complete for batch_idx 26 (96) patterns\n",
      "start get explainer for batch_idx 26\n",
      "found 96 patterns from 854 trees for batch_idx 29\n",
      "start score sort for batch_idx 29 (96) patterns\n",
      "start merge rule for batch_idx 29 (96) patterns\n",
      "[('chk_A11', False, 0.5), ('dur', False, 22.54545), ('tel_A191', False, 0.5), ('rate', False, 2.3333333333333335), ('job_A173', False, 0.5)]\n",
      "0.875 0.031236499657552288 0.2046212353712159 0.1808699162982225\n",
      "merge complete for batch_idx 22 (93) patterns\n",
      "start get explainer for batch_idx 22\n",
      "[('dur', True, 10.39796), ('crhis_A31', True, 0.5)]\n",
      "0.9672131147540983 0.16856330014224752 0.11425632276949316 0.09396838426968764\n",
      "merge complete for batch_idx 25 (90) patterns\n",
      "start get explainer for batch_idx 25\n",
      "[('chk_A14', False, 0.5)]\n",
      "0.9479166666666666 0.3737731152204836 0.10056327202116164 0.09906952619520462\n",
      "merge complete for batch_idx 28 (100) patterns\n",
      "start get explainer for batch_idx 28\n",
      "[('chk_A14', False, 0.5)]\n",
      "0.9479166666666666 0.3737731152204836 0.10906139254894587 0.09037502829268676\n",
      "merge complete for batch_idx 27 (97) patterns\n",
      "start get explainer for batch_idx 27\n",
      "[('chk_A11', True, 0.5), ('dur', True, 38.22222)]\n",
      "0.8850102669404517 0.45705903271692744 0.11470587795374292 0.1236140743465776\n",
      "merge complete for batch_idx 29 (96) patterns\n",
      "start get explainer for batch_idx 29\n",
      "GBHIPS time elapsed: 12.5845 seconds\n",
      "GBHIPS with async = True\n"
     ]
    }
   ],
   "source": [
    "if model == 'GBM':\n",
    "    # create a GBHIPS container object for the forest path detail\n",
    "    explanations = strcts.GBHIPS_container(f_walker.path_detail,\n",
    "                                    forest=rf,\n",
    "                                    sample_instances=tt.X_train_enc, # any representative sample can be used\n",
    "                                    sample_labels=sample_labels,\n",
    "                                    meta_data=meta_data)\n",
    "    \n",
    "    print('Running GBHIPS on a batch of ' + str(len(labels)) + ' instances... (please wait)')\n",
    "    # start a timer\n",
    "    ce_start_time = timeit.default_timer()\n",
    "\n",
    "    # run the explanation algorithm for Gradient Boosted Trees on all the instance path details\n",
    "    explanations.run_explanations(target_classes=preds, # we're explaining the prediction, not the true label!\n",
    "                            explanation_async=explanation_async,\n",
    "                            random_state=random_state,\n",
    "                            paths_lengths_threshold=5,\n",
    "                            which_trees='targetclass',\n",
    "                            alpha_paths=0.0,\n",
    "                            support_paths=0.05,\n",
    "                            score_func=1,\n",
    "                            precis_threshold=0.99,\n",
    "                            disc_path_bins=6,\n",
    "                            merging_bootstraps=20,\n",
    "                            pruning_bootstraps=20,\n",
    "                            delta=0.2,\n",
    "                            weighting='kldiv')\n",
    "    \n",
    "    # For unbalanced data in binary classification, if an instance has a negative margin, \n",
    "    # that means it moved towards the boundary (say prob = 0.5 or lodds = 0)\n",
    "    # but did not move far enough to change class (say from > 0.75 prior).\n",
    "    # However, one can say it has some similarities to the other class.\n",
    "    # These can be viewed by setting the other class as the target and \n",
    "    # which_trees = 'signdelta' (trees that agree with the sign of the total change of lodds)\n",
    "\n",
    "    ce_end_time = timeit.default_timer()\n",
    "    ce_elapsed_time = ce_end_time - ce_start_time\n",
    "    print('GBHIPS time elapsed:', \"{:0.4f}\".format(ce_elapsed_time), 'seconds')\n",
    "    print('GBHIPS with async = ' + str(explanation_async))\n",
    "    \n",
    "if model == 'RandomForest':\n",
    "    # create a CHIRPS container for the forest path detail\n",
    "    explanations = strcts.CHIRPS_container(f_walker.path_detail,\n",
    "                                    forest=rf,\n",
    "                                    sample_instances=tt.X_train_enc, # any representative sample can be used\n",
    "                                    sample_labels=sample_labels,\n",
    "                                    meta_data=meta_data)\n",
    "    \n",
    "    print('Running CHIRPS on a batch of ' + str(len(labels)) + ' instances... (please wait)')\n",
    "    # start a timer\n",
    "    ce_start_time = timeit.default_timer()\n",
    "    \n",
    "    # run the explanation algorithm for Random Forest or AdaBoost on all the instance path details\n",
    "    explanations.run_explanations(target_classes=preds, # we're explaining the prediction, not the true label!\n",
    "                            explanation_async=explanation_async,\n",
    "                            random_state=random_state,\n",
    "                            which_trees=which_trees,\n",
    "                            alpha_paths=0.0,\n",
    "                            support_paths=0.01,\n",
    "                            score_func=1,\n",
    "                            precis_threshold=0.99,\n",
    "                            disc_path_bins=4,\n",
    "                            merging_bootstraps=20,\n",
    "                            pruning_bootstraps=20,\n",
    "                            delta=0.2,\n",
    "                            weighting='nothing')\n",
    "\n",
    "    ce_end_time = timeit.default_timer()\n",
    "    ce_elapsed_time = ce_end_time - ce_start_time\n",
    "    print('CHIRPS time elapsed:', \"{:0.4f}\".format(ce_elapsed_time), 'seconds')\n",
    "    print('CHIRPS with async = ' + str(explanation_async))\n",
    "    \n",
    "if model == 'AdaBoost1':\n",
    "    # create a CHIRPS container for the forest path detail\n",
    "    explanations = strcts.CHIRPS_container(f_walker.path_detail,\n",
    "                                    forest=rf,\n",
    "                                    sample_instances=tt.X_train_enc, # any representative sample can be used\n",
    "                                    sample_labels=sample_labels,\n",
    "                                    meta_data=meta_data)\n",
    "    \n",
    "    print('Running CHIRPS on a batch of ' + str(len(labels)) + ' instances... (please wait)')\n",
    "    # start a timer\n",
    "    ce_start_time = timeit.default_timer()\n",
    "    \n",
    "    # run the explanation algorithm for Random Forest or AdaBoost on all the instance path details\n",
    "    explanations.run_explanations(target_classes=preds, # we're explaining the prediction, not the true label!\n",
    "                            explanation_async=explanation_async,\n",
    "                            random_state=random_state,\n",
    "                            which_trees=which_trees,\n",
    "                            alpha_paths=0.0,\n",
    "                            support_paths=0.01,\n",
    "                            score_func=1,\n",
    "                            precis_threshold=0.99,\n",
    "                            disc_path_bins=4,\n",
    "                            merging_bootstraps=20,\n",
    "                            pruning_bootstraps=20,\n",
    "                            delta=0.2,\n",
    "                            weighting='kldiv')\n",
    "\n",
    "    ce_end_time = timeit.default_timer()\n",
    "    ce_elapsed_time = ce_end_time - ce_start_time\n",
    "    print('CHIRPS time elapsed:', \"{:0.4f}\".format(ce_elapsed_time), 'seconds')\n",
    "    print('CHIRPS with async = ' + str(explanation_async))\n",
    "    \n",
    "if model == 'AdaBoost2':\n",
    "    # create a CHIRPS container for the forest path detail\n",
    "    explanations = strcts.CHIRPS_container(f_walker.path_detail,\n",
    "                                    forest=rf,\n",
    "                                    sample_instances=tt.X_train_enc, # any representative sample can be used\n",
    "                                    sample_labels=sample_labels,\n",
    "                                    meta_data=meta_data)\n",
    "    \n",
    "    print('Running CHIRPS on a batch of ' + str(len(labels)) + ' instances... (please wait)')\n",
    "    # start a timer\n",
    "    ce_start_time = timeit.default_timer()\n",
    "    \n",
    "    # run the explanation algorithm for Random Forest or AdaBoost on all the instance path details\n",
    "    explanations.run_explanations(target_classes=preds, # we're explaining the prediction, not the true label!\n",
    "                            explanation_async=explanation_async,\n",
    "                            random_state=random_state,\n",
    "                            which_trees=which_trees,\n",
    "                            alpha_paths=0.00,\n",
    "                            support_paths=0.001,\n",
    "                            score_func=1,\n",
    "                            precis_threshold=0.99,\n",
    "                            disc_path_bins=8,\n",
    "                            merging_bootstraps=20,\n",
    "                            pruning_bootstraps=20,\n",
    "                            delta=0.2,\n",
    "                            weighting='kldiv')\n",
    "\n",
    "    ce_end_time = timeit.default_timer()\n",
    "    ce_elapsed_time = ce_end_time - ce_start_time\n",
    "    print('CHIRPS time elapsed:', \"{:0.4f}\".format(ce_elapsed_time), 'seconds')\n",
    "    print('CHIRPS with async = ' + str(explanation_async))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing Explanations\n",
    "For evaluation, see alternative notebook. This session assumes that the system has been tested and tuned.\n",
    "\n",
    "It is sufficient at this point to examine the explanation stats over the training set since we are explaning the influence of the training set over the model building algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demonstrating found explanations\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 131 with true class label: 1 (bad)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 1 (bad)\n",
      "target class prior (training data): 0.22857142857142856\n",
      "forest vote share (unseen instance): 0.61875\n",
      "forest vote margin (unseen instance): 0.23750000000000004\n",
      "confidence weighted forest vote share (unseen instance): 0.7567882199505239\n",
      "confidence weighted forest vote margin (unseen instance): 0.5135764399010467\n",
      "\n",
      "rule: dur > 33.11538 AND chk_A14 False AND pps_A43 False AND debt_A103 False\n",
      "rule cardinality: 4\n",
      "Fraction of total points of rule: 0.13941368386146744\n",
      "Fraction of total weight of rule: 0.09601869373778718\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.22857142857142856\n",
      "rule coverage (unseen data): 0.06990014265335236\n",
      "rule xcoverage (unseen data): 0.06970128022759602\n",
      "rule precision (unseen data): 0.7291666666666666\n",
      "rule stability (unseen data): 0.7058823529411765\n",
      "rule recall (unseen data): 0.21875\n",
      "rule f1 score (unseen data): 0.3365384615384615\n",
      "rule NPV (unseen data): 0.975925925925926\n",
      "rule lift (unseen data): 46.52235243055556\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.27083333 0.72916667]\n",
      "rule posterior counts (unseen data): [13. 35.]\n",
      "rule chisq p-value (unseen data): 7.873014006973842e-14\n",
      "rule Kullback-Leibler divergence (unseen data): 0.5623800706221767\n",
      "Evaluation Time: 3.527798309994978\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: dur_greater_than_lower_bound\n",
      "rule: dur <= 33.11538 AND chk_A14 False AND pps_A43 False AND debt_A103 False\n",
      "rule coverage (training data): 0.35520684736091296\n",
      "rule xcoverage (training data): 0.3541963015647226\n",
      "rule precision (training data): 0.3588709677419355\n",
      "rule stability (training data): 0.35856573705179284\n",
      "rule recall (training data): 0.55625\n",
      "rule f1 score (training data): 0.4362745098039216\n",
      "rule NPV (training data): 0.7055555555555556\n",
      "rule lift (training data): 4.431622333506764\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.64112903 0.35887097]\n",
      "rule posterior counts (training data): [159.  89.]\n",
      "rule chisq p-value (training data): 8.755805916259928e-05\n",
      "rule Kullback-Leibler divergence from original: 0.2835505111074771\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [164. 536.]\n",
      "proba: [0.23428571 0.76571429]\n",
      "\n",
      "Feature Reversed: chk\n",
      "rule: dur > 33.11538 AND chk_A14 True AND pps_A43 False AND debt_A103 False\n",
      "rule coverage (training data): 0.03566333808844508\n",
      "rule xcoverage (training data): 0.03556187766714083\n",
      "rule precision (training data): 0.375\n",
      "rule stability (training data): 0.37037037037037035\n",
      "rule recall (training data): 0.05625\n",
      "rule f1 score (training data): 0.09782608695652174\n",
      "rule NPV (training data): 0.9722222222222222\n",
      "rule lift (training data): 47.8515625\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.625 0.375]\n",
      "rule posterior counts (training data): [15.  9.]\n",
      "rule chisq p-value (training data): 0.1549970842222575\n",
      "rule Kullback-Leibler divergence from original: 0.25839465650468746\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [241. 459.]\n",
      "proba: [0.34428571 0.65571429]\n",
      "\n",
      "Feature Reversed: pps\n",
      "rule: dur > 33.11538 AND chk_A14 False AND pps_A43 True AND debt_A103 False\n",
      "rule coverage (training data): 0.024251069900142655\n",
      "rule xcoverage (training data): 0.02418207681365576\n",
      "rule precision (training data): 0.4375\n",
      "rule stability (training data): 0.42105263157894735\n",
      "rule recall (training data): 0.04375\n",
      "rule f1 score (training data): 0.07954545454545453\n",
      "rule NPV (training data): 0.9833333333333333\n",
      "rule lift (training data): 83.740234375\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.5625 0.4375]\n",
      "rule posterior counts (training data): [9. 7.]\n",
      "rule chisq p-value (training data): 0.09791773883020091\n",
      "rule Kullback-Leibler divergence from original: 0.17452823507604695\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "Feature Reversed: debt\n",
      "rule: dur > 33.11538 AND chk_A14 False AND pps_A43 False AND debt_A103 True\n",
      "rule coverage (training data): 0.005706134094151213\n",
      "rule xcoverage (training data): 0.005689900426742532\n",
      "rule precision (training data): 0.0\n",
      "rule stability (training data): 0.16666666666666666\n",
      "rule recall (training data): 0.0\n",
      "rule f1 score (training data): 0.0\n",
      "rule NPV (training data): 0.9944444444444445\n",
      "rule lift (training data): 0.0\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [1. 0.]\n",
      "rule posterior counts (training data): [3. 0.]\n",
      "rule chisq p-value (training data): 0.8008567833530595\n",
      "rule Kullback-Leibler divergence from original: 11.416902560161493\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 203 with true class label: 1 (bad)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.475625\n",
      "forest vote margin (unseen instance): -0.048750000000000016\n",
      "confidence weighted forest vote share (unseen instance): 0.4510443627740867\n",
      "confidence weighted forest vote margin (unseen instance): -0.09791127445182707\n",
      "\n",
      "rule: dur <= 16.60345 AND crhis_A31 False\n",
      "rule cardinality: 2\n",
      "Fraction of total points of rule: 0.1335678339047698\n",
      "Fraction of total weight of rule: 0.1344174482723094\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.42653352353780316\n",
      "rule xcoverage (unseen data): 0.42532005689900426\n",
      "rule precision (unseen data): 0.9060402684563759\n",
      "rule stability (unseen data): 0.9003322259136213\n",
      "rule recall (unseen data): 0.5\n",
      "rule f1 score (unseen data): 0.6443914081145585\n",
      "rule NPV (unseen data): 0.825\n",
      "rule lift (unseen data): 2.75888473492185\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.90604027 0.09395973]\n",
      "rule posterior counts (unseen data): [270.  28.]\n",
      "rule chisq p-value (unseen data): 1.0148485999205537e-06\n",
      "rule Kullback-Leibler divergence (unseen data): 0.0621986551109379\n",
      "Evaluation Time: 2.3366450920002535\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: dur_less_than_upper_bound\n",
      "rule: dur > 16.60345 AND crhis_A31 False\n",
      "rule coverage (training data): 0.5221112696148359\n",
      "rule xcoverage (training data): 0.5206258890469416\n",
      "rule precision (training data): 0.6931506849315069\n",
      "rule stability (training data): 0.6902173913043478\n",
      "rule recall (training data): 0.4685185185185185\n",
      "rule f1 score (training data): 0.5591160220994476\n",
      "rule NPV (training data): 0.3\n",
      "rule lift (training data): 1.723205660154431\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.69315068 0.30684932]\n",
      "rule posterior counts (training data): [253. 112.]\n",
      "rule chisq p-value (training data): 0.006804706176442308\n",
      "rule Kullback-Leibler divergence from original: 0.18034651118137202\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [138. 562.]\n",
      "proba: [0.19714286 0.80285714]\n",
      "\n",
      "Feature Reversed: crhis\n",
      "rule: dur <= 16.60345 AND crhis_A31 True\n",
      "rule coverage (training data): 0.024251069900142655\n",
      "rule xcoverage (training data): 0.02418207681365576\n",
      "rule precision (training data): 0.5\n",
      "rule stability (training data): 0.47368421052631576\n",
      "rule recall (training data): 0.014814814814814815\n",
      "rule f1 score (training data): 0.02877697841726619\n",
      "rule NPV (training data): 0.95\n",
      "rule lift (training data): 28.356481481481485\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.5 0.5]\n",
      "rule posterior counts (training data): [8. 8.]\n",
      "rule chisq p-value (training data): 0.025422813743947992\n",
      "rule Kullback-Leibler divergence from original: 0.45462334074058686\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 50 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 1 (bad)\n",
      "target class prior (training data): 0.22857142857142856\n",
      "forest vote share (unseen instance): 0.52375\n",
      "forest vote margin (unseen instance): 0.04750000000000004\n",
      "confidence weighted forest vote share (unseen instance): 0.6037180641362435\n",
      "confidence weighted forest vote margin (unseen instance): 0.20743612827248648\n",
      "\n",
      "rule: emp_A72 True AND dur > 22.5 AND chk_A14 False\n",
      "rule cardinality: 3\n",
      "Fraction of total points of rule: 0.1570871058834033\n",
      "Fraction of total weight of rule: 0.12110773360838115\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.22857142857142856\n",
      "rule coverage (unseen data): 0.0442225392296719\n",
      "rule xcoverage (unseen data): 0.044096728307254626\n",
      "rule precision (unseen data): 0.8333333333333334\n",
      "rule stability (unseen data): 0.7878787878787878\n",
      "rule recall (unseen data): 0.15625\n",
      "rule f1 score (unseen data): 0.2631578947368421\n",
      "rule NPV (unseen data): 0.9907407407407407\n",
      "rule lift (unseen data): 85.06944444444446\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.16666667 0.83333333]\n",
      "rule posterior counts (unseen data): [ 5. 25.]\n",
      "rule chisq p-value (unseen data): 4.394970702253812e-13\n",
      "rule Kullback-Leibler divergence (unseen data): 0.8226125138712371\n",
      "Evaluation Time: 2.9814825290013687\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: emp\n",
      "rule: emp_A72 False AND dur > 22.5 AND chk_A14 False\n",
      "rule coverage (training data): 0.19686162624821682\n",
      "rule xcoverage (training data): 0.19630156472261737\n",
      "rule precision (training data): 0.46715328467153283\n",
      "rule stability (training data): 0.4642857142857143\n",
      "rule recall (training data): 0.4\n",
      "rule f1 score (training data): 0.430976430976431\n",
      "rule NPV (training data): 0.8648148148148148\n",
      "rule lift (training data): 10.442751345303426\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.53284672 0.46715328]\n",
      "rule posterior counts (training data): [73. 64.]\n",
      "rule chisq p-value (training data): 1.488467452838583e-08\n",
      "rule Kullback-Leibler divergence from original: 0.2886071396753788\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [451. 249.]\n",
      "proba: [0.64428571 0.35571429]\n",
      "\n",
      "Feature Reversed: dur_greater_than_lower_bound\n",
      "rule: emp_A72 True AND dur <= 22.5 AND chk_A14 False\n",
      "rule coverage (training data): 0.07417974322396577\n",
      "rule xcoverage (training data): 0.07396870554765292\n",
      "rule precision (training data): 0.3137254901960784\n",
      "rule stability (training data): 0.3148148148148148\n",
      "rule recall (training data): 0.1\n",
      "rule f1 score (training data): 0.15165876777251186\n",
      "rule NPV (training data): 0.9351851851851852\n",
      "rule lift (training data): 18.838908112264516\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.68627451 0.31372549]\n",
      "rule posterior counts (training data): [35. 16.]\n",
      "rule chisq p-value (training data): 0.22443539610989577\n",
      "rule Kullback-Leibler divergence from original: 0.5782154937005878\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [659.  41.]\n",
      "proba: [0.94142857 0.05857143]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [597. 103.]\n",
      "proba: [0.85285714 0.14714286]\n",
      "\n",
      "Feature Reversed: chk\n",
      "rule: emp_A72 True AND dur > 22.5 AND chk_A14 True\n",
      "rule coverage (training data): 0.018544935805991442\n",
      "rule xcoverage (training data): 0.01849217638691323\n",
      "rule precision (training data): 0.25\n",
      "rule stability (training data): 0.26666666666666666\n",
      "rule recall (training data): 0.01875\n",
      "rule f1 score (training data): 0.03488372093023256\n",
      "rule NPV (training data): 0.9833333333333333\n",
      "rule lift (training data): 63.802083333333336\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.75 0.25]\n",
      "rule posterior counts (training data): [9. 3.]\n",
      "rule chisq p-value (training data): 0.8639954212700478\n",
      "rule Kullback-Leibler divergence from original: 0.7526307290295449\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE RESULTS\n",
      "instance id: 584 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.63125\n",
      "forest vote margin (unseen instance): 0.26249999999999996\n",
      "confidence weighted forest vote share (unseen instance): 0.6962086734693407\n",
      "confidence weighted forest vote margin (unseen instance): 0.3924173469386812\n",
      "\n",
      "rule: chk_A14 True AND amt <= 7660.23034\n",
      "rule cardinality: 2\n",
      "Fraction of total points of rule: 0.10810247293527306\n",
      "Fraction of total weight of rule: 0.089715766012196\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.38373751783166904\n",
      "rule xcoverage (unseen data): 0.38264580369843526\n",
      "rule precision (unseen data): 0.9813432835820896\n",
      "rule stability (unseen data): 0.974169741697417\n",
      "rule recall (unseen data): 0.48703703703703705\n",
      "rule f1 score (unseen data): 0.650990099009901\n",
      "rule NPV (unseen data): 0.96875\n",
      "rule lift (unseen data): 3.3226797191488657\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.98134328 0.01865672]\n",
      "rule posterior counts (unseen data): [263.   5.]\n",
      "rule chisq p-value (unseen data): 1.643257992796105e-14\n",
      "rule Kullback-Leibler divergence (unseen data): 0.1894407878655745\n",
      "Evaluation Time: 2.9737596190025215\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A14 False AND amt <= 7660.23034\n",
      "rule coverage (training data): 0.550641940085592\n",
      "rule xcoverage (training data): 0.5490753911806543\n",
      "rule precision (training data): 0.6675324675324675\n",
      "rule stability (training data): 0.6649484536082474\n",
      "rule recall (training data): 0.4759259259259259\n",
      "rule f1 score (training data): 0.5556756756756757\n",
      "rule NPV (training data): 0.2\n",
      "rule lift (training data): 1.5733088460361186\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.66753247 0.33246753]\n",
      "rule posterior counts (training data): [257. 128.]\n",
      "rule chisq p-value (training data): 0.00027648008615534437\n",
      "rule Kullback-Leibler divergence from original: 0.4041671950249784\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [658.  42.]\n",
      "proba: [0.94 0.06]\n",
      "\n",
      "Feature Reversed: amt_less_than_upper_bound\n",
      "rule: chk_A14 True AND amt > 7660.23034\n",
      "rule coverage (training data): 0.025677603423680456\n",
      "rule xcoverage (training data): 0.025604551920341393\n",
      "rule precision (training data): 0.5294117647058824\n",
      "rule stability (training data): 0.5\n",
      "rule recall (training data): 0.016666666666666666\n",
      "rule f1 score (training data): 0.03231597845601436\n",
      "rule NPV (training data): 0.95\n",
      "rule lift (training data): 28.25836216839677\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.52941176 0.47058824]\n",
      "rule posterior counts (training data): [9. 8.]\n",
      "rule chisq p-value (training data): 0.04154989679462894\n",
      "rule Kullback-Leibler divergence from original: 0.6359871446557852\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [548. 152.]\n",
      "proba: [0.78285714 0.21714286]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [548. 152.]\n",
      "proba: [0.78285714 0.21714286]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 138 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.659375\n",
      "forest vote margin (unseen instance): 0.31875000000000003\n",
      "confidence weighted forest vote share (unseen instance): 0.7072838914712481\n",
      "confidence weighted forest vote margin (unseen instance): 0.4145677829424963\n",
      "\n",
      "rule: debt_A103 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.046917781891267676\n",
      "Fraction of total weight of rule: 0.031007482091632683\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.0456490727532097\n",
      "rule xcoverage (unseen data): 0.04551920341394026\n",
      "rule precision (unseen data): 0.9354838709677419\n",
      "rule stability (unseen data): 0.8823529411764706\n",
      "rule recall (unseen data): 0.053703703703703705\n",
      "rule f1 score (unseen data): 0.10157618213660247\n",
      "rule NPV (unseen data): 0.9875\n",
      "rule lift (unseen data): 27.382741742783367\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.93548387 0.06451613]\n",
      "rule posterior counts (unseen data): [29.  2.]\n",
      "rule chisq p-value (unseen data): 0.053463369960037456\n",
      "rule Kullback-Leibler divergence (unseen data): 0.09877116279752787\n",
      "Evaluation Time: 1.4454940849973354\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: debt\n",
      "rule: debt_A103 False\n",
      "rule coverage (training data): 0.9557774607703281\n",
      "rule xcoverage (training data): 0.9530583214793741\n",
      "rule precision (training data): 0.7638266068759342\n",
      "rule stability (training data): 0.7619047619047619\n",
      "rule recall (training data): 0.9462962962962963\n",
      "rule f1 score (training data): 0.8453267162944581\n",
      "rule NPV (training data): 0.0125\n",
      "rule lift (training data): 1.0360267878237495\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.76382661 0.23617339]\n",
      "rule posterior counts (training data): [511. 158.]\n",
      "rule chisq p-value (training data): 0.7879840997846265\n",
      "rule Kullback-Leibler divergence from original: 0.10592478832376419\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 834 with true class label: 1 (bad)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.566875\n",
      "forest vote margin (unseen instance): 0.13375000000000004\n",
      "confidence weighted forest vote share (unseen instance): 0.59409288039074\n",
      "confidence weighted forest vote margin (unseen instance): 0.18818576078147958\n",
      "\n",
      "rule: chk_A13 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.07111993080483947\n",
      "Fraction of total weight of rule: 0.046035686125636195\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.07703281027104136\n",
      "rule xcoverage (unseen data): 0.07681365576102418\n",
      "rule precision (unseen data): 0.9811320754716981\n",
      "rule stability (unseen data): 0.9464285714285714\n",
      "rule recall (unseen data): 0.0962962962962963\n",
      "rule f1 score (unseen data): 0.1753794266441821\n",
      "rule NPV (unseen data): 0.99375\n",
      "rule lift (unseen data): 16.797858734490987\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.98113208 0.01886792]\n",
      "rule posterior counts (unseen data): [52.  1.]\n",
      "rule chisq p-value (unseen data): 0.0006344559809018979\n",
      "rule Kullback-Leibler divergence (unseen data): 0.18886193422291037\n",
      "Evaluation Time: 2.535574573004851\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A13 False\n",
      "rule coverage (training data): 0.9243937232524965\n",
      "rule xcoverage (training data): 0.9217638691322901\n",
      "rule precision (training data): 0.7542503863987635\n",
      "rule stability (training data): 0.7523076923076923\n",
      "rule recall (training data): 0.9037037037037037\n",
      "rule f1 score (training data): 0.8222409435551812\n",
      "rule NPV (training data): 0.00625\n",
      "rule lift (training data): 1.0578244013263327\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.75425039 0.24574961]\n",
      "rule posterior counts (training data): [488. 159.]\n",
      "rule chisq p-value (training data): 0.4985465552099221\n",
      "rule Kullback-Leibler divergence from original: 0.2095895918413046\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 328 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.4975\n",
      "forest vote margin (unseen instance): -0.004999999999999949\n",
      "confidence weighted forest vote share (unseen instance): 0.4356807285657177\n",
      "confidence weighted forest vote margin (unseen instance): -0.12863854286856347\n",
      "\n",
      "rule: chk_A13 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.06292643007197037\n",
      "Fraction of total weight of rule: 0.04179123415546814\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.07703281027104136\n",
      "rule xcoverage (unseen data): 0.07681365576102418\n",
      "rule precision (unseen data): 0.9811320754716981\n",
      "rule stability (unseen data): 0.9464285714285714\n",
      "rule recall (unseen data): 0.0962962962962963\n",
      "rule f1 score (unseen data): 0.1753794266441821\n",
      "rule NPV (unseen data): 0.99375\n",
      "rule lift (unseen data): 16.797858734490987\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.98113208 0.01886792]\n",
      "rule posterior counts (unseen data): [52.  1.]\n",
      "rule chisq p-value (unseen data): 0.0006344559809018979\n",
      "rule Kullback-Leibler divergence (unseen data): 0.1888618675551068\n",
      "Evaluation Time: 2.5091774459942826\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A13 False\n",
      "rule coverage (training data): 0.9243937232524965\n",
      "rule xcoverage (training data): 0.9217638691322901\n",
      "rule precision (training data): 0.7542503863987635\n",
      "rule stability (training data): 0.7523076923076923\n",
      "rule recall (training data): 0.9037037037037037\n",
      "rule f1 score (training data): 0.8222409435551812\n",
      "rule NPV (training data): 0.00625\n",
      "rule lift (training data): 1.0578244013263327\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.75425039 0.24574961]\n",
      "rule posterior counts (training data): [488. 159.]\n",
      "rule chisq p-value (training data): 0.4985465552099221\n",
      "rule Kullback-Leibler divergence from original: 0.20958947303156672\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [313. 387.]\n",
      "proba: [0.44714286 0.55285714]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [313. 387.]\n",
      "proba: [0.44714286 0.55285714]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 655 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 1 (bad)\n",
      "target class prior (training data): 0.22857142857142856\n",
      "forest vote share (unseen instance): 0.525625\n",
      "forest vote margin (unseen instance): 0.05125000000000002\n",
      "confidence weighted forest vote share (unseen instance): 0.6176404256788617\n",
      "confidence weighted forest vote margin (unseen instance): 0.2352808513577233\n",
      "\n",
      "rule: chk_A11 True AND age <= 25.23626 AND dur > 9.5\n",
      "rule cardinality: 3\n",
      "Fraction of total points of rule: 0.15191603511178955\n",
      "Fraction of total weight of rule: 0.1305515204601579\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.22857142857142856\n",
      "rule coverage (unseen data): 0.05706134094151213\n",
      "rule xcoverage (unseen data): 0.05689900426742532\n",
      "rule precision (unseen data): 0.6923076923076923\n",
      "rule stability (unseen data): 0.6666666666666666\n",
      "rule recall (unseen data): 0.16875\n",
      "rule f1 score (unseen data): 0.271356783919598\n",
      "rule NPV (unseen data): 0.9777777777777777\n",
      "rule lift (unseen data): 54.36390532544379\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.30769231 0.69230769]\n",
      "rule posterior counts (unseen data): [12. 27.]\n",
      "rule chisq p-value (unseen data): 3.0957960824738285e-10\n",
      "rule Kullback-Leibler divergence (unseen data): 0.48438902396340533\n",
      "Evaluation Time: 3.1818740219969186\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A11 False AND age <= 25.23626 AND dur > 9.5\n",
      "rule coverage (training data): 0.10841654778887304\n",
      "rule xcoverage (training data): 0.10810810810810811\n",
      "rule precision (training data): 0.26666666666666666\n",
      "rule stability (training data): 0.2692307692307692\n",
      "rule recall (training data): 0.125\n",
      "rule f1 score (training data): 0.1702127659574468\n",
      "rule NPV (training data): 0.8981481481481481\n",
      "rule lift (training data): 10.88888888888889\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.73333333 0.26666667]\n",
      "rule posterior counts (training data): [55. 20.]\n",
      "rule chisq p-value (training data): 0.5494033634760016\n",
      "rule Kullback-Leibler divergence from original: 0.3932521773556391\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [338. 362.]\n",
      "proba: [0.48285714 0.51714286]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [370. 330.]\n",
      "proba: [0.52857143 0.47142857]\n",
      "\n",
      "Feature Reversed: age_less_than_upper_bound\n",
      "rule: chk_A11 True AND age > 25.23626 AND dur > 9.5\n",
      "rule coverage (training data): 0.16547788873038516\n",
      "rule xcoverage (training data): 0.16500711237553342\n",
      "rule precision (training data): 0.4956521739130435\n",
      "rule stability (training data): 0.4915254237288136\n",
      "rule recall (training data): 0.35625\n",
      "rule f1 score (training data): 0.41454545454545455\n",
      "rule NPV (training data): 0.8925925925925926\n",
      "rule lift (training data): 13.19943289224953\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.50434783 0.49565217]\n",
      "rule posterior counts (training data): [58. 57.]\n",
      "rule chisq p-value (training data): 3.826245641506993e-09\n",
      "rule Kullback-Leibler divergence from original: 0.07928778513204807\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [556. 144.]\n",
      "proba: [0.79428571 0.20571429]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [199. 501.]\n",
      "proba: [0.28428571 0.71571429]\n",
      "\n",
      "Feature Reversed: dur_greater_than_lower_bound\n",
      "rule: chk_A11 True AND age <= 25.23626 AND dur <= 9.5\n",
      "rule coverage (training data): 0.007132667617689016\n",
      "rule xcoverage (training data): 0.007112375533428165\n",
      "rule precision (training data): 0.25\n",
      "rule stability (training data): 0.2857142857142857\n",
      "rule recall (training data): 0.00625\n",
      "rule f1 score (training data): 0.012195121951219514\n",
      "rule NPV (training data): 0.9944444444444445\n",
      "rule lift (training data): 191.40625\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.75 0.25]\n",
      "rule posterior counts (training data): [3. 1.]\n",
      "rule chisq p-value (training data): 0.6204616253436679\n",
      "rule Kullback-Leibler divergence from original: 0.4310178504111062\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [329. 371.]\n",
      "proba: [0.47 0.53]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 581 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.568125\n",
      "forest vote margin (unseen instance): 0.13624999999999998\n",
      "confidence weighted forest vote share (unseen instance): 0.5381942210979074\n",
      "confidence weighted forest vote margin (unseen instance): 0.07638844219581409\n",
      "\n",
      "rule: dur <= 16.68939\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.12892739526831545\n",
      "Fraction of total weight of rule: 0.10414612880396862\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.44935805991440797\n",
      "rule xcoverage (unseen data): 0.4480796586059744\n",
      "rule precision (unseen data): 0.8853503184713376\n",
      "rule stability (unseen data): 0.8801261829652997\n",
      "rule recall (unseen data): 0.5148148148148148\n",
      "rule f1 score (unseen data): 0.6510538641686183\n",
      "rule NPV (unseen data): 0.775\n",
      "rule lift (unseen data): 2.5585141309917163\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.88535032 0.11464968]\n",
      "rule posterior counts (unseen data): [278.  36.]\n",
      "rule chisq p-value (unseen data): 3.1614799882268154e-05\n",
      "rule Kullback-Leibler divergence (unseen data): 0.042843012793946936\n",
      "Evaluation Time: 2.886638762000075\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: dur_less_than_upper_bound\n",
      "rule: dur > 16.68939\n",
      "rule coverage (training data): 0.5520684736091298\n",
      "rule xcoverage (training data): 0.55049786628734\n",
      "rule precision (training data): 0.6787564766839378\n",
      "rule stability (training data): 0.6760925449871465\n",
      "rule recall (training data): 0.48518518518518516\n",
      "rule f1 score (training data): 0.5658747300215983\n",
      "rule NPV (training data): 0.225\n",
      "rule lift (training data): 1.595618276603001\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.67875648 0.32124352]\n",
      "rule posterior counts (training data): [262. 124.]\n",
      "rule chisq p-value (training data): 0.001137285484628379\n",
      "rule Kullback-Leibler divergence from original: 0.3361042145986317\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [612.  88.]\n",
      "proba: [0.87428571 0.12571429]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [612.  88.]\n",
      "proba: [0.87428571 0.12571429]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 478 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.581875\n",
      "forest vote margin (unseen instance): 0.16375\n",
      "confidence weighted forest vote share (unseen instance): 0.5961036237219571\n",
      "confidence weighted forest vote margin (unseen instance): 0.1922072474439131\n",
      "\n",
      "rule: chk_A11 False\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.14892824439265662\n",
      "Fraction of total weight of rule: 0.10910564652150785\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.7475035663338089\n",
      "rule xcoverage (unseen data): 0.7453769559032717\n",
      "rule precision (unseen data): 0.8604206500956023\n",
      "rule stability (unseen data): 0.8574144486692015\n",
      "rule recall (unseen data): 0.8333333333333334\n",
      "rule f1 score (unseen data): 0.8466603951081845\n",
      "rule NPV (unseen data): 0.54375\n",
      "rule lift (unseen data): 1.4928337884953087\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.86042065 0.13957935]\n",
      "rule posterior counts (unseen data): [450.  73.]\n",
      "rule chisq p-value (unseen data): 0.00011949572817684962\n",
      "rule Kullback-Leibler divergence (unseen data): 0.02509573073780043\n",
      "Evaluation Time: 2.991198166993854\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A11 True\n",
      "rule coverage (training data): 0.25392296718972895\n",
      "rule xcoverage (training data): 0.2532005689900427\n",
      "rule precision (training data): 0.5084745762711864\n",
      "rule stability (training data): 0.5055555555555555\n",
      "rule recall (training data): 0.16666666666666666\n",
      "rule f1 score (training data): 0.2510460251046025\n",
      "rule NPV (training data): 0.45625\n",
      "rule lift (training data): 2.606743485801228\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.50847458 0.49152542]\n",
      "rule posterior counts (training data): [90. 87.]\n",
      "rule chisq p-value (training data): 7.128044900321125e-12\n",
      "rule Kullback-Leibler divergence from original: 0.6763385115065655\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE RESULTS\n",
      "instance id: 195 with true class label: 1 (bad)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.575625\n",
      "forest vote margin (unseen instance): 0.15125000000000005\n",
      "confidence weighted forest vote share (unseen instance): 0.5488346163776414\n",
      "confidence weighted forest vote margin (unseen instance): 0.09766923275528189\n",
      "\n",
      "rule: dur <= 13.14394\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.16211936505188063\n",
      "Fraction of total weight of rule: 0.14945363773208165\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.3780313837375178\n",
      "rule xcoverage (unseen data): 0.37695590327169276\n",
      "rule precision (unseen data): 0.8939393939393939\n",
      "rule stability (unseen data): 0.8876404494382022\n",
      "rule recall (unseen data): 0.43703703703703706\n",
      "rule f1 score (unseen data): 0.5870646766169154\n",
      "rule NPV (unseen data): 0.825\n",
      "rule lift (unseen data): 3.072603135734448\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.89393939 0.10606061]\n",
      "rule posterior counts (unseen data): [236.  28.]\n",
      "rule chisq p-value (unseen data): 2.790222659122365e-05\n",
      "rule Kullback-Leibler divergence (unseen data): 0.05032384757222487\n",
      "Evaluation Time: 3.4685083010044764\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: dur_less_than_upper_bound\n",
      "rule: dur > 13.14394\n",
      "rule coverage (training data): 0.62339514978602\n",
      "rule xcoverage (training data): 0.6216216216216216\n",
      "rule precision (training data): 0.6972477064220184\n",
      "rule stability (training data): 0.6947608200455581\n",
      "rule recall (training data): 0.562962962962963\n",
      "rule f1 score (training data): 0.6229508196721312\n",
      "rule NPV (training data): 0.175\n",
      "rule lift (training data): 1.4511186550577173\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.69724771 0.30275229]\n",
      "rule posterior counts (training data): [304. 132.]\n",
      "rule chisq p-value (training data): 0.006676998872221508\n",
      "rule Kullback-Leibler divergence from original: 0.30384532423832133\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [486. 214.]\n",
      "proba: [0.69428571 0.30571429]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [486. 214.]\n",
      "proba: [0.69428571 0.30571429]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 221 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 1 (bad)\n",
      "target class prior (training data): 0.22857142857142856\n",
      "forest vote share (unseen instance): 0.559375\n",
      "forest vote margin (unseen instance): 0.11874999999999997\n",
      "confidence weighted forest vote share (unseen instance): 0.6572810933454551\n",
      "confidence weighted forest vote margin (unseen instance): 0.31456218669090924\n",
      "\n",
      "rule: chk_A11 True AND pers_A92 True AND crhis_A34 False AND emp_A75 False AND debt_A103 False\n",
      "rule cardinality: 5\n",
      "Fraction of total points of rule: 0.12858675617794685\n",
      "Fraction of total weight of rule: 0.1108915949930777\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.22857142857142856\n",
      "rule coverage (unseen data): 0.05848787446504993\n",
      "rule xcoverage (unseen data): 0.05832147937411095\n",
      "rule precision (unseen data): 0.75\n",
      "rule stability (unseen data): 0.7209302325581395\n",
      "rule recall (unseen data): 0.1875\n",
      "rule f1 score (unseen data): 0.3\n",
      "rule NPV (unseen data): 0.9814814814814815\n",
      "rule lift (unseen data): 57.42187500000001\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.25 0.75]\n",
      "rule posterior counts (unseen data): [10. 30.]\n",
      "rule chisq p-value (unseen data): 8.293285443834835e-13\n",
      "rule Kullback-Leibler divergence (unseen data): 0.6094724634095476\n",
      "Evaluation Time: 3.7638157019973733\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A11 False AND pers_A92 True AND crhis_A34 False AND emp_A75 False AND debt_A103 False\n",
      "rule coverage (training data): 0.15121255349500715\n",
      "rule xcoverage (training data): 0.1507823613086771\n",
      "rule precision (training data): 0.17142857142857143\n",
      "rule stability (training data): 0.17592592592592593\n",
      "rule recall (training data): 0.1125\n",
      "rule f1 score (training data): 0.1358490566037736\n",
      "rule NPV (training data): 0.8388888888888889\n",
      "rule lift (training data): 5.000000000000001\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.82857143 0.17142857]\n",
      "rule posterior counts (training data): [87. 18.]\n",
      "rule chisq p-value (training data): 0.23419575486367805\n",
      "rule Kullback-Leibler divergence from original: 0.8073692373694044\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [466. 234.]\n",
      "proba: [0.66571429 0.33428571]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [456. 244.]\n",
      "proba: [0.65142857 0.34857143]\n",
      "\n",
      "Feature Reversed: pers\n",
      "rule: chk_A11 True AND pers_A92 False AND crhis_A34 False AND emp_A75 False AND debt_A103 False\n",
      "rule coverage (training data): 0.09557774607703282\n",
      "rule xcoverage (training data): 0.0953058321479374\n",
      "rule precision (training data): 0.5909090909090909\n",
      "rule stability (training data): 0.5797101449275363\n",
      "rule recall (training data): 0.24375\n",
      "rule f1 score (training data): 0.34513274336283184\n",
      "rule NPV (training data): 0.95\n",
      "rule lift (training data): 27.419077134986225\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.40909091 0.59090909]\n",
      "rule posterior counts (training data): [27. 39.]\n",
      "rule chisq p-value (training data): 3.6066525668922964e-10\n",
      "rule Kullback-Leibler divergence from original: 0.0556891360880465\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "Feature Reversed: crhis\n",
      "rule: chk_A11 True AND pers_A92 True AND crhis_A34 True AND emp_A75 False AND debt_A103 False\n",
      "rule coverage (training data): 0.015691868758915834\n",
      "rule xcoverage (training data): 0.015647226173541962\n",
      "rule precision (training data): 0.5\n",
      "rule stability (training data): 0.46153846153846156\n",
      "rule recall (training data): 0.03125\n",
      "rule f1 score (training data): 0.058823529411764705\n",
      "rule NPV (training data): 0.9907407407407407\n",
      "rule lift (training data): 153.12500000000003\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.5 0.5]\n",
      "rule posterior counts (training data): [5. 5.]\n",
      "rule chisq p-value (training data): 0.1008289222082264\n",
      "rule Kullback-Leibler divergence from original: 0.1308120213433284\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "Feature Reversed: emp\n",
      "rule: chk_A11 True AND pers_A92 True AND crhis_A34 False AND emp_A75 True AND debt_A103 False\n",
      "rule coverage (training data): 0.005706134094151213\n",
      "rule xcoverage (training data): 0.005689900426742532\n",
      "rule precision (training data): 0.3333333333333333\n",
      "rule stability (training data): 0.3333333333333333\n",
      "rule recall (training data): 0.00625\n",
      "rule f1 score (training data): 0.01226993865030675\n",
      "rule NPV (training data): 0.9962962962962963\n",
      "rule lift (training data): 340.27777777777777\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.66666667 0.33333333]\n",
      "rule posterior counts (training data): [2. 1.]\n",
      "rule chisq p-value (training data): 0.7967452356146236\n",
      "rule Kullback-Leibler divergence from original: 0.3629902260277481\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "Feature Reversed: debt\n",
      "rule: chk_A11 True AND pers_A92 True AND crhis_A34 False AND emp_A75 False AND debt_A103 True\n",
      "rule coverage (training data): 0.005706134094151213\n",
      "rule xcoverage (training data): 0.005689900426742532\n",
      "rule precision (training data): 0.0\n",
      "rule stability (training data): 0.16666666666666666\n",
      "rule recall (training data): 0.0\n",
      "rule f1 score (training data): 0.0\n",
      "rule NPV (training data): 0.9944444444444445\n",
      "rule lift (training data): 0.0\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [1. 0.]\n",
      "rule posterior counts (training data): [3. 0.]\n",
      "rule chisq p-value (training data): 0.8008567833530595\n",
      "rule Kullback-Leibler divergence from original: 12.084322802868318\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [259. 441.]\n",
      "proba: [0.37 0.63]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 209 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.71375\n",
      "forest vote margin (unseen instance): 0.4275\n",
      "confidence weighted forest vote share (unseen instance): 0.8294088995547078\n",
      "confidence weighted forest vote margin (unseen instance): 0.6588177991094151\n",
      "\n",
      "rule: svng_A64 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.06938853791729446\n",
      "Fraction of total weight of rule: 0.054675405091459885\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.052781740370898715\n",
      "rule xcoverage (unseen data): 0.05263157894736842\n",
      "rule precision (unseen data): 0.9722222222222222\n",
      "rule stability (unseen data): 0.9230769230769231\n",
      "rule recall (unseen data): 0.06481481481481481\n",
      "rule f1 score (unseen data): 0.12152777777777778\n",
      "rule NPV (unseen data): 0.99375\n",
      "rule lift (unseen data): 24.505601280292638\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.97222222 0.02777778]\n",
      "rule posterior counts (unseen data): [35.  1.]\n",
      "rule chisq p-value (unseen data): 0.00840333185183688\n",
      "rule Kullback-Leibler divergence (unseen data): 0.16636934601355274\n",
      "Evaluation Time: 2.3458698470058152\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: svng\n",
      "rule: svng_A64 False\n",
      "rule coverage (training data): 0.948644793152639\n",
      "rule xcoverage (training data): 0.9459459459459459\n",
      "rule precision (training data): 0.7605421686746988\n",
      "rule stability (training data): 0.7586206896551724\n",
      "rule recall (training data): 0.9351851851851852\n",
      "rule f1 score (training data): 0.8388704318936878\n",
      "rule NPV (training data): 0.00625\n",
      "rule lift (training data): 1.0393397552727643\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.76054217 0.23945783]\n",
      "rule posterior counts (training data): [505. 159.]\n",
      "rule chisq p-value (training data): 0.6812428035882169\n",
      "rule Kullback-Leibler divergence from original: 0.17889458904880726\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 378 with true class label: 1 (bad)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 1 (bad)\n",
      "target class prior (training data): 0.22857142857142856\n",
      "forest vote share (unseen instance): 0.594375\n",
      "forest vote margin (unseen instance): 0.18874999999999997\n",
      "confidence weighted forest vote share (unseen instance): 0.6733506066710532\n",
      "confidence weighted forest vote margin (unseen instance): 0.346701213342106\n",
      "\n",
      "rule: amt > 11725.47059 AND emp_A74 False\n",
      "rule cardinality: 2\n",
      "Fraction of total points of rule: 0.11712458000648203\n",
      "Fraction of total weight of rule: 0.073129386913114\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.22857142857142856\n",
      "rule coverage (unseen data): 0.017118402282453638\n",
      "rule xcoverage (unseen data): 0.017069701280227598\n",
      "rule precision (unseen data): 0.9090909090909091\n",
      "rule stability (unseen data): 0.7857142857142857\n",
      "rule recall (unseen data): 0.0625\n",
      "rule f1 score (unseen data): 0.11695906432748537\n",
      "rule NPV (unseen data): 0.9981481481481481\n",
      "rule lift (unseen data): 253.099173553719\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.09090909 0.90909091]\n",
      "rule posterior counts (unseen data): [ 1. 10.]\n",
      "rule chisq p-value (unseen data): 9.867958380321785e-07\n",
      "rule Kullback-Leibler divergence (unseen data): 1.0606888283319629\n",
      "Evaluation Time: 2.522016064998752\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: amt_greater_than_lower_bound\n",
      "rule: amt <= 11725.47059 AND emp_A74 False\n",
      "rule coverage (training data): 0.8088445078459344\n",
      "rule xcoverage (training data): 0.8065433854907539\n",
      "rule precision (training data): 0.22791519434628976\n",
      "rule stability (training data): 0.22847100175746923\n",
      "rule recall (training data): 0.80625\n",
      "rule f1 score (training data): 0.3553719008264463\n",
      "rule NPV (training data): 0.19074074074074074\n",
      "rule lift (training data): 1.2331983793030254\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.77208481 0.22791519]\n",
      "rule posterior counts (training data): [437. 129.]\n",
      "rule chisq p-value (training data): 0.9683482043871003\n",
      "rule Kullback-Leibler divergence from original: 1.0632251025220127\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [ 95. 605.]\n",
      "proba: [0.13571429 0.86428571]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [ 36. 664.]\n",
      "proba: [0.05142857 0.94857143]\n",
      "\n",
      "Feature Reversed: emp\n",
      "rule: amt > 11725.47059 AND emp_A74 True\n",
      "rule coverage (training data): 0.005706134094151213\n",
      "rule xcoverage (training data): 0.005689900426742532\n",
      "rule precision (training data): 0.3333333333333333\n",
      "rule stability (training data): 0.3333333333333333\n",
      "rule recall (training data): 0.00625\n",
      "rule f1 score (training data): 0.01226993865030675\n",
      "rule NPV (training data): 0.9962962962962963\n",
      "rule lift (training data): 340.27777777777777\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.66666667 0.33333333]\n",
      "rule posterior counts (training data): [2. 1.]\n",
      "rule chisq p-value (training data): 0.7967452356146236\n",
      "rule Kullback-Leibler divergence from original: 0.7309624780965736\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 156 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.62125\n",
      "forest vote margin (unseen instance): 0.2425\n",
      "confidence weighted forest vote share (unseen instance): 0.6191995307062359\n",
      "confidence weighted forest vote margin (unseen instance): 0.23839906141247152\n",
      "\n",
      "rule: dur <= 11.8125\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.09619538912249552\n",
      "Fraction of total weight of rule: 0.07705367055126326\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.18830242510699002\n",
      "rule xcoverage (unseen data): 0.18776671408250356\n",
      "rule precision (unseen data): 0.9618320610687023\n",
      "rule stability (unseen data): 0.9477611940298507\n",
      "rule recall (unseen data): 0.23333333333333334\n",
      "rule f1 score (unseen data): 0.37555886736214605\n",
      "rule NPV (unseen data): 0.96875\n",
      "rule lift (unseen data): 6.662393411417361\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.96183206 0.03816794]\n",
      "rule posterior counts (unseen data): [126.   5.]\n",
      "rule chisq p-value (unseen data): 9.848433256805366e-07\n",
      "rule Kullback-Leibler divergence (unseen data): 0.1438609570644751\n",
      "Evaluation Time: 3.183545415995468\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: dur_less_than_upper_bound\n",
      "rule: dur > 11.8125\n",
      "rule coverage (training data): 0.8131241084165478\n",
      "rule xcoverage (training data): 0.8108108108108109\n",
      "rule precision (training data): 0.7275922671353251\n",
      "rule stability (training data): 0.7255244755244755\n",
      "rule recall (training data): 0.7666666666666667\n",
      "rule f1 score (training data): 0.7466185752930569\n",
      "rule NPV (training data): 0.03125\n",
      "rule lift (training data): 1.1603209363285467\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.72759227 0.27240773]\n",
      "rule posterior counts (training data): [414. 155.]\n",
      "rule chisq p-value (training data): 0.08319101436578318\n",
      "rule Kullback-Leibler divergence from original: 0.26654652946183727\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE RESULTS\n",
      "instance id: 327 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.58\n",
      "forest vote margin (unseen instance): 0.15999999999999998\n",
      "confidence weighted forest vote share (unseen instance): 0.6432723737018423\n",
      "confidence weighted forest vote margin (unseen instance): 0.2865447474036838\n",
      "\n",
      "rule: svng_A64 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.07025762177877748\n",
      "Fraction of total weight of rule: 0.05175484457960335\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.052781740370898715\n",
      "rule xcoverage (unseen data): 0.05263157894736842\n",
      "rule precision (unseen data): 0.9722222222222222\n",
      "rule stability (unseen data): 0.9230769230769231\n",
      "rule recall (unseen data): 0.06481481481481481\n",
      "rule f1 score (unseen data): 0.12152777777777778\n",
      "rule NPV (unseen data): 0.99375\n",
      "rule lift (unseen data): 24.505601280292638\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.97222222 0.02777778]\n",
      "rule posterior counts (unseen data): [35.  1.]\n",
      "rule chisq p-value (unseen data): 0.00840333185183688\n",
      "rule Kullback-Leibler divergence (unseen data): 0.16636932315698905\n",
      "Evaluation Time: 2.1787032100037322\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: svng\n",
      "rule: svng_A64 False\n",
      "rule coverage (training data): 0.948644793152639\n",
      "rule xcoverage (training data): 0.9459459459459459\n",
      "rule precision (training data): 0.7605421686746988\n",
      "rule stability (training data): 0.7586206896551724\n",
      "rule recall (training data): 0.9351851851851852\n",
      "rule f1 score (training data): 0.8388704318936878\n",
      "rule NPV (training data): 0.00625\n",
      "rule lift (training data): 1.0393397552727643\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.76054217 0.23945783]\n",
      "rule posterior counts (training data): [505. 159.]\n",
      "rule chisq p-value (training data): 0.6812428035882169\n",
      "rule Kullback-Leibler divergence from original: 0.17889466399362675\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 901 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.634375\n",
      "forest vote margin (unseen instance): 0.26875000000000004\n",
      "confidence weighted forest vote share (unseen instance): 0.651907113582012\n",
      "confidence weighted forest vote margin (unseen instance): 0.3038142271640233\n",
      "\n",
      "rule: chk_A14 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.12929116581594347\n",
      "Fraction of total weight of rule: 0.11233689571381035\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.4079885877318117\n",
      "rule xcoverage (unseen data): 0.406827880512091\n",
      "rule precision (unseen data): 0.9543859649122807\n",
      "rule stability (unseen data): 0.9479166666666666\n",
      "rule recall (unseen data): 0.5037037037037037\n",
      "rule f1 score (unseen data): 0.6593939393939393\n",
      "rule NPV (unseen data): 0.91875\n",
      "rule lift (unseen data): 3.0386557687265596\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.95438596 0.04561404]\n",
      "rule posterior counts (unseen data): [272.  13.]\n",
      "rule chisq p-value (unseen data): 1.472950609816159e-11\n",
      "rule Kullback-Leibler divergence (unseen data): 0.12960314851554391\n",
      "Evaluation Time: 3.2772796130011557\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A14 False\n",
      "rule coverage (training data): 0.5934379457917262\n",
      "rule xcoverage (training data): 0.5917496443812233\n",
      "rule precision (training data): 0.6457831325301204\n",
      "rule stability (training data): 0.6435406698564593\n",
      "rule recall (training data): 0.4962962962962963\n",
      "rule f1 score (training data): 0.5612565445026177\n",
      "rule NPV (training data): 0.08125\n",
      "rule lift (training data): 1.4120202362327487\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.64578313 0.35421687]\n",
      "rule posterior counts (training data): [268. 147.]\n",
      "rule chisq p-value (training data): 7.788053206075143e-06\n",
      "rule Kullback-Leibler divergence from original: 0.4372903125628355\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 320 with true class label: 1 (bad)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 1 (bad)\n",
      "target class prior (training data): 0.22857142857142856\n",
      "forest vote share (unseen instance): 0.563125\n",
      "forest vote margin (unseen instance): 0.12624999999999997\n",
      "confidence weighted forest vote share (unseen instance): 0.6712604411642721\n",
      "confidence weighted forest vote margin (unseen instance): 0.3425208823285446\n",
      "\n",
      "rule: dur > 28.5 AND chk_A12 True\n",
      "rule cardinality: 2\n",
      "Fraction of total points of rule: 0.1504022376129984\n",
      "Fraction of total weight of rule: 0.10557205257728658\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.22857142857142856\n",
      "rule coverage (unseen data): 0.06419400855920114\n",
      "rule xcoverage (unseen data): 0.06401137980085349\n",
      "rule precision (unseen data): 0.6590909090909091\n",
      "rule stability (unseen data): 0.6382978723404256\n",
      "rule recall (unseen data): 0.18125\n",
      "rule f1 score (unseen data): 0.28431372549019607\n",
      "rule NPV (unseen data): 0.9722222222222222\n",
      "rule lift (unseen data): 45.87422520661157\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.34090909 0.65909091]\n",
      "rule posterior counts (unseen data): [15. 29.]\n",
      "rule chisq p-value (unseen data): 6.221728453093667e-10\n",
      "rule Kullback-Leibler divergence (unseen data): 0.41958956460265356\n",
      "Evaluation Time: 3.1864347780065145\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: dur_greater_than_lower_bound\n",
      "rule: dur <= 28.5 AND chk_A12 True\n",
      "rule coverage (training data): 0.20256776034236804\n",
      "rule xcoverage (training data): 0.2019914651493599\n",
      "rule precision (training data): 0.2127659574468085\n",
      "rule stability (training data): 0.2152777777777778\n",
      "rule recall (training data): 0.1875\n",
      "rule f1 score (training data): 0.1993355481727575\n",
      "rule NPV (training data): 0.7944444444444444\n",
      "rule lift (training data): 4.621246416176248\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.78723404 0.21276596]\n",
      "rule posterior counts (training data): [111.  30.]\n",
      "rule chisq p-value (training data): 0.7648794870715684\n",
      "rule Kullback-Leibler divergence from original: 0.4599032444230151\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [385. 315.]\n",
      "proba: [0.55 0.45]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [385. 315.]\n",
      "proba: [0.55 0.45]\n",
      "\n",
      "Feature Reversed: chk\n",
      "rule: dur > 28.5 AND chk_A12 False\n",
      "rule coverage (training data): 0.12125534950071326\n",
      "rule xcoverage (training data): 0.12091038406827881\n",
      "rule precision (training data): 0.35714285714285715\n",
      "rule stability (training data): 0.3563218390804598\n",
      "rule recall (training data): 0.1875\n",
      "rule f1 score (training data): 0.24590163934426226\n",
      "rule NPV (training data): 0.9\n",
      "rule lift (training data): 13.020833333333334\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.64285714 0.35714286]\n",
      "rule posterior counts (training data): [54. 30.]\n",
      "rule chisq p-value (training data): 0.013749044050135837\n",
      "rule Kullback-Leibler divergence from original: 0.18760100207208882\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [377. 323.]\n",
      "proba: [0.53857143 0.46142857]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [287. 413.]\n",
      "proba: [0.41 0.59]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 274 with true class label: 1 (bad)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 1 (bad)\n",
      "target class prior (training data): 0.22857142857142856\n",
      "forest vote share (unseen instance): 0.610625\n",
      "forest vote margin (unseen instance): 0.22124999999999995\n",
      "confidence weighted forest vote share (unseen instance): 0.7127918443423727\n",
      "confidence weighted forest vote margin (unseen instance): 0.425583688684744\n",
      "\n",
      "rule: amt > 11262.48077\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.09946290576359922\n",
      "Fraction of total weight of rule: 0.06267639293705192\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.22857142857142856\n",
      "rule coverage (unseen data): 0.02282453637660485\n",
      "rule xcoverage (unseen data): 0.02275960170697013\n",
      "rule precision (unseen data): 0.8\n",
      "rule stability (unseen data): 0.7222222222222222\n",
      "rule recall (unseen data): 0.075\n",
      "rule f1 score (unseen data): 0.13714285714285715\n",
      "rule NPV (unseen data): 0.9944444444444445\n",
      "rule lift (unseen data): 163.33333333333334\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.2 0.8]\n",
      "rule posterior counts (unseen data): [ 3. 12.]\n",
      "rule chisq p-value (unseen data): 1.4501238952744817e-06\n",
      "rule Kullback-Leibler divergence (unseen data): 0.7322248011456673\n",
      "Evaluation Time: 0.9935751900047762\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: amt_greater_than_lower_bound\n",
      "rule: amt <= 11262.48077\n",
      "rule coverage (training data): 0.978601997146933\n",
      "rule xcoverage (training data): 0.9758179231863442\n",
      "rule precision (training data): 0.21605839416058395\n",
      "rule stability (training data): 0.21656976744186046\n",
      "rule recall (training data): 0.925\n",
      "rule f1 score (training data): 0.35029585798816565\n",
      "rule NPV (training data): 0.005555555555555556\n",
      "rule lift (training data): 0.965954499440567\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.78394161 0.21605839]\n",
      "rule posterior counts (training data): [537. 148.]\n",
      "rule chisq p-value (training data): 0.6204132858485366\n",
      "rule Kullback-Leibler divergence from original: 0.7740469156783207\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 417 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 1 (bad)\n",
      "target class prior (training data): 0.22857142857142856\n",
      "forest vote share (unseen instance): 0.565\n",
      "forest vote margin (unseen instance): 0.12999999999999995\n",
      "confidence weighted forest vote share (unseen instance): 0.6419395766640698\n",
      "confidence weighted forest vote margin (unseen instance): 0.2838791533281394\n",
      "\n",
      "rule: amt > 7968.1413 AND emp_A74 False AND pps_A41 False\n",
      "rule cardinality: 3\n",
      "Fraction of total points of rule: 0.11740726347195611\n",
      "Fraction of total weight of rule: 0.08552511876908173\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.22857142857142856\n",
      "rule coverage (unseen data): 0.037089871611982884\n",
      "rule xcoverage (unseen data): 0.03698435277382646\n",
      "rule precision (unseen data): 0.88\n",
      "rule stability (unseen data): 0.8214285714285714\n",
      "rule recall (unseen data): 0.1375\n",
      "rule f1 score (unseen data): 0.23783783783783785\n",
      "rule NPV (unseen data): 0.9944444444444445\n",
      "rule lift (unseen data): 107.80000000000001\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.12 0.88]\n",
      "rule posterior counts (unseen data): [ 3. 22.]\n",
      "rule chisq p-value (unseen data): 8.910708116449417e-13\n",
      "rule Kullback-Leibler divergence (unseen data): 0.9630137167271259\n",
      "Evaluation Time: 2.803789695004525\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: amt_greater_than_lower_bound\n",
      "rule: amt <= 7968.1413 AND emp_A74 False AND pps_A41 False\n",
      "rule coverage (training data): 0.7146932952924394\n",
      "rule xcoverage (training data): 0.7126600284495022\n",
      "rule precision (training data): 0.222\n",
      "rule stability (training data): 0.22266401590457258\n",
      "rule recall (training data): 0.69375\n",
      "rule f1 score (training data): 0.33636363636363636\n",
      "rule NPV (training data): 0.2796296296296296\n",
      "rule lift (training data): 1.3597500000000002\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.778 0.222]\n",
      "rule posterior counts (training data): [389. 111.]\n",
      "rule chisq p-value (training data): 0.8427423558150413\n",
      "rule Kullback-Leibler divergence from original: 0.98766681879811\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [ 41. 659.]\n",
      "proba: [0.05857143 0.94142857]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [233. 467.]\n",
      "proba: [0.33285714 0.66714286]\n",
      "\n",
      "Feature Reversed: emp\n",
      "rule: amt > 7968.1413 AND emp_A74 True AND pps_A41 False\n",
      "rule coverage (training data): 0.009985734664764621\n",
      "rule xcoverage (training data): 0.00995732574679943\n",
      "rule precision (training data): 0.16666666666666666\n",
      "rule stability (training data): 0.2222222222222222\n",
      "rule recall (training data): 0.00625\n",
      "rule f1 score (training data): 0.012048192771084338\n",
      "rule NPV (training data): 0.9907407407407407\n",
      "rule lift (training data): 85.06944444444444\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.83333333 0.16666667]\n",
      "rule posterior counts (training data): [5. 1.]\n",
      "rule chisq p-value (training data): 0.8975784040489545\n",
      "rule Kullback-Leibler divergence from original: 1.2317015858052738\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [213. 487.]\n",
      "proba: [0.30428571 0.69571429]\n",
      "\n",
      "Feature Reversed: pps\n",
      "rule: amt > 7968.1413 AND emp_A74 False AND pps_A41 True\n",
      "rule coverage (training data): 0.014265335235378032\n",
      "rule xcoverage (training data): 0.01422475106685633\n",
      "rule precision (training data): 0.3333333333333333\n",
      "rule stability (training data): 0.3333333333333333\n",
      "rule recall (training data): 0.01875\n",
      "rule f1 score (training data): 0.03550295857988166\n",
      "rule NPV (training data): 0.9888888888888889\n",
      "rule lift (training data): 113.42592592592592\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.66666667 0.33333333]\n",
      "rule posterior counts (training data): [6. 3.]\n",
      "rule chisq p-value (training data): 0.7311942635791682\n",
      "rule Kullback-Leibler divergence from original: 0.6485093994738024\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [472. 228.]\n",
      "proba: [0.67428571 0.32571429]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 372 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.595625\n",
      "forest vote margin (unseen instance): 0.19124999999999998\n",
      "confidence weighted forest vote share (unseen instance): 0.6453646935541697\n",
      "confidence weighted forest vote margin (unseen instance): 0.29072938710833957\n",
      "\n",
      "rule: chk_A14 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.13153748848623814\n",
      "Fraction of total weight of rule: 0.10907187636037934\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.4079885877318117\n",
      "rule xcoverage (unseen data): 0.406827880512091\n",
      "rule precision (unseen data): 0.9543859649122807\n",
      "rule stability (unseen data): 0.9479166666666666\n",
      "rule recall (unseen data): 0.5037037037037037\n",
      "rule f1 score (unseen data): 0.6593939393939393\n",
      "rule NPV (unseen data): 0.91875\n",
      "rule lift (unseen data): 3.0386557687265596\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.95438596 0.04561404]\n",
      "rule posterior counts (unseen data): [272.  13.]\n",
      "rule chisq p-value (unseen data): 1.472950609816159e-11\n",
      "rule Kullback-Leibler divergence (unseen data): 0.12960319931926986\n",
      "Evaluation Time: 2.810849818000861\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A14 False\n",
      "rule coverage (training data): 0.5934379457917262\n",
      "rule xcoverage (training data): 0.5917496443812233\n",
      "rule precision (training data): 0.6457831325301204\n",
      "rule stability (training data): 0.6435406698564593\n",
      "rule recall (training data): 0.4962962962962963\n",
      "rule f1 score (training data): 0.5612565445026177\n",
      "rule NPV (training data): 0.08125\n",
      "rule lift (training data): 1.4120202362327487\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.64578313 0.35421687]\n",
      "rule posterior counts (training data): [268. 147.]\n",
      "rule chisq p-value (training data): 7.788053206075143e-06\n",
      "rule Kullback-Leibler divergence from original: 0.4027417161729629\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE RESULTS\n",
      "instance id: 299 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.621875\n",
      "forest vote margin (unseen instance): 0.24374999999999997\n",
      "confidence weighted forest vote share (unseen instance): 0.6984271327115645\n",
      "confidence weighted forest vote margin (unseen instance): 0.3968542654231285\n",
      "\n",
      "rule: svng_A64 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.07586760547388684\n",
      "Fraction of total weight of rule: 0.052069916762445226\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.052781740370898715\n",
      "rule xcoverage (unseen data): 0.05263157894736842\n",
      "rule precision (unseen data): 0.9722222222222222\n",
      "rule stability (unseen data): 0.9230769230769231\n",
      "rule recall (unseen data): 0.06481481481481481\n",
      "rule f1 score (unseen data): 0.12152777777777778\n",
      "rule NPV (unseen data): 0.99375\n",
      "rule lift (unseen data): 24.505601280292638\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.97222222 0.02777778]\n",
      "rule posterior counts (unseen data): [35.  1.]\n",
      "rule chisq p-value (unseen data): 0.00840333185183688\n",
      "rule Kullback-Leibler divergence (unseen data): 0.16636928345910823\n",
      "Evaluation Time: 2.5899494819968822\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: svng\n",
      "rule: svng_A64 False\n",
      "rule coverage (training data): 0.948644793152639\n",
      "rule xcoverage (training data): 0.9459459459459459\n",
      "rule precision (training data): 0.7605421686746988\n",
      "rule stability (training data): 0.7586206896551724\n",
      "rule recall (training data): 0.9351851851851852\n",
      "rule f1 score (training data): 0.8388704318936878\n",
      "rule NPV (training data): 0.00625\n",
      "rule lift (training data): 1.0393397552727643\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.76054217 0.23945783]\n",
      "rule posterior counts (training data): [505. 159.]\n",
      "rule chisq p-value (training data): 0.6812428035882169\n",
      "rule Kullback-Leibler divergence from original: 0.1788944991580949\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 229 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 1 (bad)\n",
      "target class prior (training data): 0.22857142857142856\n",
      "forest vote share (unseen instance): 0.585625\n",
      "forest vote margin (unseen instance): 0.17124999999999996\n",
      "confidence weighted forest vote share (unseen instance): 0.6496354716287619\n",
      "confidence weighted forest vote margin (unseen instance): 0.299270943257523\n",
      "\n",
      "rule: chk_A11 True AND dur > 22.54545 AND tel_A191 True AND rate > 2.3333333333333335 AND job_A173 True\n",
      "rule cardinality: 5\n",
      "Fraction of total points of rule: 0.2046212353712159\n",
      "Fraction of total weight of rule: 0.1808699162982225\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.22857142857142856\n",
      "rule coverage (unseen data): 0.03138373751783167\n",
      "rule xcoverage (unseen data): 0.031294452347083924\n",
      "rule precision (unseen data): 0.9523809523809523\n",
      "rule stability (unseen data): 0.875\n",
      "rule recall (unseen data): 0.125\n",
      "rule f1 score (unseen data): 0.22099447513812154\n",
      "rule NPV (unseen data): 0.9981481481481481\n",
      "rule lift (unseen data): 138.88888888888889\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.04761905 0.95238095]\n",
      "rule posterior counts (unseen data): [ 1. 20.]\n",
      "rule chisq p-value (unseen data): 2.978859714073977e-13\n",
      "rule Kullback-Leibler divergence (unseen data): 1.226538512750765\n",
      "Evaluation Time: 3.5386220599975786\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A11 False AND dur > 22.54545 AND tel_A191 True AND rate > 2.3333333333333335 AND job_A173 True\n",
      "rule coverage (training data): 0.06276747503566334\n",
      "rule xcoverage (training data): 0.06258890469416785\n",
      "rule precision (training data): 0.20930232558139536\n",
      "rule stability (training data): 0.21739130434782608\n",
      "rule recall (training data): 0.05625\n",
      "rule f1 score (training data): 0.08866995073891626\n",
      "rule NPV (training data): 0.937037037037037\n",
      "rule lift (training data): 14.906706327744727\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.79069767 0.20930233]\n",
      "rule posterior counts (training data): [34.  9.]\n",
      "rule chisq p-value (training data): 0.9162359102665177\n",
      "rule Kullback-Leibler divergence from original: 1.3092388443537124\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [485. 215.]\n",
      "proba: [0.69285714 0.30714286]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [403. 297.]\n",
      "proba: [0.57571429 0.42428571]\n",
      "\n",
      "Feature Reversed: dur_greater_than_lower_bound\n",
      "rule: chk_A11 True AND dur <= 22.54545 AND tel_A191 True AND rate > 2.3333333333333335 AND job_A173 True\n",
      "rule coverage (training data): 0.04850213980028531\n",
      "rule xcoverage (training data): 0.04836415362731152\n",
      "rule precision (training data): 0.5454545454545454\n",
      "rule stability (training data): 0.5277777777777778\n",
      "rule recall (training data): 0.1125\n",
      "rule f1 score (training data): 0.18652849740932642\n",
      "rule NPV (training data): 0.9722222222222222\n",
      "rule lift (training data): 50.619834710743795\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.45454545 0.54545455]\n",
      "rule posterior counts (training data): [15. 18.]\n",
      "rule chisq p-value (training data): 8.118399269970722e-05\n",
      "rule Kullback-Leibler divergence from original: 0.4233736316249053\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [104. 596.]\n",
      "proba: [0.14857143 0.85142857]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [104. 596.]\n",
      "proba: [0.14857143 0.85142857]\n",
      "\n",
      "Feature Reversed: tel\n",
      "rule: chk_A11 True AND dur > 22.54545 AND tel_A191 False AND rate > 2.3333333333333335 AND job_A173 True\n",
      "rule coverage (training data): 0.021398002853067047\n",
      "rule xcoverage (training data): 0.021337126600284494\n",
      "rule precision (training data): 0.5\n",
      "rule stability (training data): 0.47058823529411764\n",
      "rule recall (training data): 0.04375\n",
      "rule f1 score (training data): 0.08045977011494253\n",
      "rule NPV (training data): 0.987037037037037\n",
      "rule lift (training data): 109.37499999999999\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.5 0.5]\n",
      "rule posterior counts (training data): [7. 7.]\n",
      "rule chisq p-value (training data): 0.03971182897909637\n",
      "rule Kullback-Leibler divergence from original: 0.5017028798006548\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "Feature Reversed: rate_greater_than_lower_bound\n",
      "rule: chk_A11 True AND dur > 22.54545 AND tel_A191 True AND rate <= 2.3333333333333335 AND job_A173 True\n",
      "rule coverage (training data): 0.019971469329529243\n",
      "rule xcoverage (training data): 0.01991465149359886\n",
      "rule precision (training data): 0.46153846153846156\n",
      "rule stability (training data): 0.4375\n",
      "rule recall (training data): 0.0375\n",
      "rule f1 score (training data): 0.06936416184971099\n",
      "rule NPV (training data): 0.987037037037037\n",
      "rule lift (training data): 108.72781065088758\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.53846154 0.46153846]\n",
      "rule posterior counts (training data): [7. 6.]\n",
      "rule chisq p-value (training data): 0.10139185480944686\n",
      "rule Kullback-Leibler divergence from original: 0.5744050066885331\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "Feature Reversed: job\n",
      "rule: chk_A11 True AND dur > 22.54545 AND tel_A191 True AND rate > 2.3333333333333335 AND job_A173 False\n",
      "rule coverage (training data): 0.008559201141226819\n",
      "rule xcoverage (training data): 0.008534850640113799\n",
      "rule precision (training data): 0.4\n",
      "rule stability (training data): 0.375\n",
      "rule recall (training data): 0.0125\n",
      "rule f1 score (training data): 0.024242424242424246\n",
      "rule NPV (training data): 0.9944444444444445\n",
      "rule lift (training data): 245.00000000000003\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.6 0.4]\n",
      "rule posterior counts (training data): [3. 2.]\n",
      "rule chisq p-value (training data): 0.7080153610182813\n",
      "rule Kullback-Leibler divergence from original: 0.7055386015979779\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 895 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.611875\n",
      "forest vote margin (unseen instance): 0.22374999999999995\n",
      "confidence weighted forest vote share (unseen instance): 0.6310291714959682\n",
      "confidence weighted forest vote margin (unseen instance): 0.26205834299193637\n",
      "\n",
      "rule: chk_A11 False AND amt <= 10699.61111\n",
      "rule cardinality: 2\n",
      "Fraction of total points of rule: 0.12078505935826428\n",
      "Fraction of total weight of rule: 0.12347541259629799\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.7261055634807418\n",
      "rule xcoverage (unseen data): 0.7240398293029872\n",
      "rule precision (unseen data): 0.8818897637795275\n",
      "rule stability (unseen data): 0.8786692759295499\n",
      "rule recall (unseen data): 0.8296296296296296\n",
      "rule f1 score (unseen data): 0.8549618320610686\n",
      "rule NPV (unseen data): 0.625\n",
      "rule lift (unseen data): 1.5752624097840786\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.88188976 0.11811024]\n",
      "rule posterior counts (unseen data): [448.  60.]\n",
      "rule chisq p-value (unseen data): 1.3308714095175822e-06\n",
      "rule Kullback-Leibler divergence (unseen data): 0.04003717951104793\n",
      "Evaluation Time: 2.599963814995135\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A11 True AND amt <= 10699.61111\n",
      "rule coverage (training data): 0.24964336661911554\n",
      "rule xcoverage (training data): 0.24893314366998578\n",
      "rule precision (training data): 0.5057471264367817\n",
      "rule stability (training data): 0.5028248587570622\n",
      "rule recall (training data): 0.16296296296296298\n",
      "rule f1 score (training data): 0.24649859943977592\n",
      "rule NPV (training data): 0.4625\n",
      "rule lift (training data): 2.6374637287571625\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.50574713 0.49425287]\n",
      "rule posterior counts (training data): [88. 86.]\n",
      "rule chisq p-value (training data): 5.9852850691292534e-12\n",
      "rule Kullback-Leibler divergence from original: 0.6263997217437951\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "Feature Reversed: amt_less_than_upper_bound\n",
      "rule: chk_A11 False AND amt > 10699.61111\n",
      "rule coverage (training data): 0.02282453637660485\n",
      "rule xcoverage (training data): 0.02275960170697013\n",
      "rule precision (training data): 0.13333333333333333\n",
      "rule stability (training data): 0.16666666666666666\n",
      "rule recall (training data): 0.003703703703703704\n",
      "rule f1 score (training data): 0.007207207207207207\n",
      "rule NPV (training data): 0.91875\n",
      "rule lift (training data): 8.065843621399177\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.13333333 0.86666667]\n",
      "rule posterior counts (training data): [ 2. 13.]\n",
      "rule chisq p-value (training data): 6.48063493852144e-08\n",
      "rule Kullback-Leibler divergence from original: 1.940823498723703\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 652 with true class label: 1 (bad)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.48\n",
      "forest vote margin (unseen instance): -0.040000000000000036\n",
      "confidence weighted forest vote share (unseen instance): 0.4180680897147676\n",
      "confidence weighted forest vote margin (unseen instance): -0.16386382057046456\n",
      "\n",
      "rule: prop_A121 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.10278431484937683\n",
      "Fraction of total weight of rule: 0.1020067919262398\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.2995720399429387\n",
      "rule xcoverage (unseen data): 0.29871977240398295\n",
      "rule precision (unseen data): 0.8899521531100478\n",
      "rule stability (unseen data): 0.8820754716981132\n",
      "rule recall (unseen data): 0.34444444444444444\n",
      "rule f1 score (unseen data): 0.4966622162883844\n",
      "rule NPV (unseen data): 0.85625\n",
      "rule lift (unseen data): 3.863871655359945\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.88995215 0.11004785]\n",
      "rule posterior counts (unseen data): [186.  23.]\n",
      "rule chisq p-value (unseen data): 0.00026064017212830664\n",
      "rule Kullback-Leibler divergence (unseen data): 0.0467574899593339\n",
      "Evaluation Time: 2.4470702079997864\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: prop\n",
      "rule: prop_A121 False\n",
      "rule coverage (training data): 0.7018544935805991\n",
      "rule xcoverage (training data): 0.6998577524893315\n",
      "rule precision (training data): 0.7209775967413442\n",
      "rule stability (training data): 0.7186234817813765\n",
      "rule recall (training data): 0.6555555555555556\n",
      "rule f1 score (training data): 0.6867119301648885\n",
      "rule NPV (training data): 0.14375\n",
      "rule lift (training data): 1.332424464069015\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.7209776 0.2790224]\n",
      "rule posterior counts (training data): [354. 137.]\n",
      "rule chisq p-value (training data): 0.05576139292070267\n",
      "rule Kullback-Leibler divergence from original: 0.2637458282164835\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [337. 363.]\n",
      "proba: [0.48142857 0.51857143]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [337. 363.]\n",
      "proba: [0.48142857 0.51857143]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE RESULTS\n",
      "instance id: 792 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.644375\n",
      "forest vote margin (unseen instance): 0.28875\n",
      "confidence weighted forest vote share (unseen instance): 0.7399634287641512\n",
      "confidence weighted forest vote margin (unseen instance): 0.4799268575283019\n",
      "\n",
      "rule: dur <= 10.39796 AND crhis_A31 False\n",
      "rule cardinality: 2\n",
      "Fraction of total points of rule: 0.11425632276949316\n",
      "Fraction of total weight of rule: 0.09396838426968764\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.17118402282453637\n",
      "rule xcoverage (unseen data): 0.17069701280227595\n",
      "rule precision (unseen data): 0.9831932773109243\n",
      "rule stability (unseen data): 0.9672131147540983\n",
      "rule recall (unseen data): 0.21666666666666667\n",
      "rule f1 score (unseen data): 0.3550834597875569\n",
      "rule NPV (unseen data): 0.9875\n",
      "rule lift (unseen data): 7.497116493656286\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.98319328 0.01680672]\n",
      "rule posterior counts (unseen data): [117.   2.]\n",
      "rule chisq p-value (unseen data): 1.6326564155579123e-07\n",
      "rule Kullback-Leibler divergence (unseen data): 0.19461817709539178\n",
      "Evaluation Time: 2.4928744330027257\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: dur_less_than_upper_bound\n",
      "rule: dur > 10.39796 AND crhis_A31 False\n",
      "rule coverage (training data): 0.7774607703281027\n",
      "rule xcoverage (training data): 0.7752489331436699\n",
      "rule precision (training data): 0.7463235294117647\n",
      "rule stability (training data): 0.7440585009140768\n",
      "rule recall (training data): 0.7518518518518519\n",
      "rule f1 score (training data): 0.7490774907749078\n",
      "rule NPV (training data): 0.1375\n",
      "rule lift (training data): 1.244888784762271\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.74632353 0.25367647]\n",
      "rule posterior counts (training data): [406. 138.]\n",
      "rule chisq p-value (training data): 0.33596804524413165\n",
      "rule Kullback-Leibler divergence from original: 0.22539549865383673\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "Feature Reversed: crhis\n",
      "rule: dur <= 10.39796 AND crhis_A31 True\n",
      "rule coverage (training data): 0.009985734664764621\n",
      "rule xcoverage (training data): 0.00995732574679943\n",
      "rule precision (training data): 0.5\n",
      "rule stability (training data): 0.4444444444444444\n",
      "rule recall (training data): 0.005555555555555556\n",
      "rule f1 score (training data): 0.01098901098901099\n",
      "rule NPV (training data): 0.98125\n",
      "rule lift (training data): 75.61728395061728\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.5 0.5]\n",
      "rule posterior counts (training data): [3. 3.]\n",
      "rule chisq p-value (training data): 0.2781108939853556\n",
      "rule Kullback-Leibler divergence from original: 0.6078103980700387\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 735 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 1 (bad)\n",
      "target class prior (training data): 0.22857142857142856\n",
      "forest vote share (unseen instance): 0.571875\n",
      "forest vote margin (unseen instance): 0.14375000000000004\n",
      "confidence weighted forest vote share (unseen instance): 0.7131070954677424\n",
      "confidence weighted forest vote margin (unseen instance): 0.4262141909354843\n",
      "\n",
      "rule: crhis_A31 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.06512342916278079\n",
      "Fraction of total weight of rule: 0.051609275456392774\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.22857142857142856\n",
      "rule coverage (unseen data): 0.05420827389443652\n",
      "rule xcoverage (unseen data): 0.05405405405405406\n",
      "rule precision (unseen data): 0.5405405405405406\n",
      "rule stability (unseen data): 0.525\n",
      "rule recall (unseen data): 0.125\n",
      "rule f1 score (unseen data): 0.20304568527918782\n",
      "rule NPV (unseen data): 0.9685185185185186\n",
      "rule lift (unseen data): 44.74068663257852\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.45945946 0.54054054]\n",
      "rule posterior counts (unseen data): [17. 20.]\n",
      "rule chisq p-value (unseen data): 3.986356080051858e-05\n",
      "rule Kullback-Leibler divergence (unseen data): 0.22716566612697034\n",
      "Evaluation Time: 0.9598728180062608\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: crhis\n",
      "rule: crhis_A31 False\n",
      "rule coverage (training data): 0.9472182596291013\n",
      "rule xcoverage (training data): 0.9445234708392604\n",
      "rule precision (training data): 0.21116138763197587\n",
      "rule stability (training data): 0.21171171171171171\n",
      "rule recall (training data): 0.875\n",
      "rule f1 score (training data): 0.34021871202916165\n",
      "rule NPV (training data): 0.03148148148148148\n",
      "rule lift (training data): 0.9753872543332219\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.78883861 0.21116139]\n",
      "rule posterior counts (training data): [523. 140.]\n",
      "rule chisq p-value (training data): 0.477703919725012\n",
      "rule Kullback-Leibler divergence from original: 0.25973650936591675\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 700.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 85 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.641875\n",
      "forest vote margin (unseen instance): 0.28374999999999995\n",
      "confidence weighted forest vote share (unseen instance): 0.7574522321342758\n",
      "confidence weighted forest vote margin (unseen instance): 0.5149044642685511\n",
      "\n",
      "rule: chk_A14 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.10906139254894587\n",
      "Fraction of total weight of rule: 0.09037502829268676\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.4079885877318117\n",
      "rule xcoverage (unseen data): 0.406827880512091\n",
      "rule precision (unseen data): 0.9543859649122807\n",
      "rule stability (unseen data): 0.9479166666666666\n",
      "rule recall (unseen data): 0.5037037037037037\n",
      "rule f1 score (unseen data): 0.6593939393939393\n",
      "rule NPV (unseen data): 0.91875\n",
      "rule lift (unseen data): 3.0386557687265596\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.95438596 0.04561404]\n",
      "rule posterior counts (unseen data): [272.  13.]\n",
      "rule chisq p-value (unseen data): 1.472950609816159e-11\n",
      "rule Kullback-Leibler divergence (unseen data): 0.1296030264233668\n",
      "Evaluation Time: 2.3184167989966227\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A14 False\n",
      "rule coverage (training data): 0.5934379457917262\n",
      "rule xcoverage (training data): 0.5917496443812233\n",
      "rule precision (training data): 0.6457831325301204\n",
      "rule stability (training data): 0.6435406698564593\n",
      "rule recall (training data): 0.4962962962962963\n",
      "rule f1 score (training data): 0.5612565445026177\n",
      "rule NPV (training data): 0.08125\n",
      "rule lift (training data): 1.4120202362327487\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.64578313 0.35421687]\n",
      "rule posterior counts (training data): [268. 147.]\n",
      "rule chisq p-value (training data): 7.788053206075143e-06\n",
      "rule Kullback-Leibler divergence from original: 0.3613053980008781\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 881 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.6075\n",
      "forest vote margin (unseen instance): 0.21500000000000002\n",
      "confidence weighted forest vote share (unseen instance): 0.5808870502688325\n",
      "confidence weighted forest vote margin (unseen instance): 0.16177410053766378\n",
      "\n",
      "rule: chk_A14 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.10056327202116164\n",
      "Fraction of total weight of rule: 0.09906952619520462\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.4079885877318117\n",
      "rule xcoverage (unseen data): 0.406827880512091\n",
      "rule precision (unseen data): 0.9543859649122807\n",
      "rule stability (unseen data): 0.9479166666666666\n",
      "rule recall (unseen data): 0.5037037037037037\n",
      "rule f1 score (unseen data): 0.6593939393939393\n",
      "rule NPV (unseen data): 0.91875\n",
      "rule lift (unseen data): 3.0386557687265596\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.95438596 0.04561404]\n",
      "rule posterior counts (unseen data): [272.  13.]\n",
      "rule chisq p-value (unseen data): 1.472950609816159e-11\n",
      "rule Kullback-Leibler divergence (unseen data): 0.12960314732104758\n",
      "Evaluation Time: 2.1883172649977496\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A14 False\n",
      "rule coverage (training data): 0.5934379457917262\n",
      "rule xcoverage (training data): 0.5917496443812233\n",
      "rule precision (training data): 0.6457831325301204\n",
      "rule stability (training data): 0.6435406698564593\n",
      "rule recall (training data): 0.4962962962962963\n",
      "rule f1 score (training data): 0.5612565445026177\n",
      "rule NPV (training data): 0.08125\n",
      "rule lift (training data): 1.4120202362327487\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.64578313 0.35421687]\n",
      "rule posterior counts (training data): [268. 147.]\n",
      "rule chisq p-value (training data): 7.788053206075143e-06\n",
      "rule Kullback-Leibler divergence from original: 0.36130553774353097\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "instance id: 7 with true class label: 0 (good)\n",
      "\n",
      "Model Results for Instance\n",
      "target (predicted) class: 0 (good)\n",
      "target class prior (training data): 0.7714285714285715\n",
      "forest vote share (unseen instance): 0.53375\n",
      "forest vote margin (unseen instance): 0.06749999999999995\n",
      "confidence weighted forest vote share (unseen instance): 0.5193786165464033\n",
      "confidence weighted forest vote margin (unseen instance): 0.03875723309280543\n",
      "\n",
      "rule: chk_A11 False AND dur <= 38.22222\n",
      "rule cardinality: 2\n",
      "Fraction of total points of rule: 0.11470587795374292\n",
      "Fraction of total weight of rule: 0.1236140743465776\n",
      "\n",
      "Results - Reference Sample + Pruned Rule\n",
      "target class prior (unseen data): 0.7714285714285715\n",
      "rule coverage (unseen data): 0.6918687589158345\n",
      "rule xcoverage (unseen data): 0.689900426742532\n",
      "rule precision (unseen data): 0.8884297520661157\n",
      "rule stability (unseen data): 0.8850102669404517\n",
      "rule recall (unseen data): 0.7962962962962963\n",
      "rule f1 score (unseen data): 0.83984375\n",
      "rule NPV (unseen data): 0.6625\n",
      "rule lift (unseen data): 1.6656358222849583\n",
      "prior (unseen data): [0.77142857 0.22857143]\n",
      "prior counts (unseen data): [540. 160.]\n",
      "rule posterior (unseen data): [0.88842975 0.11157025]\n",
      "rule posterior counts (unseen data): [430.  54.]\n",
      "rule chisq p-value (unseen data): 4.051435325974734e-07\n",
      "rule Kullback-Leibler divergence (unseen data): 0.0454389621750189\n",
      "Evaluation Time: 3.227538569997705\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A11 True AND dur <= 38.22222\n",
      "rule coverage (training data): 0.2282453637660485\n",
      "rule xcoverage (training data): 0.22759601706970128\n",
      "rule precision (training data): 0.5345911949685535\n",
      "rule stability (training data): 0.5308641975308642\n",
      "rule recall (training data): 0.1574074074074074\n",
      "rule f1 score (training data): 0.24320457796852646\n",
      "rule NPV (training data): 0.5375\n",
      "rule lift (training data): 3.0508931462216538\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.53459119 0.46540881]\n",
      "rule posterior counts (training data): [85. 74.]\n",
      "rule chisq p-value (training data): 2.572477019661088e-09\n",
      "rule Kullback-Leibler divergence from original: 0.5437963059664016\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "Feature Reversed: dur_less_than_upper_bound\n",
      "rule: chk_A11 False AND dur > 38.22222\n",
      "rule coverage (training data): 0.05706134094151213\n",
      "rule xcoverage (training data): 0.05689900426742532\n",
      "rule precision (training data): 0.5128205128205128\n",
      "rule stability (training data): 0.5\n",
      "rule recall (training data): 0.037037037037037035\n",
      "rule f1 score (training data): 0.0690846286701209\n",
      "rule NPV (training data): 0.88125\n",
      "rule lift (training data): 11.931721333430733\n",
      "prior (training data): [0.77142857 0.22857143]\n",
      "prior counts (training data): [540. 160.]\n",
      "rule posterior (training data): [0.51282051 0.48717949]\n",
      "rule posterior counts (training data): [20. 19.]\n",
      "rule chisq p-value (training data): 0.0005074478091110452\n",
      "rule Kullback-Leibler divergence from original: 0.5839178326654242\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [700.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "CHIRPS batch results eval time elapsed: 1.2780 seconds\n"
     ]
    }
   ],
   "source": [
    "# iterate over all the test instances to determine the various scores using leave-one-out testing\n",
    "print('demonstrating found explanations')\n",
    "print()\n",
    "results_start_time = timeit.default_timer()\n",
    "\n",
    "save_results_file = model + '_CHIRPS_rnst_demo' + str(random_state)\n",
    "\n",
    "rt.demonstrate_explainers(explanations, tt, labels.index, # for full batch runs: tt.y_test.index,\n",
    "                              forest=rf,\n",
    "                              meta_data=meta_data,\n",
    "                              model=model,\n",
    "                              eval_start_time=results_start_time,\n",
    "                              print_to_screen=True, # set True when running single instances\n",
    "                              eval_alt_labelings=True,\n",
    "                              eval_rule_complements=True,\n",
    "                              save_results_path=save_path,\n",
    "                              dataset_name='',\n",
    "                              save_results_file=save_results_file,\n",
    "                              save_CHIRPS=False)\n",
    "\n",
    "results_end_time = timeit.default_timer()\n",
    "results_elapsed_time = results_end_time - results_start_time\n",
    "print('CHIRPS batch results eval time elapsed:', \"{:0.4f}\".format(results_elapsed_time), 'seconds')\n",
    "# this completes the CHIRPS runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
