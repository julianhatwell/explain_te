{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up notebook and load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load what we need\n",
    "import numpy as np\n",
    "import CHIRPS.datasets as ds\n",
    "import CHIRPS.datasets_proprietary as dsp\n",
    "import CHIRPS.reproducible as rp\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optional Memory and Computation Cost Management\n",
    "# CHIRPS is time economical but memory intensive to compute for lots of instances at once.\n",
    "forest_walk_async=True\n",
    "explanation_async=True\n",
    "n_cores = mp.cpu_count()-2\n",
    "\n",
    "# How many instances from the test set do you want to explain?\n",
    "# A number bigger than the test set will be interpreted as 'all'\n",
    "n_instances = 100\n",
    "start_instance = 0 # here can opt to start at a specific instance, diagnostic if something crashes\n",
    "\n",
    "# model = 'RandomForest'\n",
    "# model = 'AdaBoost1'\n",
    "# model = 'AdaBoost2'\n",
    "model = 'GBM'\n",
    "\n",
    "# prepare data\n",
    "datasets = [\n",
    "        ds.adult,\n",
    "        ds.bankmark,\n",
    "        ds.car,\n",
    "        ds.cardio,\n",
    "        ds.credit,\n",
    "        ds.german,\n",
    "        ds.lending_tiny_samp,\n",
    "        ds.nursery,\n",
    "        ds.rcdv,\n",
    "       ]\n",
    "\n",
    "# location to save results\n",
    "project_dir = '/datadisk/whiteboxing/2020/GBM'\n",
    "# project_dir = 'V:\\\\whiteboxing\\\\2020\\\\GBM' # defaults to a directory \"whiteboxing\" in the working directory\n",
    "# project_dir = 'C:\\\\Users\\\\Crutt\\\\Documents\\\\whiteboxing\\\\2020\\\\GBM'\n",
    "\n",
    "random_state_splits = 123 # change this if you want to try different splits of the data into test / train\n",
    "random_state_rf = 123 # change this if you want to try with different forest construction\n",
    "random_state_exp = 123 # change this if you want to try with different runs of the explainer algorithm (affects bootstrap eval)\n",
    "\n",
    "verbose = True\n",
    "\n",
    "# CHIRPS default parameters - see papers for details\n",
    "precis_threshold = 0.99\n",
    "merging_bootstraps = 20 # how many training bootstraps to test improvement in growing rule?\n",
    "pruning_bootstraps = 20 # how many training bootstraps to test deterioration in pruning rule?\n",
    "delta = 0.2 # pruning deterioration tolerance paramater\n",
    "\n",
    "tuning = {'override' : False}\n",
    "\n",
    "if model == 'RandomForest':\n",
    "    tuning.update({'grid' : {'n_estimators': [(i + 1) * 200 for i in range(8)], 'max_depth' : [32]}})\n",
    "    benchmark_items = rp.benchmarking_prep(datasets, model, tuning, project_dir,\n",
    "                                           random_state=random_state_rf,\n",
    "                                           random_state_splits=random_state_splits,\n",
    "                                           start_instance=start_instance,\n",
    "                                           verbose=verbose, n_cores=n_cores)\n",
    "\n",
    "    alpha_paths = np.tile([0.9, 0.5, 0.1], 24)\n",
    "    disc_path_bins = np.tile(np.repeat([4, 8], 3), 12)\n",
    "    score_func = np.tile(np.repeat([5, 3, 1], 6), 4)\n",
    "    support_paths = np.tile(np.repeat([0.3, 0.2], 18), 2)\n",
    "    weighting = np.repeat(['kldiv', 'nothing'], 36)\n",
    "\n",
    "    kwargs_grid = {k : {'alpha_paths' : ap, 'disc_path_bins' : dpb, 'disc_path_eqcounts' : False,\n",
    "                        'score_func' : sf, 'weighting' : w, 'support_paths' : sp,\n",
    "                        'precis_threshold' : precis_threshold,\n",
    "                        'merging_bootstraps' : merging_bootstraps,\n",
    "                        'pruning_bootstraps' : pruning_bootstraps,\n",
    "                        'which_trees' : 'majority',\n",
    "                        'delta' : delta} \n",
    "        for k, ap, dpb, sf, w, sp in zip(range(72), alpha_paths, disc_path_bins, score_func, weighting, support_paths)}\n",
    "    \n",
    "    \n",
    "    for kwargs in kwargs_grid:\n",
    "        bi_copy = rp.deepcopy(benchmark_items) # to avoid running down the internal counters\n",
    "        control = {'method' : 'CHIRPS', 'model' : model,\n",
    "                    'n_instances' : n_instances,\n",
    "                    'random_state' : random_state_exp,\n",
    "                    'kwargs' : kwargs_grid[kwargs],\n",
    "                    'forest_walk_async' : forest_walk_async,\n",
    "                    'explanation_async' : explanation_async,\n",
    "                    'n_cores' : n_cores,\n",
    "                    'save_sensitivity_path' : 'rf_sensitivity'}\n",
    "        \n",
    "        print('Sensitivity round: ' + str(kwargs))\n",
    "        rp.do_benchmarking(bi_copy, verbose, **control)\n",
    "        \n",
    "elif model in ('AdaBoost1', 'AdaBoost2'):\n",
    "    if model == 'AdaBoost1':\n",
    "        algo = 'SAMME'\n",
    "        save_sensitivity_path = 'ada1_sensitivity'\n",
    "        support_paths = np.tile(np.tile([0.05, 0.02, 0.01], 16), 2)\n",
    "        n_kwargs = 36\n",
    "    else:\n",
    "        algo = 'SAMME.R'\n",
    "        save_sensitivity_path = 'ada2_sensitivity'\n",
    "        support_paths = np.tile(np.tile([0.005, 0.002, 0.001], 16), 2)\n",
    "        n_kwargs = 72\n",
    "        \n",
    "    max_depth = [i for i in range(1, 5)]\n",
    "    tuning.update({'grid' : {'base_estimator' : [rp.DecisionTreeClassifier(max_depth=d) for d in max_depth],\n",
    "                            'n_estimators': [(i + 1) * 200 for i in range(8)], 'algorithm': [algo]}})\n",
    "    benchmark_items = rp.benchmarking_prep(datasets, model, tuning, project_dir,\n",
    "                                           random_state=123, random_state_splits=123,\n",
    "                                           start_instance=start_instance,\n",
    "                                           verbose=verbose, n_cores=n_cores)\n",
    "    \n",
    "    disc_path_bins = np.tile(np.tile(np.repeat([4, 8], 3), 6), 2)\n",
    "    disc_path_eqcounts = np.tile(np.tile(np.repeat([True, False], 6), 6), 2)\n",
    "    weighting = np.tile(np.repeat(['chisq', 'kldiv', 'nothing'], 12), 2)\n",
    "    which_trees = np.repeat(['majority', 'conf_weighted'], 36)\n",
    "\n",
    "    kwargs_grid = {k : {'paths_lengths_threshold' : 5, 'alpha_paths' : 0.0,\n",
    "                        'disc_path_bins' : dpb, 'disc_path_eqcounts' : dpeq,\n",
    "                        'score_func' : 1, 'weighting' : w, 'support_paths' : sp,\n",
    "                        'merging_bootstraps' : merging_bootstraps,\n",
    "                        'pruning_bootstraps' : pruning_bootstraps,\n",
    "                        'which_trees' : wchtr,\n",
    "                        'delta' : delta} \n",
    "    for k, dpb, dpeq, w, sp, wchtr \\\n",
    "                   in zip(range(n_kwargs), disc_path_bins, disc_path_eqcounts, weighting, support_paths, which_trees)}\n",
    "\n",
    "    for kwargs in kwargs_grid: # range(39, 72): # \n",
    "        bi_copy = rp.deepcopy(benchmark_items) # to avoid running down the internal counters\n",
    "        control = {'method' : 'CHIRPS', 'model' : model,\n",
    "                    'n_instances' : n_instances,\n",
    "                    'random_state' : random_state_exp,\n",
    "                    'kwargs' : kwargs_grid[kwargs],\n",
    "                    'forest_walk_async' : forest_walk_async,\n",
    "                    'explanation_async' : explanation_async,\n",
    "                    'n_cores' : n_cores,\n",
    "                    'save_sensitivity_path' : save_sensitivity_path}\n",
    "        \n",
    "        print('Sensitivity round: ' + str(kwargs))\n",
    "        rp.do_benchmarking(bi_copy, verbose, **control)\n",
    "\n",
    "else: # GBM\n",
    "    tuning.update({'grid' : {'subsample' : [(i + 1) * 0.25 for i in range(3)],\n",
    "                    'n_estimators': [i * 200 for i in range(1, 9)],\n",
    "                    'max_depth' : [i for i in range(1, 5)],\n",
    "                    'learning_rate': np.full(4, 10.0)**[i for i in range(-3, 1)]}})\n",
    "    benchmark_items = rp.benchmarking_prep(datasets, model, tuning, project_dir,\n",
    "                                           random_state=random_state_rf,\n",
    "                                           random_state_splits=random_state_splits,\n",
    "                                           start_instance=start_instance,\n",
    "                                           verbose=verbose, n_cores=n_cores)\n",
    "\n",
    "    support_paths = np.tile([0.05, 0.1, 0.15, 0.2], 4)\n",
    "    disc_path_bins = np.tile(np.repeat([4, 8], 4), 4)\n",
    "    disc_path_eqcounts = np.repeat([True, False], 8)\n",
    "\n",
    "    kwargs_grid = {k : {'paths_lengths_threshold' : 5, 'alpha_paths' : 0.0,\n",
    "                    'disc_path_bins' : dpb, 'disc_path_eqcounts' : dpeq,\n",
    "                    'score_func' : 1, 'weighting' : 'kldiv',\n",
    "                    'support_paths' : sp,\n",
    "                    'merging_bootstraps' : merging_bootstraps,\n",
    "                    'pruning_bootstraps' : pruning_bootstraps,\n",
    "                    'which_trees' : 'targetclass',\n",
    "                    'delta' : 0.2} \n",
    "        for k, dpb, dpeq, sp in zip(range(32), disc_path_bins, disc_path_eqcounts, support_paths)}\n",
    "    \n",
    "    for kwargs in kwargs_grid: \n",
    "        bi_copy = rp.deepcopy(benchmark_items) # to avoid running down the internal counters\n",
    "        control = {'method' : 'CHIRPS', 'model' : model,\n",
    "                    'n_instances' : n_instances,\n",
    "                    'random_state' : random_state_exp,\n",
    "                    'kwargs' : kwargs_grid[kwargs],\n",
    "                    'forest_walk_async' : forest_walk_async,\n",
    "                    'explanation_async' : explanation_async,\n",
    "                    'n_cores' : n_cores,\n",
    "                    'save_sensitivity_path' : 'rf_sensitivity'}\n",
    "\n",
    "        print('Sensitivity round: ' + str(kwargs))\n",
    "        rp.do_benchmarking(bi_copy, verbose, **control)\n",
    "    \n",
    "print('finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
