{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\B3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\ProgramData\\Anaconda3\\envs\\B3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "# for notebook plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# load what we need\n",
    "import time\n",
    "import timeit\n",
    "import CHIRPS.structures as strcts\n",
    "import CHIRPS.datasets as ds\n",
    "import CHIRPS.datasets_proprietary as dsp\n",
    "import CHIRPS.routines as rt\n",
    "\n",
    "import CHIRPS.reproducible as rp\n",
    "from lore import test_lore as tlore\n",
    "from lore import prepare_dataset as prda\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "project_dir = '/datadisk/whiteboxing/examples'\n",
    "# project_dir = 'V:\\\\whiteboxing\\\\examples' # defaults to a directory \"whiteboxing\" in the working directory\n",
    "# project_dir = 'C:\\\\Users\\\\Crutt\\\\Documents\\\\whiteboxing\\\\exampada'\n",
    "\n",
    "random_state_splits = 123 # one off for splitting the data into test / train\n",
    "random_state = 123 # for everything else - e.g. building a new rf with same data\n",
    "\n",
    "# load one of the included datasets\n",
    "# project_dir will default to directory name CHIRPS in the working directory if not given\n",
    "# random_state will default to 123\n",
    "#mydata = dsp.usoc2(random_state=random_state_splits, project_dir=project_dir)\n",
    "d_constructor = ds.adult_small_samp\n",
    "mydata = d_constructor(random_state=random_state_splits, project_dir=project_dir)\n",
    "meta_data = mydata.get_meta()\n",
    "name = d_constructor.__name__\n",
    "\n",
    "meta_data = mydata.get_meta()\n",
    "save_path = meta_data['get_save_path']()\n",
    "\n",
    "train_index, test_index = mydata.get_tt_split_idx(random_state=random_state_splits)\n",
    "# optionally, indexes can be ommitted and will default to scikit's train_test_split method\n",
    "tt = mydata.tt_split(train_index, test_index)\n",
    "\n",
    "# lore proprietary\n",
    "path_data = 'C:\\\\Users\\\\id126493\\\\Documents\\\\GitHub\\\\explain_te\\\\lore\\\\datasets\\\\'\n",
    "\n",
    "# dataset = prepare_german_dataset('german_credit.csv', path_data)\n",
    "dataset = prda.prepare_adult_dataset('adult.csv', path_data)\n",
    "# dataset = prda.prepare_compass_dataset('compas-scores-two-years.csv', path_data)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def prepare_dataset_lore(name, ds_container, meta_data):\n",
    "    columns = meta_data['features_enc']\n",
    "    columns.append(meta_data['class_col'])\n",
    "    dataset = {\n",
    "        'name': name,\n",
    "        'df': pd.DataFrame(ds_container.X_train_enc).merge(ds_container.y_train, left_index=True, right_index=True),\n",
    "        'columns': columns,\n",
    "        'class_name': meta_data['class_col'],\n",
    "        'possible_outcomes': [i for i in range(len(meta_data['class_names']))],\n",
    "        'type_features': {'integer' : [],\n",
    "                         'double' : meta_data['features_enc'],\n",
    "                         'string' : []},\n",
    "        'features_type': {k : 'double' for k in meta_data['features_enc']},\n",
    "        'discrete': [],\n",
    "        'continuous': meta_data['features_enc'],\n",
    "        'idx_features': {i : v for i, v in enumerate(meta_data['features_enc'])},\n",
    "        'label_encoder': meta_data['le_dict'],\n",
    "        'X': np.array(ds_container.X_train_enc.todense()),\n",
    "        'y': np.array(ds_container.y_train),\n",
    "    }\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "lore_dataset = prepare_dataset_lore(name, ds_container=tt, meta_data=meta_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(lore_dataset['X'][:,9:10])#  == np.array([0., 1.])\n",
    "# np.unique(np.array([12, 0, 0, 1]))\n",
    "if (np.unique(lore_dataset['X'][:,0]) == np.array([0., 1.])).all():\n",
    "    pass\n",
    "#tt.X_train_enc.todense()[:,9:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0.]\n",
      "False\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0.]\n",
      "False\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0.]\n",
      "False\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0.]\n",
      "False\n",
      "[0.]\n",
      "False\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0.]\n",
      "False\n",
      "[0.]\n",
      "False\n",
      "[0.]\n",
      "False\n",
      "[0. 1.]\n",
      "True\n",
      "[0.]\n",
      "False\n",
      "[0.]\n",
      "False\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0.]\n",
      "False\n",
      "[0. 1.]\n",
      "True\n",
      "[0.]\n",
      "False\n",
      "[0.]\n",
      "False\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0.]\n",
      "False\n",
      "[0.]\n",
      "False\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0. 1.]\n",
      "True\n",
      "[0.]\n",
      "False\n",
      "[17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34.\n",
      " 35. 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52.\n",
      " 53. 54. 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 66. 67. 72. 73. 76. 90.]\n",
      "False\n",
      "[10.5255146  10.61410621 10.61785792 10.64268305 10.67364207 10.6855152\n",
      " 10.68839316 10.72333346 10.74647614 10.74920559 10.77362963 10.80717925\n",
      " 10.84951183 10.89481154 10.89764632 10.95122751 10.98515712 10.99697004\n",
      " 11.0334693  11.08309594 11.09387347 11.0958482  11.12106736 11.13407794\n",
      " 11.21678102 11.2284117  11.25630269 11.26933683 11.27618996 11.28387701\n",
      " 11.29245334 11.32639105 11.35398835 11.4033561  11.43397966 11.4636932\n",
      " 11.47416385 11.48932925 11.52075474 11.52851334 11.52964491 11.54319275\n",
      " 11.5442497  11.54957557 11.57193938 11.59344498 11.59461604 11.60647956\n",
      " 11.61410023 11.61778085 11.62044265 11.62786    11.62950778 11.63213859\n",
      " 11.64915073 11.65142574 11.657424   11.66316278 11.66922811 11.67021977\n",
      " 11.67540989 11.6764379  11.68080997 11.68652577 11.69110512 11.6930613\n",
      " 11.70120424 11.70822906 11.71026699 11.71535189 11.72161303 11.72731884\n",
      " 11.74579754 11.75296546 11.75642051 11.76409655 11.7671645  11.76823413\n",
      " 11.78147059 11.78208199 11.81522764 11.82492935 11.82604865 11.83587091\n",
      " 11.83751307 11.84964767 11.85047569 11.85471213 11.8563875  11.86353304\n",
      " 11.87066984 11.87475908 11.8766932  11.88162977 11.88336425 11.89122491\n",
      " 11.89527888 11.90026733 11.9171765  11.91906368 11.91996933 11.92157882\n",
      " 11.92700668 11.92811646 11.93279302 11.9350838  11.93786635 11.94009335\n",
      " 11.94391536 11.95113523 11.95391858 11.96578929 11.96683782 11.96985652\n",
      " 11.97292295 11.98245398 11.98679661 11.9947712  11.99494412 11.99602423\n",
      " 11.99726953 11.99910997 12.00131528 12.00248659 12.00380345 12.01546284\n",
      " 12.02206567 12.03300415 12.04020104 12.06114513 12.06667839 12.07326099\n",
      " 12.07590132 12.08612289 12.08894877 12.08902184 12.09306631 12.09372668\n",
      " 12.09688816 12.09821457 12.10217772 12.1026935  12.10728493 12.10795252\n",
      " 12.11073397 12.11727968 12.11962656 12.12058556 12.12073804 12.12108649\n",
      " 12.1229247  12.12449918 12.12772184 12.1291052  12.12945075 12.13220541\n",
      " 12.13332989 12.13879972 12.14301037 12.14395785 12.14402169 12.14476623\n",
      " 12.14495228 12.14549427 12.14585544 12.14613685 12.14649248 12.15048594\n",
      " 12.15212847 12.15792702 12.16125309 12.16271619 12.16525586 12.16936198\n",
      " 12.17268131 12.17898918 12.182287   12.1867522  12.18741976 12.1896485\n",
      " 12.19032429 12.19423283 12.19435931 12.19580006 12.19800015 12.19899264\n",
      " 12.20108523 12.20260665 12.20740676 12.21030866 12.21092087 12.21659707\n",
      " 12.2227085  12.22438887 12.22460486 12.22829391 12.23007234 12.23207172\n",
      " 12.23400391 12.23499532 12.237799   12.23881569 12.24006819 12.24075423\n",
      " 12.2408315  12.24382594 12.24788135 12.24932369 12.25030004 12.2519968\n",
      " 12.25327107 12.25630463 12.26359127 12.27023453 12.2738668  12.27952755\n",
      " 12.28137954 12.28187097 12.28195904 12.28359834 12.28591841 12.28673977\n",
      " 12.29245674 12.29359806 12.29630633 12.29843302 12.30817335 12.31373351\n",
      " 12.31678631 12.32329552 12.32886533 12.33580621 12.33810917 12.33947528\n",
      " 12.34026257 12.34057731 12.34113661 12.34554324 12.34847458 12.35046732\n",
      " 12.36358054 12.36728973 12.37234104 12.37363583 12.3750852  12.38204911\n",
      " 12.38568637 12.38591196 12.38677205 12.38898569 12.39321175 12.40012101\n",
      " 12.4067047  12.41393605 12.42475426 12.4263521  12.43664057 12.44017196\n",
      " 12.44036581 12.44680461 12.44843042 12.45102465 12.45589318 12.45784253\n",
      " 12.46767123 12.47251321 12.48355664 12.48711523 12.48967892 12.49364346\n",
      " 12.50378178 12.51686071 12.52443183 12.53830376 12.53934692 12.54056793\n",
      " 12.54825356 12.55797874 12.55856937 12.56649855 12.5700315  12.57736375\n",
      " 12.58598744 12.59461537 12.60344174 12.60925849 12.61008003 12.62119101\n",
      " 12.65682019 12.66075005 12.66517962 12.66535652 12.67104489 12.67269243\n",
      " 12.68805425 12.68965245 12.69062308 12.69555103 12.69647921 12.69667209\n",
      " 12.70602638 12.71618902 12.71737116 12.71769495 12.74461654 12.74809166\n",
      " 12.7554043  12.75601898 12.75787801 12.76181236 12.76757808 12.77167051\n",
      " 12.77474728 12.77693354 12.78210157 12.78343854 12.79731445 12.80015059\n",
      " 12.80790466 12.82100149 12.83118453 12.83452129 12.83777252 12.8530031\n",
      " 12.86542775 12.87393022 12.88268132 12.88417471 12.89482267 12.90456054\n",
      " 12.91996564 12.95154421 12.97143351 13.0270852  13.07129322 13.09220722\n",
      " 13.14135391 13.15667591 13.26793796 13.33823253 13.39477545]\n",
      "False\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "False\n",
      "[ 0.          7.04925484  7.3178762   7.68478394  8.04044688  8.10952566\n",
      "  8.31016902  8.31922994  8.3864009   8.44483753  8.49002752  8.50410795\n",
      "  8.55236727  8.6044712   8.89549263  8.94754602  9.06126015  9.14708103\n",
      "  9.26112854  9.6172045   9.61747076 10.23383392 11.51292546]\n",
      "False\n",
      "[0.         6.43935037 7.3556411  7.40974195 7.45124168 7.53743004\n",
      " 7.54327335 7.55118687 7.62657021 7.6989362  7.72267752 7.78986856]\n",
      "False\n",
      "[ 2.  4.  5.  6.  8. 10. 11. 12. 15. 18. 20. 21. 24. 25. 26. 30. 32. 34.\n",
      " 35. 36. 37. 38. 40. 42. 45. 46. 47. 48. 50. 51. 52. 55. 60. 65. 70. 90.]\n",
      "False\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3206a69873fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtlore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlore_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblackbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblackbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\lore\\test_lore.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(dataset, path_data, blackbox)\u001b[0m\n\u001b[0;32m     28\u001b[0m                                       \u001b[0mcontinuous_function_estimation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                                       \u001b[0mreturns_infos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                                       path=path_data, sep=';', log=False)\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mdfX2E\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_df2explain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblackbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2E\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\lore\\lore.py\u001b[0m in \u001b[0;36mexplain\u001b[1;34m(idx_record2explain, X2E, dataset, blackbox, ng_function, discrete_use_probabilities, continuous_function_estimation, returns_infos, path, sep, log)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Generate Neighborhood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mdfZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mng_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblackbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Build Decision Tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\lore\\neighbor_generator.py\u001b[0m in \u001b[0;36mgenetic_neighborhood\u001b[1;34m(dfZ, x, blackbox, dataset)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mdiscrete_no_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscrete\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mdiscrete_no_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdistance_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "blackbox = RandomForestClassifier(n_estimators=20)\n",
    "#blackbox = AdaBoostClassifier(n_estimators=20)\n",
    "\n",
    "# path_data = '/home/julianhatwell/Documents/github/explain_te/lore/datasets/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tlore.main(dataset=lore_dataset, path_data=path_data, blackbox=blackbox)\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split the data. here using a basic sampling method.\n",
    "# the returned object is a wrapper class that contains\n",
    "# the train and test splits for X and y\n",
    "\n",
    "# also the the encoded versions of X_train and X_test that the rf will use\n",
    "# this is because we prefer onehot encoded over allowing categorical vars to be represented as integer\n",
    "# scikit would treat these as ordinal, which is inappropriate\n",
    "\n",
    "# also some meta-data: priors for y, the indexes from the input data\n",
    "\n",
    "# also some convenience functions for leave-one-out testing\n",
    "\n",
    "# train test split - one off hard-coded random state.\n",
    "# random state can be ommitted \n",
    "# and will default to the state held in the dataset container\n",
    "# which defaults to 123 if ommitted in the constructor\n",
    "train_index, test_index = mydata.get_tt_split_idx(random_state=random_state_splits)\n",
    "# optionally, indexes can be ommitted and will default to scikit's train_test_split method\n",
    "tt = mydata.tt_split(train_index, test_index)\n",
    "\n",
    "# build model, tuned for high accuracy\n",
    "model = 'RandomForest'\n",
    "# model = 'AdaBoost1'\n",
    "# model = 'AdaBoost2'\n",
    "# model = 'GBM'\n",
    "\n",
    "# decide if to run the whole tuning routine again (long for Adaboost)\n",
    "# RF routine has a default tuning grid, so can leave as None, or come up with some other options\n",
    "tuning = {'grid' : None, 'override' : False}\n",
    "if model == 'RandomForest':\n",
    "    which_trees = 'majority'\n",
    "    tuning.update({'grid' : None}) # defaults to n_trees [200, 400, ..., 1600]\n",
    "\n",
    "elif model in ('AdaBoost1', 'AdaBoost2'):\n",
    "    if model == 'AdaBoost1':\n",
    "        # classic (and multi-class) AdaBoost\n",
    "        algo = 'SAMME'\n",
    "        which_trees = 'majority'\n",
    "    else:\n",
    "        algo = 'SAMME.R'\n",
    "        which_trees = 'conf_weighted'\n",
    "    max_depth = [i for i in range(1, 5)]\n",
    "    tuning.update({'grid' : {'base_estimator' : [rt.DecisionTreeClassifier(max_depth=d) for d in max_depth],\n",
    "                            'n_estimators': [(i + 1) * 200 for i in range(8)], 'algorithm': [algo]}})\n",
    "    \n",
    "else: # GBM - not fully implemented yet\n",
    "    stop # ValueError\n",
    "\n",
    "rf = rt.forest_prep(ds_container=tt,\n",
    "                    meta_data=meta_data,\n",
    "                    # override_tuning=True,\n",
    "                    model=model,\n",
    "                    tuning_grid=tuning['grid'],\n",
    "                    save_path=save_path,\n",
    "                    plot_cm=True, plot_cm_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
