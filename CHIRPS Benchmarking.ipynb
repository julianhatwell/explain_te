{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up notebook and load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for notebook plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# load what we need\n",
    "import numpy as np\n",
    "import CHIRPS.datasets as ds\n",
    "import CHIRPS.reproducible as rp\n",
    "from CHIRPS.routines import extend_path\n",
    "\n",
    "# demo datasets that ship with package. all from UCI unless stated otherwise\n",
    "# ds.adult_data, ds.adult_samp_data, ds.adult_small_samp_data Large dataset ships with manageable sub samples\n",
    "# ds.bankmark_data, ds.bankmark_samp_data\n",
    "# ds.car_data\n",
    "# ds.cardio_data this is the cardiotocography dataset\n",
    "# ds.credit_data\n",
    "# ds.german_data\n",
    "# ds.lending_data, ds.lending_samp_data, ds.lending_small_samp_data, ds.lending_tiny_samp_data from Kaggle. see datasets_from_source file for links\n",
    "# ds.nursery_data, ds.nursery_samp_data\n",
    "# ds.rcdv_data, ds.rcdv_samp_data from US government see datasets_from_source file for links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common config - can be ommitted if defaults are OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_dir = 'V:\\\\whiteboxing\\\\tests' # defaults to a directory \"whiteboxing\" in the working directory\n",
    "project_dir = 'C:\\\\Users\\\\Crutt\\\\Documents\\\\whiteboxing\\\\tests'\n",
    "random_state_splits = 123 # one off for splitting the data into test / train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several datasets are available as pre-prepared containers that hold the data and some meta-data that is used in the algorithm\n",
    "Any dataset can be turned into a container by invoking the constructor found in the file structures.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function CHIRPS.datasets.adult_small_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.bankmark_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.car(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.cardio(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.credit(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.german(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.lending_tiny_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.nursery_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.rcdv_samp(random_state=123, project_dir=None)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets might be down-sampled to make them easier to work with\n",
    "# the full sets are available too\n",
    "# this is a list of constructors that will be used in the benchmarking\n",
    "rp.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CHIRPS.structures.data_container at 0x1941434e0f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of one dataset\n",
    "# note: random_state propagates through other functions and is easily updated to allow alternative runs\n",
    "ds.cardio(random_state=123, project_dir=project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardising train-test splitting\n",
    "Some methods are not available in Python. We want to maintain the same dataset splits no matter which platform. So, the train test data is split with the one-time random seed and the splits are saved to csv in the project folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:190: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_train.to_csv(path = save_path + 'y_train.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:192: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  self.y_test.to_csv(path = save_path + 'y_test.csv')\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:177: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.train_index).to_csv(path = save_path + 'train_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'path' will be renamed to 'path_or_buf'.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:178: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  Series(self.test_index).to_csv(path = save_path + 'test_index.csv', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported train-test data for 9 datasets.\n"
     ]
    }
   ],
   "source": [
    "# writes external files\n",
    "rp.export_data_splits(datasets=rp.datasets, project_dir=project_dir, random_state_splits=random_state_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Runs\n",
    "Loop through datasets, actioning the functions in the package to execute a round of experiments and test evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Optional Memory and Computation Cost Management\n",
    "CHIRPS is time economical but memory intensive to compute for lots of instances at once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel processing\n",
    "Scikit takes care of parallel for the RF construction.\n",
    "We can parallelise the following:\n",
    "1. the walk of instances down each tree to collect the paths. The paths for many instances are returned in a single array. This parallelises across trees.\n",
    "2. building CHIRPS and the final explanation (rule). This is a search optimisation and we can parallelise each instance.\n",
    "\n",
    "This is expecially effective when running batches. For single instances, set both to false to avoid spinning up the parallel infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control for async processes - each tree walk can be done in its own core\n",
    "# and so can each explanation (e.g. rule conditions merge by hill-climbing)\n",
    "# these will default to false if not passed explicitly to the explainer function\n",
    "# on a multi-core machine there should be a good speed up for large batches\n",
    "# when the batch_size advantage exceeds the overhead of setting up multi-processing\n",
    "# timings will be printed to screen so you can see if it helps\n",
    "forest_walk_async=True\n",
    "chirps_explanation_async=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing unseen data\n",
    "\n",
    "Again note:\n",
    "test set has never been \"seen\" by random forest during training\n",
    "test set has been only used to assess model (random forest) accuracy - no additional tuning after this\n",
    "test set has not be involved in generating the explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching\n",
    "The memory space requirements for all the paths can be reduced by dividing the test set into batches. However this does take longer as there is an overhead to instantiate all the required objects, especially if coupled with parallel processing.\n",
    "Best compromise could be a small number of larger batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of instances can be controlled by\n",
    "# n_instances - how many instances to explain at one time\n",
    "# set these larger than the size of the test set and it will simply run the whole test set in one batch. Better do option 2\n",
    "n_instances = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data and Forest prep\n",
    "Use the random state splits to do a one-off data split.\n",
    "Fit the RF to training data, using the iterating random state.\n",
    "Save the performance metrics on the test set for later review.\n",
    "\n",
    "### 2. Prepare Unseen Data and Predictions\n",
    "Important to note:\n",
    "Test set never \"seen\" by RF during training.\n",
    "test set not involved in generating the explainer.\n",
    "Test set used to evaluate model (random forest) accuracy beyond OOBE scores - no additional tuning based on these results.\n",
    "Test set used to evaluate explanation scores by leave-one-out method removing the specific instance we're explaining.\n",
    "\n",
    "Important to note:\n",
    "We will explain predictions directly from the trained RF. Explanation system makes no compromise on model accuracy.\n",
    "\n",
    "### 3. CHIRPS algorithm\n",
    "1. Extract tree prediction paths\n",
    "2. Freqent pattern mining of paths\n",
    "3. Score and sort mined path segments\n",
    "4. Merge path segments into one rule\n",
    "\n",
    "#### CHIRPS 1\n",
    "Fit a forest_walker object to the dataset and decision forest. This is a wrapper that will extract the paths of all the given instances. Its main method delivers the instance paths for the remaining steps of the algorithm as a new object: a batch_paths_container. It can also report interesting statistics (treating the forest as a set of random tree-structured variables).\n",
    "\n",
    "#### CHIRPS 2-4\n",
    "A batch_CHIRPS_container is fitted with the batch_paths_container returned by the forest walker, and with a sample of data. For CHIRPS, we prefer a large sample. The whole training set or other representative sample will do. This is a wrapper object will execute steps 2-4 on all each the instance-paths in the batch_paths_container.\n",
    "\n",
    "Important to note:\n",
    "true_divide warnings are OK! It just means that a continuous variable is unbounded on one side i.e. no greater/less than inequality is used in the specific CHIRPS explanation.\n",
    "\n",
    "Important note: \n",
    "Here we are using the training set to create the explainers. We could use a different dataset as long as it is representative of the training set that built the decision forest. Most important that we don't use the dataset that we wish to explain, so never use the test set, for example.\n",
    "\n",
    "### 4. Evaluating CHIRPS Explanations\n",
    "Test set has been used to create an explainer *one instance at a time* and the rest of test set was not \"seen\" during this construction. To score each explainer, we use test set, leaving out the individual instance being explained. The data_split_container (tt) has a convenience funtion for doing this. All the results are saved to csv files in the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for adult_small_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.24, K = 1\n",
      "[Seed 124] TrainingError = 0.24, K = 3\n",
      "[Seed 125] TrainingError = 0.24, K = 2\n",
      "[Seed 126] TrainingError = 0.24, K = 1\n",
      "[Seed 127] TrainingError = 0.24, K = 2\n",
      "[Seed 128] TrainingError = 0.24, K = 3\n",
      "[Seed 129] TrainingError = 0.24, K = 1\n",
      "[Seed 130] TrainingError = 0.24, K = 2\n",
      "[Seed 131] TrainingError = 0.24, K = 2\n",
      "[Seed 132] TrainingError = 0.24, K = 2\n",
      "[Seed 133] TrainingError = 0.24, K = 2\n",
      "[Seed 134] TrainingError = 0.24, K = 2\n",
      "[Seed 135] TrainingError = 0.24, K = 1\n",
      "[Seed 136] TrainingError = 0.24, K = 2\n",
      "[Seed 137] TrainingError = 0.24, K = 2\n",
      "[Seed 138] TrainingError = 0.24, K = 2\n",
      "[Seed 139] TrainingError = 0.24, K = 1\n",
      "[Seed 140] TrainingError = 0.24, K = 1\n",
      "[Seed 141] TrainingError = 0.24, K = 1\n",
      "[Seed 142] TrainingError = 0.24, K = 2\n",
      "Optimal Model >> Seed 123, TrainingError = 0.24, K = 1\n",
      "Fit defragTrees time elapsed: 2899.9400 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.769441\n",
      "Coverage = 1.000000\n",
      "Overlap = 0.000000\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\reproducible.py:555: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  eval_model['test_kappa'], fid, sqrt((fid/(1-fid))/len(labels))]]\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for bankmark_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n",
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.10, K = 1\n",
      "[Seed 124] TrainingError = 0.10, K = 2\n",
      "[Seed 125] TrainingError = 0.10, K = 1\n",
      "[Seed 126] TrainingError = 0.10, K = 1\n",
      "[Seed 127] TrainingError = 0.10, K = 2\n",
      "[Seed 128] TrainingError = 0.10, K = 2\n",
      "[Seed 129] TrainingError = 0.10, K = 1\n",
      "[Seed 130] TrainingError = 0.10, K = 2\n",
      "[Seed 131] TrainingError = 0.10, K = 2\n",
      "[Seed 132] TrainingError = 0.10, K = 2\n",
      "[Seed 133] TrainingError = 0.10, K = 2\n",
      "[Seed 134] TrainingError = 0.10, K = 1\n",
      "[Seed 135] TrainingError = 0.10, K = 2\n",
      "[Seed 136] TrainingError = 0.10, K = 1\n",
      "[Seed 137] TrainingError = 0.10, K = 1\n",
      "[Seed 138] TrainingError = 0.10, K = 2\n",
      "[Seed 139] TrainingError = 0.10, K = 2\n",
      "[Seed 140] TrainingError = 0.10, K = 2\n",
      "[Seed 141] TrainingError = 0.10, K = 2\n",
      "[Seed 142] TrainingError = 0.10, K = 1\n",
      "Optimal Model >> Seed 123, TrainingError = 0.10, K = 1\n",
      "Fit defragTrees time elapsed: 2080.5588 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.880882\n",
      "Coverage = 1.000000\n",
      "Overlap = 0.000000\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\metrics\\classification.py:576: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\reproducible.py:554: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  p_perf, sqrt((p_perf/(1-p_perf))/len(labels)), \\\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\reproducible.py:555: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  eval_model['test_kappa'], fid, sqrt((fid/(1-fid))/len(labels))]]\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for car with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n",
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.29, K = 2\n",
      "[Seed 124] TrainingError = 0.29, K = 4\n",
      "[Seed 125] TrainingError = 0.29, K = 3\n",
      "[Seed 126] TrainingError = 0.29, K = 3\n",
      "[Seed 127] TrainingError = 0.29, K = 3\n",
      "[Seed 128] TrainingError = 0.29, K = 3\n",
      "[Seed 129] TrainingError = 0.29, K = 3\n",
      "[Seed 130] TrainingError = 0.29, K = 4\n",
      "[Seed 131] TrainingError = 0.29, K = 2\n",
      "[Seed 132] TrainingError = 0.29, K = 2\n",
      "[Seed 133] TrainingError = 0.29, K = 4\n",
      "[Seed 134] TrainingError = 0.29, K = 3\n",
      "[Seed 135] TrainingError = 0.29, K = 2\n",
      "[Seed 136] TrainingError = 0.29, K = 3\n",
      "[Seed 137] TrainingError = 0.29, K = 2\n",
      "[Seed 138] TrainingError = 0.28, K = 4\n",
      "[Seed 139] TrainingError = 0.29, K = 2\n",
      "[Seed 140] TrainingError = 0.29, K = 2\n",
      "[Seed 141] TrainingError = 0.29, K = 2\n",
      "[Seed 142] TrainingError = 0.28, K = 3\n",
      "Optimal Model >> Seed 142, TrainingError = 0.28, K = 3\n",
      "Fit defragTrees time elapsed: 480.0525 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.704633\n",
      "Coverage = 1.000000\n",
      "Overlap = 0.355212\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 1633\n",
      "Running experiment for cardio with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n",
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.22, K = 2\n",
      "[Seed 124] TrainingError = 0.22, K = 2\n",
      "[Seed 125] TrainingError = 0.22, K = 1\n",
      "[Seed 126] TrainingError = 0.22, K = 2\n",
      "[Seed 127] TrainingError = 0.22, K = 4\n",
      "[Seed 128] TrainingError = 0.20, K = 3\n",
      "[Seed 129] TrainingError = 0.22, K = 4\n",
      "[Seed 130] TrainingError = 0.22, K = 2\n",
      "[Seed 131] TrainingError = 0.18, K = 5\n",
      "[Seed 132] TrainingError = 0.19, K = 4\n",
      "[Seed 133] TrainingError = 0.20, K = 3\n",
      "[Seed 134] TrainingError = 0.22, K = 4\n",
      "[Seed 135] TrainingError = 0.22, K = 1\n",
      "[Seed 136] TrainingError = 0.20, K = 4\n",
      "[Seed 137] TrainingError = 0.17, K = 4\n",
      "[Seed 138] TrainingError = 0.22, K = 2\n",
      "[Seed 139] TrainingError = 0.22, K = 3\n",
      "[Seed 140] TrainingError = 0.21, K = 3\n",
      "[Seed 141] TrainingError = 0.22, K = 1\n",
      "[Seed 142] TrainingError = 0.22, K = 2\n",
      "Optimal Model >> Seed 137, TrainingError = 0.17, K = 4\n",
      "Fit defragTrees time elapsed: 795.2733 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.826019\n",
      "Coverage = 0.985893\n",
      "Overlap = 0.316614\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\metrics\\classification.py:576: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\reproducible.py:554: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  p_perf, sqrt((p_perf/(1-p_perf))/len(labels)), \\\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\reproducible.py:555: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  eval_model['test_kappa'], fid, sqrt((fid/(1-fid))/len(labels))]]\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for credit with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n",
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.43, K = 1\n",
      "[Seed 124] TrainingError = 0.43, K = 1\n",
      "[Seed 125] TrainingError = 0.14, K = 2\n",
      "[Seed 126] TrainingError = 0.43, K = 1\n",
      "[Seed 127] TrainingError = 0.43, K = 1\n",
      "[Seed 128] TrainingError = 0.43, K = 1\n",
      "[Seed 129] TrainingError = 0.43, K = 1\n",
      "[Seed 130] TrainingError = 0.43, K = 1\n",
      "[Seed 131] TrainingError = 0.43, K = 1\n",
      "[Seed 132] TrainingError = 0.43, K = 1\n",
      "[Seed 133] TrainingError = 0.43, K = 1\n",
      "[Seed 134] TrainingError = 0.43, K = 1\n",
      "[Seed 135] TrainingError = 0.43, K = 1\n",
      "[Seed 136] TrainingError = 0.43, K = 1\n",
      "[Seed 137] TrainingError = 0.14, K = 2\n",
      "[Seed 138] TrainingError = 0.43, K = 1\n",
      "[Seed 139] TrainingError = 0.43, K = 1\n",
      "[Seed 140] TrainingError = 0.43, K = 1\n",
      "[Seed 141] TrainingError = 0.43, K = 1\n",
      "[Seed 142] TrainingError = 0.43, K = 1\n",
      "Optimal Model >> Seed 125, TrainingError = 0.14, K = 2\n",
      "Fit defragTrees time elapsed: 354.2617 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.859903\n",
      "Coverage = 0.990338\n",
      "Overlap = 0.463768\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\metrics\\classification.py:576: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\reproducible.py:554: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  p_perf, sqrt((p_perf/(1-p_perf))/len(labels)), \\\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\reproducible.py:555: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  eval_model['test_kappa'], fid, sqrt((fid/(1-fid))/len(labels))]]\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for german with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n",
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.30, K = 1\n",
      "[Seed 124] TrainingError = 0.30, K = 2\n",
      "[Seed 125] TrainingError = 0.30, K = 1\n",
      "[Seed 126] TrainingError = 0.30, K = 1\n",
      "[Seed 127] TrainingError = 0.30, K = 2\n",
      "[Seed 128] TrainingError = 0.30, K = 1\n",
      "[Seed 129] TrainingError = 0.30, K = 1\n",
      "[Seed 130] TrainingError = 0.30, K = 1\n",
      "[Seed 131] TrainingError = 0.30, K = 2\n",
      "[Seed 132] TrainingError = 0.30, K = 2\n",
      "[Seed 133] TrainingError = 0.30, K = 1\n",
      "[Seed 134] TrainingError = 0.30, K = 1\n",
      "[Seed 135] TrainingError = 0.30, K = 1\n",
      "[Seed 136] TrainingError = 0.30, K = 2\n",
      "[Seed 137] TrainingError = 0.30, K = 1\n",
      "[Seed 138] TrainingError = 0.30, K = 1\n",
      "[Seed 139] TrainingError = 0.30, K = 3\n",
      "[Seed 140] TrainingError = 0.30, K = 2\n",
      "[Seed 141] TrainingError = 0.30, K = 2\n",
      "[Seed 142] TrainingError = 0.30, K = 2\n",
      "Optimal Model >> Seed 123, TrainingError = 0.30, K = 1\n",
      "Fit defragTrees time elapsed: 644.8070 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.706667\n",
      "Coverage = 1.000000\n",
      "Overlap = 0.000000\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 131\n",
      "Running experiment for lending_tiny_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using previous tuning parameters\n",
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.21, K = 2\n",
      "[Seed 124] TrainingError = 0.21, K = 2\n",
      "[Seed 125] TrainingError = 0.21, K = 1\n",
      "[Seed 126] TrainingError = 0.21, K = 1\n",
      "[Seed 127] TrainingError = 0.21, K = 2\n",
      "[Seed 128] TrainingError = 0.21, K = 3\n",
      "[Seed 129] TrainingError = 0.21, K = 1\n",
      "[Seed 130] TrainingError = 0.21, K = 1\n",
      "[Seed 131] TrainingError = 0.21, K = 2\n",
      "[Seed 132] TrainingError = 0.21, K = 2\n",
      "[Seed 133] TrainingError = 0.21, K = 1\n",
      "[Seed 134] TrainingError = 0.21, K = 2\n",
      "[Seed 135] TrainingError = 0.21, K = 3\n",
      "[Seed 136] TrainingError = 0.21, K = 2\n",
      "[Seed 137] TrainingError = 0.21, K = 2\n",
      "[Seed 138] TrainingError = 0.21, K = 2\n",
      "[Seed 139] TrainingError = 0.21, K = 1\n",
      "[Seed 140] TrainingError = 0.21, K = 2\n",
      "[Seed 141] TrainingError = 0.21, K = 3\n",
      "[Seed 142] TrainingError = 0.21, K = 2\n",
      "Optimal Model >> Seed 123, TrainingError = 0.21, K = 2\n",
      "Fit defragTrees time elapsed: 3913.3759 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.816456\n",
      "Coverage = 0.957278\n",
      "Overlap = 0.549051\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\metrics\\classification.py:576: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\reproducible.py:554: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  p_perf, sqrt((p_perf/(1-p_perf))/len(labels)), \\\n",
      "C:\\Users\\Crutt\\Documents\\GitHub\\explain_te\\CHIRPS\\reproducible.py:555: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  eval_model['test_kappa'], fid, sqrt((fid/(1-fid))/len(labels))]]\n",
      "C:\\Users\\Crutt\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:414: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for nursery_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n",
      "\n",
      "Running defragTrees\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-aceb172705c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m                                                                                 \u001b[0mmeta_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                                                                                 \u001b[0mKmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrestart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxitr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxitr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                                                                                 identifier='defragTrees', save_path=save_path)\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\CHIRPS\\reproducible.py\u001b[0m in \u001b[0;36mdefragTrees_prep\u001b[1;34m(forest, meta_data, ds_container, Kmax, maxitr, restart, identifier, save_path)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[0msplitter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDefragModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseSLtrees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# parse sklearn tree ensembles into the array of (feature index, threshold)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[0mmdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDefragModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodeltype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'classification'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxitr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxitr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqitr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrestart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m     \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfittype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'FAB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[0mdefTrees_end_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\defragTrees\\defragTrees.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, splitter, K, fittype, featurename)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 \u001b[0mdefr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_defragger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfittype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodeltype_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxitr_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqitr_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed_\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mitr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefragger_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnjobs_\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\defragTrees\\defragTrees.py\u001b[0m in \u001b[0;36mfit_defragger\u001b[1;34m(self, X, y, splitter, K, fittype, modeltype, maxitr, qitr, tol, eps, delta, seed, verbose)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_defragger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfittype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodeltype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxitr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqitr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mdefragger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDefragger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodeltype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodeltype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxitr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxitr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqitr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqitr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[0mdefragger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfittype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfittype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdefragger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\defragTrees\\defragTrees.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, splitter, K, fittype)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__fitEM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mfittype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'FAB'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__fitFAB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\defragTrees\\defragTrees.py\u001b[0m in \u001b[0;36m__fitFAB\u001b[1;34m(self, X, y, splitter, Kmax, seed)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mAnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[0mKnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__objFAB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodeltype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodeltype_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxitr_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[0mQnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\defragTrees\\defragTrees.py\u001b[0m in \u001b[0;36m__objFAB\u001b[1;34m(self, y, R, Q, h, E, A, K, eps, w, modeltype)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m             \u001b[0mlogP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getLogP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodeltype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodeltype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\explain_te\\defragTrees\\defragTrees.py\u001b[0m in \u001b[0;36m__getLogP\u001b[1;34m(self, k, y, R, h, E, A, eps, w, modeltype)\u001b[0m\n\u001b[0;32m    654\u001b[0m                 \u001b[0mlogP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m         \u001b[0mlogP\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m         \u001b[0mlogP\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlogP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_CHIRPS = False\n",
    "CHIRPS_sensitivity = False\n",
    "\n",
    "run_Anchors = False\n",
    "run_defragTrees = False\n",
    "\n",
    "# CHIRPS default set up\n",
    "merging_bootstraps = 20\n",
    "pruning_bootstraps = 20\n",
    "delta = 0.1\n",
    "kwargs_default = {'support_paths' : 0.1, 'alpha_paths' : 0.5, 'disc_path_bins' : 4, 'score_func' : 1, 'weighting' : 'chisq',\n",
    "                 'merging_bootstraps' : merging_bootstraps, 'pruning_bootstraps' : pruning_bootstraps, 'delta' : delta}\n",
    "\n",
    "\n",
    "# CHIRPS Sensitivity set up\n",
    "alpha_paths = np.tile([0.9, 0.5, 0.1], 24)\n",
    "disc_path_bins = np.tile(np.repeat([4, 8], 3), 12)\n",
    "score_func = np.tile(np.repeat([5, 3, 1], 6), 4)\n",
    "support_paths = np.tile(np.repeat([0.1, 0.05], 18), 2)\n",
    "weighting = np.repeat(['chisq', 'nothing'], 36)\n",
    "\n",
    "kwargs_grid = {k : {'alpha_paths' : ap, 'disc_path_bins' : dpb, 'score_func' : sf, 'weighting' : w, 'support_paths' : sp,\n",
    "                   'merging_bootstraps' : merging_bootstraps, 'pruning_bootstraps' : pruning_bootstraps, 'delta' : delta} \n",
    "    for k, ap, dpb, sf, w, sp in zip(range(72), alpha_paths, disc_path_bins, score_func, weighting, support_paths)}\n",
    "\n",
    "for random_state in range(123, 124):\n",
    "    for d_constructor in rp.datasets:\n",
    "        print('Running experiment for ' + d_constructor.__name__ + ' with random state = ' + str(random_state))\n",
    "        print()\n",
    "        # 1. Data and Forest prep\n",
    "        print('Split data into main train-test and build RF') \n",
    "        mydata = d_constructor(random_state=random_state, project_dir=project_dir)\n",
    "        \n",
    "        meta_data = mydata.get_meta()\n",
    "        save_path = meta_data['get_save_path']()\n",
    "        train_index, test_index = mydata.get_tt_split_idx(random_state=random_state_splits)\n",
    "        tt = mydata.tt_split(train_index, test_index)\n",
    "        \n",
    "        # this will train and score the model\n",
    "        rf = rp.forest_prep(ds_container=tt,\n",
    "                            meta_data=meta_data,\n",
    "                            save_path=save_path)\n",
    "\n",
    "        print()\n",
    "        if run_CHIRPS:\n",
    "            if CHIRPS_sensitivity:\n",
    "                for kwg in kwargs_grid:\n",
    "                    \n",
    "                    rp.CHIRPS_benchmark(forest=rf, ds_container=tt, meta_data=meta_data,\n",
    "                                        n_instances=n_instances,\n",
    "                                        forest_walk_async=forest_walk_async,\n",
    "                                        chirps_explanation_async=chirps_explanation_async,\n",
    "                                        save_path=save_path,\n",
    "                                        save_sensitivity_path=extend_path(stem=save_path, \\\n",
    "                                                              extensions=['sensitivity', \\\n",
    "                                                                'sp_' + str(kwargs_grid[kwg]['support_paths']) + \\\n",
    "                                                                '_ap_' + str(kwargs_grid[kwg]['alpha_paths']) + \\\n",
    "                                                                '_dpb_' + str(kwargs_grid[kwg]['disc_path_bins']) + \\\n",
    "                                                                '_sf_' + str(kwargs_grid[kwg]['score_func']) + \\\n",
    "                                                                '_w_' + str(kwargs_grid[kwg]['weighting']) + '_']),\n",
    "                                        dataset_name=d_constructor.__name__,\n",
    "                                        random_state=random_state, **kwargs_grid[kwg])\n",
    "                    \n",
    "                    # create a new ds_container as the last one is used up\n",
    "                    tt = mydata.tt_split(train_index, test_index)\n",
    "            else:\n",
    "                rp.CHIRPS_benchmark(forest=rf, ds_container=tt, meta_data=meta_data,\n",
    "                                    n_instances=n_instances,\n",
    "                                    forest_walk_async=forest_walk_async,\n",
    "                                    chirps_explanation_async=chirps_explanation_async,\n",
    "                                    save_path=save_path,\n",
    "                                    dataset_name=d_constructor.__name__,\n",
    "                                    random_state=random_state, **kwargs_default)\n",
    "                    \n",
    "        if run_Anchors:\n",
    "            # new copy of ds_container (need to reset the row counters)\n",
    "            tt_anch = mydata.tt_split(train_index, test_index)\n",
    "            # preprocessing - discretised continuous X matrix has been added and also needs an updated var_dict \n",
    "            # plus returning the fitted explainer that holds the data distribution\n",
    "            tt_anch, anchors_explainer = rp.Anchors_preproc(ds_container=tt_anch,\n",
    "                                                             meta_data=meta_data)\n",
    "    \n",
    "            # re-fitting the random forest to the discretised data and evaluating\n",
    "            rf = rp.forest_prep(ds_container=tt_anch,\n",
    "                            meta_data=meta_data,\n",
    "                            save_path=save_path,\n",
    "                            identifier='Anchors')\n",
    "\n",
    "            rp.Anchors_benchmark(forest=rf, ds_container=tt_anch, meta_data=meta_data,\n",
    "                                anchors_explainer=anchors_explainer,\n",
    "                                n_instances=n_instances,\n",
    "                                save_path=save_path, dataset_name=d_constructor.__name__,\n",
    "                                random_state=meta_data['random_state'])\n",
    "        \n",
    "        if run_defragTrees:\n",
    "            # create a new copy of tt split, because each one keeps track of which instances it has given out.\n",
    "            # re-using the top one means different instances are passed\n",
    "            tt_dfrgtrs = mydata.tt_split(train_index, test_index)\n",
    "            \n",
    "            # some dfrgtrs specific parameters\n",
    "            Kmax = 10\n",
    "            restart = 20\n",
    "            maxitr = 100\n",
    "            dfrgtrs, eval_start_time, defTrees_elapsed_time = rp.defragTrees_prep(ds_container=tt_dfrgtrs,\n",
    "                                                                                meta_data=meta_data, forest=rf, \n",
    "                                                                                Kmax=Kmax, restart=restart, maxitr=maxitr,\n",
    "                                                                                identifier='defragTrees', save_path=save_path)\n",
    "            \n",
    "                        \n",
    "            rp.defragTrees_benchmark(forest=rf, ds_container=tt_dfrgtrs, meta_data=meta_data,\n",
    "                                    dfrgtrs=dfrgtrs, eval_start_time=eval_start_time,\n",
    "                                    defTrees_elapsed_time=defTrees_elapsed_time,\n",
    "                                    n_instances=n_instances,\n",
    "                                    save_path=save_path, dataset_name=d_constructor.__name__,\n",
    "                                    random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
