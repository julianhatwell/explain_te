{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up notebook and load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load what we need\n",
    "import CHIRPS.datasets as ds\n",
    "import CHIRPS.reproducible as rp\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any dataset can be turned into a container by invoking the constructor found in the module structures.py, the only mandatory parameters are an object that can be input to pandas.DataFrame and a class column name. Your object needs either its own column names, or these should be passed as a list to the var_names parameter.\n",
    "\n",
    "Several datasets are available as pre-prepared containers that hold the data and some meta-data that is used in the algorithm. If these pre-packaged sets have more than 10,000 rows then we've included some downsampled versions. You can see what there is by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the builtins, np, pd, urllib and cfg. The rest are dataset constructors that will load specific datasets.\n",
    "if False:\n",
    "    dir(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see more information about each dataset with something like this for the adult dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(ds.adult().spiel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of one dataset is given below. Note that the random_state propagates through other functions via the meta_data and is easily updated to allow alternative runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    cardio = ds.cardio(random_state=123, project_dir=project_dir)\n",
    "    meta_data = cardio.get_meta()\n",
    "    meta_data['random_state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of datasets used in \"CHIRPS: Explaining Random Forest Classification\" is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    datasets = [\n",
    "            ds.adult,\n",
    "            ds.bankmark,\n",
    "            ds.car,\n",
    "            ds.cardio,\n",
    "            ds.credit,\n",
    "            ds.german,\n",
    "            ds.lending_tiny_samp,\n",
    "            ds.nursery,\n",
    "            ds.rcdv,\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of datasets used in \"Explaining Multi-class AdaBoost Classification in Medical Applications\" is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    datasets = [\n",
    "                ds.breast,\n",
    "                ds.cardio,\n",
    "                ds.diaretino,\n",
    "                ds.heart,\n",
    "                ds.mhtech14,\n",
    "                ds.mh2tech16,\n",
    "                ds.readmit,\n",
    "                ds.thyroid,\n",
    "                dsp.usoc2,\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising train-test splitting across environments\n",
    "To compare with methods in different environments, as we did in \"CHIRPS: Explaining Random Forest Classification,\" you can maintain the same dataset splits. The train test data is split with the one-time random_state_splits and the splits are saved to csv in the project folders. This way you can do same model with different data splits, or same data splits with different model. This is what's happening behind the scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### do not run this here\n",
    "# train_index, test_index = mydata.get_tt_split_idx(random_state=random_state_splits)\n",
    "# tt = mydata.tt_split(train_index, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All you need here is the following, to take the same train_index, test_index numbers to an external .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Runs\n",
    "From here on, everything is automated behind the scenes to perform runs across several datasets and comparing different algorithms with CHIRPS. If you want to run CHIRPS and control the parameters and view results and performance directly, look at the CHIRPS Examples Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# do the model tuning from scratch?\n",
    "override_tuning = False\n",
    "\n",
    "# Optional Memory and Computation Cost Management\n",
    "# CHIRPS is time economical but memory intensive to compute for lots of instances at once.\n",
    "forest_walk_async=True\n",
    "chirps_explanation_async=True\n",
    "n_cores = mp.cpu_count()-2\n",
    "\n",
    "# How many instances from the test set do you want to explain?\n",
    "# A number bigger than the test set will be interpreted as 'all'\n",
    "n_instances = 1000\n",
    "start_instance = 0 # here can opt to start at a specific instance, diagnostic if something crashes\n",
    "\n",
    "# CHOOSE ONE\n",
    "model = 'RandomForest'\n",
    "# model = 'AdaBoost1' # SAMME\n",
    "# model = 'AdaBoost2' # SAMME.R\n",
    "# model = 'GBM'\n",
    "\n",
    "# CHOOSE ONE OR MORE\n",
    "do_CHIRPS = True\n",
    "do_Anchors = False\n",
    "do_dfrgTrs = False\n",
    "do_lore = False\n",
    "\n",
    "# list the dataset constructors you want to include\n",
    "datasets = [\n",
    "#         ds.adult,\n",
    "#         ds.bankmark,\n",
    "#         ds.car,\n",
    "#         ds.cardio,\n",
    "#         ds.credit,\n",
    "#         ds.german,\n",
    "        ds.lending_tiny_samp,\n",
    "#         ds.nursery,\n",
    "#        ds.rcdv,\n",
    "       ]\n",
    "# datasets = [ds.cervicalh] # here can opt for just one but it must be a list, e.g. datasets = [datasets[0]]\n",
    "\n",
    "# location to save results\n",
    "project_dir = '/datadisk/whiteboxing/benchmarks2'\n",
    "# project_dir = 'V:\\\\whiteboxing\\\\tests' # defaults to a directory \"whiteboxing\" in the working directory\n",
    "# project_dir = 'C:\\\\Users\\\\Crutt\\\\Documents\\\\whiteboxing\\\\tests'\n",
    "\n",
    "# set the random_state for various tasks. This is not the same as random.seed(), not system wide.\n",
    "random_state_splits = 123 # change this if you want to try different splits of the data into test / train\n",
    "random_state_rf = 123 # change this if you want to try with different forest construction\n",
    "random_state_exp = 123 # change this if you want to try with different runs of the explainer algorithm (affects bootstrap eval)\n",
    "\n",
    "# To standardise train-test splitting across environments - writes external files\n",
    "rp.export_data_splits(datasets=datasets, project_dir=project_dir, random_state_splits=random_state_splits)\n",
    "\n",
    "# How much messaging to print to the screen?\n",
    "verbose = True\n",
    "\n",
    "# CHIRPS default parameters - see papers for details\n",
    "merging_bootstraps = 20 # how many training bootstraps to test improvement in growing rule?\n",
    "pruning_bootstraps = 20 # how many training bootstraps to test deterioration in pruning rule?\n",
    "delta = 0.1 # pruning deterioration tolerance paramater\n",
    "\n",
    "# this is here if you want to pass parameters to the methods\n",
    "def benchmark_wrapper(do_CHIRPS=do_CHIRPS, do_Anchors=do_Anchors, do_dfrgTrs=do_dfrgTrs, do_lore=do_lore, **control):\n",
    "\n",
    "    if do_CHIRPS:\n",
    "        rp.do_benchmarking(benchmark_items, verbose, **control)\n",
    "    \n",
    "    if do_Anchors:\n",
    "        control.update({'method' : 'Anchors'})\n",
    "        rp.do_benchmarking(benchmark_items, verbose, **control)\n",
    "    if do_dfrgTrs:\n",
    "        control.update({'method' : 'defragTrees',\n",
    "                    'Kmax' : 10, 'restart' : 100, 'maxitr' : 20})\n",
    "        rp.do_benchmarking(benchmark_items, verbose, **control)\n",
    "\n",
    "    if do_lore:\n",
    "        control.update({'method' : 'lore'})\n",
    "        rp.do_benchmarking(benchmark_items, verbose, **control)\n",
    "\n",
    "# this is here to pass parameters to the model training and further parameters to CHIRPS\n",
    "tuning = {'override' : override_tuning}\n",
    "if model == 'RandomForest':\n",
    "    tuning.update({'grid' : {'n_estimators': [(i + 1) * 200 for i in range(8)],\n",
    "                            'max_depth' : [32]}})\n",
    "    benchmark_items = rp.benchmarking_prep(datasets, model, tuning, project_dir,\n",
    "                                           random_state=random_state_rf,\n",
    "                                           random_state_splits=random_state_splits,\n",
    "                                           do_raw=True, do_discretise=do_Anchors,\n",
    "                                           start_instance=start_instance,\n",
    "                                           verbose=verbose, n_cores=n_cores)\n",
    "\n",
    "    kwargs = {'support_paths' : 0.2, 'alpha_paths' : 0.5, 'disc_path_bins' : 8,\n",
    "             'score_func' : 1, 'weighting' : 'kldiv',\n",
    "             'merging_bootstraps' : merging_bootstraps,\n",
    "             'pruning_bootstraps' : pruning_bootstraps,\n",
    "             'precis_threshold' : 0.99,\n",
    "             'delta' : delta}\n",
    " \n",
    "    control = {'method' : 'CHIRPS', 'model' : model,\n",
    "                'n_instances' : n_instances,\n",
    "                'random_state' : random_state_exp,\n",
    "                'kwargs' : kwargs,\n",
    "                'forest_walk_async' : forest_walk_async,\n",
    "                'chirps_explanation_async' : chirps_explanation_async,\n",
    "                'n_cores' : n_cores}\n",
    "    \n",
    "    benchmark_wrapper(do_CHIRPS, do_Anchors, do_dfrgTrs, do_lore, **control)\n",
    "    \n",
    "elif model == \"AdaBoost1\":\n",
    "    algo = 'SAMME'\n",
    "    max_depth = [i for i in range(1, 5)]\n",
    "    tuning.update({'grid' : {'base_estimator' : [rp.DecisionTreeClassifier(max_depth=d) for d in max_depth],\n",
    "                            'n_estimators': [(i + 1) * 200 for i in range(8)], 'algorithm': [algo]}})\n",
    "    benchmark_items = rp.benchmarking_prep(datasets, model, tuning, project_dir,\n",
    "                                       random_state=random_state_rf,\n",
    "                                       random_state_splits=random_state_splits,\n",
    "                                       do_raw=(do_CHIRPS or do_dfrgTrs), do_discretise=(do_Anchors or do_lore),\n",
    "                                       start_instance=start_instance,\n",
    "                                       verbose=verbose, n_cores=n_cores)\n",
    "    \n",
    "    kwargs = {'paths_lengths_threshold' : 5,\n",
    "             'support_paths' : 0.1, 'alpha_paths' : 0.0,\n",
    "             'disc_path_bins' : 4, 'disc_path_eqcounts' : True,\n",
    "             'score_func' : 1, 'weighting' : 'kldiv',\n",
    "             'merging_bootstraps' : merging_bootstraps,\n",
    "             'pruning_bootstraps' : pruning_bootstraps, 'delta' : delta}\n",
    " \n",
    "    control = {'method' : 'CHIRPS', 'model' : model,\n",
    "                'n_instances' : n_instances,\n",
    "                'random_state' : random_state_exp,\n",
    "                'kwargs' : kwargs,\n",
    "                'forest_walk_async' : forest_walk_async,\n",
    "                'chirps_explanation_async' : chirps_explanation_async,\n",
    "                'n_cores' : n_cores}\n",
    "    \n",
    "    benchmark_wrapper(do_CHIRPS, do_Anchors, do_dfrgTrs, do_lore, **control)\n",
    "    \n",
    "elif model == 'AdaBoost2':\n",
    "    algo = 'SAMME.R'\n",
    "    max_depth = [i for i in range(1, 5)]\n",
    "    tuning.update({'grid' : {'base_estimator' : [rp.DecisionTreeClassifier(max_depth=d) for d in max_depth],\n",
    "                            'n_estimators': [(i + 1) * 200 for i in range(8)], 'algorithm': [algo]}})\n",
    "    benchmark_items = rp.benchmarking_prep(datasets, model, tuning, project_dir,\n",
    "                                       random_state=random_state_rf,\n",
    "                                       random_state_splits=random_state_splits,\n",
    "                                       do_raw=True, do_discretise=do_Anchors,\n",
    "                                       start_instance=start_instance,\n",
    "                                       verbose=verbose, n_cores=n_cores)\n",
    "    \n",
    "    kwargs = {'paths_lengths_threshold' : 5,\n",
    "                 'support_paths' : 0.01, 'alpha_paths' : 0.0,\n",
    "                 'disc_path_bins' : 8, 'disc_path_eqcounts' : True,\n",
    "                 'score_func' : 1, 'weighting' : 'kldiv',\n",
    "                 'merging_bootstraps' : merging_bootstraps,\n",
    "                 'pruning_bootstraps' : pruning_bootstraps, 'delta' : delta}\n",
    "    \n",
    "    control = {'method' : 'CHIRPS', 'model' : model,\n",
    "                'n_instances' : n_instances,\n",
    "                'random_state' : random_state_exp,\n",
    "                'kwargs' : kwargs,\n",
    "                'forest_walk_async' : forest_walk_async,\n",
    "                'chirps_explanation_async' : chirps_explanation_async,\n",
    "                'n_cores' : n_cores}\n",
    "    \n",
    "    benchmark_wrapper(do_CHIRPS, do_Anchors, do_dfrgTrs, do_lore, **control)\n",
    "    \n",
    "\n",
    "    \n",
    "else: # GBM - not fully implemented yet\n",
    "    benchmark_items = rp.benchmarking_prep(datasets, model, tuning, project_dir,\n",
    "                                           random_state=123, random_state_splits=123,\n",
    "                                           start_instance=start_instance, verbose=verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
