{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up notebook and load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for notebook plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# load what we need\n",
    "import numpy as np\n",
    "import CHIRPS.datasets as ds\n",
    "import CHIRPS.reproducible as rp\n",
    "from CHIRPS.routines import extend_path\n",
    "\n",
    "# demo datasets that ship with package. all from UCI unless stated otherwise\n",
    "# ds.adult_data, ds.adult_samp_data, ds.adult_small_samp_data Large dataset ships with manageable sub samples\n",
    "# ds.bankmark_data, ds.bankmark_samp_data\n",
    "# ds.car_data\n",
    "# ds.cardio_data this is the cardiotocography dataset\n",
    "# ds.credit_data\n",
    "# ds.german_data\n",
    "# ds.lending_data, ds.lending_samp_data, ds.lending_small_samp_data, ds.lending_tiny_samp_data from Kaggle. see datasets_from_source file for links\n",
    "# ds.nursery_data, ds.nursery_samp_data\n",
    "# ds.rcdv_data, ds.rcdv_samp_data from US government see datasets_from_source file for links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common config - can be ommitted if defaults are OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'V:\\\\whiteboxing' # defaults to a directory \"whiteboxing\" in the working directory\n",
    "random_state_splits = 123 # one off for splitting the data into test / train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several datasets are available as pre-prepared containers that hold the data and some meta-data that is used in the algorithm\n",
    "Any dataset can be turned into a container by invoking the constructor found in the file structures.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function CHIRPS.datasets.adult_small_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.bankmark_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.car(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.cardio(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.credit(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.german(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.lending_tiny_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.nursery_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.rcdv_samp(random_state=123, project_dir=None)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets might be down-sampled to make them easier to work with\n",
    "# the full sets are available too\n",
    "# this is a list of constructors that will be used in the benchmarking\n",
    "rp.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CHIRPS.structures.data_container at 0x218c4392c88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of one dataset\n",
    "# note: random_state propagates through other functions and is easily updated to allow alternative runs\n",
    "ds.cardio(random_state=123, project_dir=project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardising train-test splitting\n",
    "Some methods are not available in Python. We want to maintain the same dataset splits no matter which platform. So, the train test data is split with the one-time random seed and the splits are saved to csv in the project folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported train-test data for 9 datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# writes external files\n",
    "rp.export_data_splits(datasets=rp.datasets, project_dir=project_dir, random_state_splits=random_state_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Runs\n",
    "Loop through datasets, actioning the functions in the package to execute a round of experiments and test evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Optional Memory and Computation Cost Management\n",
    "CHIRPS is time economical but memory intensive to compute for lots of instances at once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel processing\n",
    "Scikit takes care of parallel for the RF construction.\n",
    "We can parallelise the following:\n",
    "1. the walk of instances down each tree to collect the paths. The paths for many instances are returned in a single array. This parallelises across trees.\n",
    "2. building CHIRPS and the final explanation (rule). This is a search optimisation and we can parallelise each instance.\n",
    "\n",
    "This is expecially effective when running batches. For single instances, set both to false to avoid spinning up the parallel infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control for async processes - each tree walk can be done in its own core\n",
    "# and so can each explanation (e.g. rule conditions merge by hill-climbing)\n",
    "# these will default to false if not passed explicitly to the explainer function\n",
    "# on a multi-core machine there should be a good speed up for large batches\n",
    "# when the batch_size advantage exceeds the overhead of setting up multi-processing\n",
    "# timings will be printed to screen so you can see if it helps\n",
    "forest_walk_async=True\n",
    "chirps_explanation_async=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing unseen data\n",
    "\n",
    "Again note:\n",
    "test set has never been \"seen\" by random forest during training\n",
    "test set has been only used to assess model (random forest) accuracy - no additional tuning after this\n",
    "test set has not be involved in generating the explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching\n",
    "The memory space requirements for all the paths can be reduced by dividing the test set into batches. However this does take longer as there is an overhead to instantiate all the required objects, especially if coupled with parallel processing.\n",
    "Best compromise could be a small number of larger batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of instances can be controlled by\n",
    "# batch_size - how many instances to explain at one time\n",
    "# set these larger than the size of the test set and it will simply run the whole test set in one batch. Better do option 2\n",
    "batch_size = 10000\n",
    "# how many instances to explain in total from a test/unseen set\n",
    "n_instances = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data and Forest prep\n",
    "Use the random state splits to do a one-off data split.\n",
    "Fit the RF to training data, using the iterating random state.\n",
    "Save the performance metrics on the test set for later review.\n",
    "\n",
    "### 2. Prepare Unseen Data and Predictions\n",
    "Important to note:\n",
    "Test set never \"seen\" by RF during training.\n",
    "test set not involved in generating the explainer.\n",
    "Test set used to evaluate model (random forest) accuracy beyond OOBE scores - no additional tuning based on these results.\n",
    "Test set used to evaluate explanation scores by leave-one-out method removing the specific instance we're explaining.\n",
    "\n",
    "Important to note:\n",
    "We will explain predictions directly from the trained RF. Explanation system makes no compromise on model accuracy.\n",
    "\n",
    "### 3. CHIRPS algorithm\n",
    "1. Extract tree prediction paths\n",
    "2. Freqent pattern mining of paths\n",
    "3. Score and sort mined path segments\n",
    "4. Merge path segments into one rule\n",
    "\n",
    "#### CHIRPS 1\n",
    "Fit a forest_walker object to the dataset and decision forest. This is a wrapper that will extract the paths of all the given instances. Its main method delivers the instance paths for the remaining steps of the algorithm as a new object: a batch_paths_container. It can also report interesting statistics (treating the forest as a set of random tree-structured variables).\n",
    "\n",
    "#### CHIRPS 2-4\n",
    "A batch_CHIRPS_container is fitted with the batch_paths_container returned by the forest walker, and with a sample of data. For CHIRPS, we prefer a large sample. The whole training set or other representative sample will do. This is a wrapper object will execute steps 2-4 on all each the instance-paths in the batch_paths_container.\n",
    "\n",
    "Important to note:\n",
    "true_divide warnings are OK! It just means that a continuous variable is unbounded on one side i.e. no greater/less than inequality is used in the specific CHIRPS explanation.\n",
    "\n",
    "Important note: \n",
    "Here we are using the training set to create the explainers. We could use a different dataset as long as it is representative of the training set that built the decision forest. Most important that we don't use the dataset that we wish to explain, so never use the test set, for example.\n",
    "\n",
    "### 4. Evaluating CHIRPS Explanations\n",
    "Test set has been used to create an explainer *one instance at a time* and the rest of test set was not \"seen\" during this construction. To score each explainer, we use test set, leaving out the individual instance being explained. The data_split_container (tt) has a convenience funtion for doing this. All the results are saved to csv files in the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for adult_small_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.24, K = 1\n",
      "[Seed 124] TrainingError = 0.24, K = 3\n",
      "[Seed 125] TrainingError = 0.24, K = 2\n",
      "[Seed 126] TrainingError = 0.24, K = 1\n",
      "[Seed 127] TrainingError = 0.24, K = 2\n",
      "[Seed 128] TrainingError = 0.24, K = 3\n",
      "[Seed 129] TrainingError = 0.24, K = 1\n",
      "[Seed 130] TrainingError = 0.24, K = 2\n",
      "[Seed 131] TrainingError = 0.24, K = 2\n",
      "[Seed 132] TrainingError = 0.24, K = 2\n",
      "[Seed 133] TrainingError = 0.24, K = 2\n",
      "[Seed 134] TrainingError = 0.24, K = 2\n",
      "[Seed 135] TrainingError = 0.24, K = 1\n",
      "[Seed 136] TrainingError = 0.24, K = 2\n",
      "[Seed 137] TrainingError = 0.24, K = 2\n",
      "[Seed 138] TrainingError = 0.24, K = 2\n",
      "[Seed 139] TrainingError = 0.24, K = 1\n",
      "[Seed 140] TrainingError = 0.24, K = 1\n",
      "[Seed 141] TrainingError = 0.24, K = 1\n",
      "[Seed 142] TrainingError = 0.24, K = 2\n",
      "Optimal Model >> Seed 123, TrainingError = 0.24, K = 1\n",
      "Fit defragTrees time elapsed: 1146.8500 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.769441\n",
      "Coverage = 1.000000\n",
      "Overlap = 0.000000\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 263\n",
      "Working on defragTrees for instance 905\n",
      "Working on defragTrees for instance 1205\n",
      "Working on defragTrees for instance 1727\n",
      "Working on defragTrees for instance 1866\n",
      "Working on defragTrees for instance 2087\n",
      "Working on defragTrees for instance 2357\n",
      "Working on defragTrees for instance 1935\n",
      "Working on defragTrees for instance 742\n",
      "Working on defragTrees for instance 1597\n",
      "Working on defragTrees for instance 208\n",
      "Working on defragTrees for instance 1012\n",
      "Working on defragTrees for instance 1369\n",
      "Working on defragTrees for instance 21\n",
      "Working on defragTrees for instance 1383\n",
      "Working on defragTrees for instance 1191\n",
      "Working on defragTrees for instance 1234\n",
      "Working on defragTrees for instance 1620\n",
      "Working on defragTrees for instance 429\n",
      "Working on defragTrees for instance 1074\n",
      "Working on defragTrees for instance 1633\n",
      "Working on defragTrees for instance 1678\n",
      "Working on defragTrees for instance 1617\n",
      "Working on defragTrees for instance 2209\n",
      "Working on defragTrees for instance 1394\n",
      "Working on defragTrees for instance 2419\n",
      "Working on defragTrees for instance 1711\n",
      "Working on defragTrees for instance 215\n",
      "Working on defragTrees for instance 1844\n",
      "Working on defragTrees for instance 553\n",
      "Working on defragTrees for instance 1823\n",
      "Working on defragTrees for instance 1796\n",
      "Working on defragTrees for instance 1058\n",
      "Working on defragTrees for instance 1565\n",
      "Working on defragTrees for instance 72\n",
      "Working on defragTrees for instance 803\n",
      "Working on defragTrees for instance 116\n",
      "Working on defragTrees for instance 1657\n",
      "Working on defragTrees for instance 1469\n",
      "Working on defragTrees for instance 2174\n",
      "Working on defragTrees for instance 2165\n",
      "Working on defragTrees for instance 2145\n",
      "Working on defragTrees for instance 2157\n",
      "Working on defragTrees for instance 318\n",
      "Working on defragTrees for instance 2085\n",
      "Working on defragTrees for instance 1065\n",
      "Working on defragTrees for instance 1798\n",
      "Working on defragTrees for instance 292\n",
      "Working on defragTrees for instance 2074\n",
      "Working on defragTrees for instance 1215\n",
      "Working on defragTrees for instance 671\n",
      "Working on defragTrees for instance 1166\n",
      "Working on defragTrees for instance 188\n",
      "Working on defragTrees for instance 1462\n",
      "Working on defragTrees for instance 1458\n",
      "Working on defragTrees for instance 2300\n",
      "Working on defragTrees for instance 375\n",
      "Working on defragTrees for instance 891\n",
      "Working on defragTrees for instance 1563\n",
      "Working on defragTrees for instance 1975\n",
      "Working on defragTrees for instance 1026\n",
      "Working on defragTrees for instance 831\n",
      "Working on defragTrees for instance 1865\n",
      "Working on defragTrees for instance 1296\n",
      "Working on defragTrees for instance 1453\n",
      "Working on defragTrees for instance 711\n",
      "Working on defragTrees for instance 512\n",
      "Working on defragTrees for instance 81\n",
      "Working on defragTrees for instance 1882\n",
      "Working on defragTrees for instance 265\n",
      "Working on defragTrees for instance 35\n",
      "Working on defragTrees for instance 1193\n",
      "Working on defragTrees for instance 1604\n",
      "Working on defragTrees for instance 119\n",
      "Running experiment for bankmark_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.10, K = 1\n",
      "[Seed 124] TrainingError = 0.10, K = 2\n",
      "[Seed 125] TrainingError = 0.10, K = 1\n",
      "[Seed 126] TrainingError = 0.10, K = 1\n",
      "[Seed 127] TrainingError = 0.10, K = 2\n",
      "[Seed 128] TrainingError = 0.10, K = 2\n",
      "[Seed 129] TrainingError = 0.10, K = 1\n",
      "[Seed 130] TrainingError = 0.10, K = 2\n",
      "[Seed 131] TrainingError = 0.10, K = 2\n",
      "[Seed 132] TrainingError = 0.10, K = 2\n",
      "[Seed 133] TrainingError = 0.10, K = 2\n",
      "[Seed 134] TrainingError = 0.10, K = 1\n",
      "[Seed 135] TrainingError = 0.10, K = 2\n",
      "[Seed 136] TrainingError = 0.10, K = 1\n",
      "[Seed 137] TrainingError = 0.10, K = 1\n",
      "[Seed 138] TrainingError = 0.10, K = 2\n",
      "[Seed 139] TrainingError = 0.10, K = 2\n",
      "[Seed 140] TrainingError = 0.10, K = 2\n",
      "[Seed 141] TrainingError = 0.10, K = 2\n",
      "[Seed 142] TrainingError = 0.10, K = 1\n",
      "Optimal Model >> Seed 123, TrainingError = 0.10, K = 1\n",
      "Fit defragTrees time elapsed: 842.8470 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.880882\n",
      "Coverage = 1.000000\n",
      "Overlap = 0.000000\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 141\n",
      "Working on defragTrees for instance 890\n",
      "Working on defragTrees for instance 1676\n",
      "Working on defragTrees for instance 1665\n",
      "Working on defragTrees for instance 1158\n",
      "Working on defragTrees for instance 1765\n",
      "Working on defragTrees for instance 2104\n",
      "Working on defragTrees for instance 1573\n",
      "Working on defragTrees for instance 1950\n",
      "Working on defragTrees for instance 1014\n",
      "Working on defragTrees for instance 691\n",
      "Working on defragTrees for instance 701\n",
      "Working on defragTrees for instance 1097\n",
      "Working on defragTrees for instance 1394\n",
      "Working on defragTrees for instance 417\n",
      "Working on defragTrees for instance 1738\n",
      "Working on defragTrees for instance 809\n",
      "Working on defragTrees for instance 2067\n",
      "Working on defragTrees for instance 43\n",
      "Working on defragTrees for instance 1167\n",
      "Working on defragTrees for instance 846\n",
      "Working on defragTrees for instance 75\n",
      "Working on defragTrees for instance 591\n",
      "Working on defragTrees for instance 1694\n",
      "Working on defragTrees for instance 1026\n",
      "Working on defragTrees for instance 188\n",
      "Working on defragTrees for instance 831\n",
      "Working on defragTrees for instance 1976\n",
      "Working on defragTrees for instance 2070\n",
      "Working on defragTrees for instance 1522\n",
      "Working on defragTrees for instance 108\n",
      "Working on defragTrees for instance 1924\n",
      "Working on defragTrees for instance 1642\n",
      "Working on defragTrees for instance 961\n",
      "Working on defragTrees for instance 1208\n",
      "Working on defragTrees for instance 1762\n",
      "Working on defragTrees for instance 1799\n",
      "Working on defragTrees for instance 273\n",
      "Working on defragTrees for instance 356\n",
      "Working on defragTrees for instance 628\n",
      "Working on defragTrees for instance 1518\n",
      "Working on defragTrees for instance 1399\n",
      "Working on defragTrees for instance 1313\n",
      "Working on defragTrees for instance 1825\n",
      "Working on defragTrees for instance 2135\n",
      "Working on defragTrees for instance 265\n",
      "Working on defragTrees for instance 679\n",
      "Working on defragTrees for instance 1011\n",
      "Working on defragTrees for instance 968\n",
      "Working on defragTrees for instance 328\n",
      "Working on defragTrees for instance 1067\n",
      "Working on defragTrees for instance 2068\n",
      "Working on defragTrees for instance 1601\n",
      "Working on defragTrees for instance 633\n",
      "Working on defragTrees for instance 2134\n",
      "Working on defragTrees for instance 1701\n",
      "Working on defragTrees for instance 1801\n",
      "Working on defragTrees for instance 1600\n",
      "Working on defragTrees for instance 1337\n",
      "Working on defragTrees for instance 842\n",
      "Working on defragTrees for instance 533\n",
      "Working on defragTrees for instance 2110\n",
      "Working on defragTrees for instance 226\n",
      "Working on defragTrees for instance 822\n",
      "Working on defragTrees for instance 357\n",
      "Working on defragTrees for instance 602\n",
      "Working on defragTrees for instance 1528\n",
      "Working on defragTrees for instance 1716\n",
      "Running experiment for car with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.29, K = 2\n",
      "[Seed 124] TrainingError = 0.29, K = 4\n",
      "[Seed 125] TrainingError = 0.29, K = 3\n",
      "[Seed 126] TrainingError = 0.29, K = 3\n",
      "[Seed 127] TrainingError = 0.29, K = 3\n",
      "[Seed 128] TrainingError = 0.29, K = 3\n",
      "[Seed 129] TrainingError = 0.29, K = 3\n",
      "[Seed 130] TrainingError = 0.29, K = 4\n",
      "[Seed 131] TrainingError = 0.29, K = 2\n",
      "[Seed 132] TrainingError = 0.29, K = 2\n",
      "[Seed 133] TrainingError = 0.29, K = 4\n",
      "[Seed 134] TrainingError = 0.29, K = 3\n",
      "[Seed 135] TrainingError = 0.29, K = 2\n",
      "[Seed 136] TrainingError = 0.29, K = 3\n",
      "[Seed 137] TrainingError = 0.29, K = 2\n",
      "[Seed 138] TrainingError = 0.28, K = 4\n",
      "[Seed 139] TrainingError = 0.29, K = 2\n",
      "[Seed 140] TrainingError = 0.29, K = 2\n",
      "[Seed 141] TrainingError = 0.29, K = 2\n",
      "[Seed 142] TrainingError = 0.28, K = 3\n",
      "Optimal Model >> Seed 142, TrainingError = 0.28, K = 3\n",
      "Fit defragTrees time elapsed: 183.3384 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.704633\n",
      "Coverage = 1.000000\n",
      "Overlap = 0.355212\n",
      "defragTrees benchmark\n",
      "Working on defragTrees for instance 1633\n",
      "Working on defragTrees for instance 1009\n",
      "Working on defragTrees for instance 1663\n",
      "Working on defragTrees for instance 120\n",
      "Working on defragTrees for instance 1338\n",
      "Working on defragTrees for instance 1008\n",
      "Working on defragTrees for instance 1558\n",
      "Working on defragTrees for instance 1661\n",
      "Working on defragTrees for instance 1114\n",
      "Working on defragTrees for instance 980\n",
      "Working on defragTrees for instance 357\n",
      "Working on defragTrees for instance 31\n",
      "Working on defragTrees for instance 403\n",
      "Working on defragTrees for instance 206\n",
      "Working on defragTrees for instance 129\n",
      "Working on defragTrees for instance 637\n",
      "Working on defragTrees for instance 674\n",
      "Working on defragTrees for instance 1198\n",
      "Working on defragTrees for instance 1658\n",
      "Working on defragTrees for instance 63\n",
      "Working on defragTrees for instance 822\n",
      "Working on defragTrees for instance 1373\n",
      "Working on defragTrees for instance 410\n",
      "Working on defragTrees for instance 1126\n",
      "Working on defragTrees for instance 134\n",
      "Working on defragTrees for instance 1501\n",
      "Working on defragTrees for instance 249\n",
      "Working on defragTrees for instance 700\n",
      "Working on defragTrees for instance 841\n",
      "Working on defragTrees for instance 327\n",
      "Working on defragTrees for instance 1717\n",
      "Working on defragTrees for instance 813\n",
      "Working on defragTrees for instance 328\n",
      "Working on defragTrees for instance 1259\n",
      "Working on defragTrees for instance 1413\n",
      "Working on defragTrees for instance 334\n",
      "Working on defragTrees for instance 1265\n",
      "Working on defragTrees for instance 535\n",
      "Working on defragTrees for instance 597\n",
      "Working on defragTrees for instance 75\n",
      "Working on defragTrees for instance 932\n",
      "Working on defragTrees for instance 1715\n",
      "Working on defragTrees for instance 879\n",
      "Working on defragTrees for instance 1474\n",
      "Working on defragTrees for instance 684\n",
      "Working on defragTrees for instance 1399\n",
      "Working on defragTrees for instance 314\n",
      "Working on defragTrees for instance 1515\n",
      "Working on defragTrees for instance 85\n",
      "Working on defragTrees for instance 1414\n",
      "Working on defragTrees for instance 1183\n",
      "Working on defragTrees for instance 1637\n",
      "Running experiment for cardio with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n",
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.22, K = 2\n",
      "[Seed 124] TrainingError = 0.22, K = 2\n",
      "[Seed 125] TrainingError = 0.22, K = 1\n",
      "[Seed 126] TrainingError = 0.22, K = 2\n",
      "[Seed 127] TrainingError = 0.22, K = 4\n",
      "[Seed 128] TrainingError = 0.20, K = 3\n",
      "[Seed 129] TrainingError = 0.22, K = 4\n",
      "[Seed 130] TrainingError = 0.22, K = 2\n",
      "[Seed 131] TrainingError = 0.18, K = 5\n",
      "[Seed 132] TrainingError = 0.19, K = 4\n",
      "[Seed 133] TrainingError = 0.20, K = 3\n",
      "[Seed 134] TrainingError = 0.22, K = 4\n",
      "[Seed 135] TrainingError = 0.22, K = 1\n",
      "[Seed 136] TrainingError = 0.20, K = 4\n",
      "[Seed 137] TrainingError = 0.17, K = 4\n",
      "[Seed 138] TrainingError = 0.22, K = 2\n",
      "[Seed 139] TrainingError = 0.22, K = 3\n",
      "[Seed 140] TrainingError = 0.21, K = 3\n",
      "[Seed 141] TrainingError = 0.22, K = 1\n",
      "[Seed 142] TrainingError = 0.22, K = 2\n",
      "Optimal Model >> Seed 137, TrainingError = 0.17, K = 4\n",
      "Fit defragTrees time elapsed: 318.1592 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.826019\n",
      "Coverage = 0.985893\n",
      "Overlap = 0.316614\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 63\n",
      "Working on defragTrees for instance 1726\n",
      "Working on defragTrees for instance 594\n",
      "Working on defragTrees for instance 772\n",
      "Working on defragTrees for instance 1155\n",
      "Working on defragTrees for instance 1503\n",
      "Working on defragTrees for instance 1391\n",
      "Working on defragTrees for instance 1286\n",
      "Working on defragTrees for instance 1848\n",
      "Working on defragTrees for instance 433\n",
      "Working on defragTrees for instance 1298\n",
      "Working on defragTrees for instance 1702\n",
      "Working on defragTrees for instance 381\n",
      "Working on defragTrees for instance 565\n",
      "Working on defragTrees for instance 1737\n",
      "Working on defragTrees for instance 1026\n",
      "Working on defragTrees for instance 680\n",
      "Working on defragTrees for instance 1640\n",
      "Working on defragTrees for instance 556\n",
      "Working on defragTrees for instance 1216\n",
      "Working on defragTrees for instance 704\n",
      "Working on defragTrees for instance 550\n",
      "Working on defragTrees for instance 838\n",
      "Working on defragTrees for instance 1659\n",
      "Working on defragTrees for instance 72\n",
      "Working on defragTrees for instance 265\n",
      "Working on defragTrees for instance 914\n",
      "Working on defragTrees for instance 1850\n",
      "Working on defragTrees for instance 198\n",
      "Working on defragTrees for instance 948\n",
      "Working on defragTrees for instance 343\n",
      "Working on defragTrees for instance 1273\n",
      "Working on defragTrees for instance 2068\n",
      "Working on defragTrees for instance 1057\n",
      "Working on defragTrees for instance 1350\n",
      "Working on defragTrees for instance 86\n",
      "Working on defragTrees for instance 1948\n",
      "Working on defragTrees for instance 944\n",
      "Working on defragTrees for instance 218\n",
      "Working on defragTrees for instance 1495\n",
      "Working on defragTrees for instance 75\n",
      "Working on defragTrees for instance 1587\n",
      "Working on defragTrees for instance 822\n",
      "Working on defragTrees for instance 35\n",
      "Working on defragTrees for instance 1576\n",
      "Working on defragTrees for instance 1467\n",
      "Working on defragTrees for instance 875\n",
      "Working on defragTrees for instance 996\n",
      "Working on defragTrees for instance 31\n",
      "Working on defragTrees for instance 1485\n",
      "Working on defragTrees for instance 61\n",
      "Working on defragTrees for instance 605\n",
      "Working on defragTrees for instance 1067\n",
      "Working on defragTrees for instance 627\n",
      "Working on defragTrees for instance 1993\n",
      "Working on defragTrees for instance 1963\n",
      "Working on defragTrees for instance 1812\n",
      "Working on defragTrees for instance 1422\n",
      "Working on defragTrees for instance 610\n",
      "Working on defragTrees for instance 15\n",
      "Working on defragTrees for instance 1173\n",
      "Working on defragTrees for instance 732\n",
      "Working on defragTrees for instance 1215\n",
      "Working on defragTrees for instance 1964\n",
      "Running experiment for credit with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.43, K = 1\n",
      "[Seed 124] TrainingError = 0.43, K = 1\n",
      "[Seed 125] TrainingError = 0.14, K = 2\n",
      "[Seed 126] TrainingError = 0.43, K = 1\n",
      "[Seed 127] TrainingError = 0.43, K = 1\n",
      "[Seed 128] TrainingError = 0.43, K = 1\n",
      "[Seed 129] TrainingError = 0.43, K = 1\n",
      "[Seed 130] TrainingError = 0.43, K = 1\n",
      "[Seed 131] TrainingError = 0.43, K = 1\n",
      "[Seed 132] TrainingError = 0.43, K = 1\n",
      "[Seed 133] TrainingError = 0.43, K = 1\n",
      "[Seed 134] TrainingError = 0.43, K = 1\n",
      "[Seed 135] TrainingError = 0.43, K = 1\n",
      "[Seed 136] TrainingError = 0.43, K = 1\n",
      "[Seed 137] TrainingError = 0.14, K = 2\n",
      "[Seed 138] TrainingError = 0.43, K = 1\n",
      "[Seed 139] TrainingError = 0.43, K = 1\n",
      "[Seed 140] TrainingError = 0.43, K = 1\n",
      "[Seed 141] TrainingError = 0.43, K = 1\n",
      "[Seed 142] TrainingError = 0.43, K = 1\n",
      "Optimal Model >> Seed 125, TrainingError = 0.14, K = 2\n",
      "Fit defragTrees time elapsed: 141.5855 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.859903\n",
      "Coverage = 0.990338\n",
      "Overlap = 0.463768\n",
      "defragTrees benchmark\n",
      "Working on defragTrees for instance 587\n",
      "Working on defragTrees for instance 631\n",
      "Working on defragTrees for instance 686\n",
      "Working on defragTrees for instance 688\n",
      "Working on defragTrees for instance 138\n",
      "Working on defragTrees for instance 345\n",
      "Working on defragTrees for instance 457\n",
      "Working on defragTrees for instance 453\n",
      "Working on defragTrees for instance 82\n",
      "Working on defragTrees for instance 252\n",
      "Working on defragTrees for instance 529\n",
      "Working on defragTrees for instance 592\n",
      "Working on defragTrees for instance 533\n",
      "Working on defragTrees for instance 584\n",
      "Working on defragTrees for instance 120\n",
      "Working on defragTrees for instance 177\n",
      "Working on defragTrees for instance 511\n",
      "Working on defragTrees for instance 217\n",
      "Working on defragTrees for instance 285\n",
      "Working on defragTrees for instance 437\n",
      "Working on defragTrees for instance 275\n",
      "Running experiment for german with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.30, K = 1\n",
      "[Seed 124] TrainingError = 0.30, K = 2\n",
      "[Seed 125] TrainingError = 0.30, K = 1\n",
      "[Seed 126] TrainingError = 0.30, K = 1\n",
      "[Seed 127] TrainingError = 0.30, K = 2\n",
      "[Seed 128] TrainingError = 0.30, K = 1\n",
      "[Seed 129] TrainingError = 0.30, K = 1\n",
      "[Seed 130] TrainingError = 0.30, K = 1\n",
      "[Seed 131] TrainingError = 0.30, K = 2\n",
      "[Seed 132] TrainingError = 0.30, K = 2\n",
      "[Seed 133] TrainingError = 0.30, K = 1\n",
      "[Seed 134] TrainingError = 0.30, K = 1\n",
      "[Seed 135] TrainingError = 0.30, K = 1\n",
      "[Seed 136] TrainingError = 0.30, K = 2\n",
      "[Seed 137] TrainingError = 0.30, K = 1\n",
      "[Seed 138] TrainingError = 0.30, K = 1\n",
      "[Seed 139] TrainingError = 0.30, K = 3\n",
      "[Seed 140] TrainingError = 0.30, K = 2\n",
      "[Seed 141] TrainingError = 0.30, K = 2\n",
      "[Seed 142] TrainingError = 0.30, K = 2\n",
      "Optimal Model >> Seed 123, TrainingError = 0.30, K = 1\n",
      "Fit defragTrees time elapsed: 233.7488 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.706667\n",
      "Coverage = 1.000000\n",
      "Overlap = 0.000000\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 131\n",
      "Working on defragTrees for instance 195\n",
      "Working on defragTrees for instance 372\n",
      "Working on defragTrees for instance 721\n",
      "Working on defragTrees for instance 770\n",
      "Working on defragTrees for instance 161\n",
      "Working on defragTrees for instance 470\n",
      "Working on defragTrees for instance 345\n",
      "Working on defragTrees for instance 437\n",
      "Working on defragTrees for instance 992\n",
      "Working on defragTrees for instance 538\n",
      "Working on defragTrees for instance 827\n",
      "Working on defragTrees for instance 829\n",
      "Working on defragTrees for instance 952\n",
      "Working on defragTrees for instance 298\n",
      "Working on defragTrees for instance 922\n",
      "Working on defragTrees for instance 204\n",
      "Working on defragTrees for instance 758\n",
      "Working on defragTrees for instance 816\n",
      "Working on defragTrees for instance 388\n",
      "Working on defragTrees for instance 511\n",
      "Working on defragTrees for instance 75\n",
      "Working on defragTrees for instance 880\n",
      "Working on defragTrees for instance 13\n",
      "Working on defragTrees for instance 719\n",
      "Working on defragTrees for instance 893\n",
      "Working on defragTrees for instance 273\n",
      "Working on defragTrees for instance 107\n",
      "Working on defragTrees for instance 670\n",
      "Working on defragTrees for instance 913\n",
      "Running experiment for lending_tiny_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.21, K = 2\n",
      "[Seed 124] TrainingError = 0.21, K = 2\n",
      "[Seed 125] TrainingError = 0.21, K = 1\n",
      "[Seed 126] TrainingError = 0.21, K = 1\n",
      "[Seed 127] TrainingError = 0.21, K = 2\n",
      "[Seed 128] TrainingError = 0.21, K = 3\n",
      "[Seed 129] TrainingError = 0.21, K = 1\n",
      "[Seed 130] TrainingError = 0.21, K = 1\n",
      "[Seed 131] TrainingError = 0.21, K = 2\n",
      "[Seed 132] TrainingError = 0.21, K = 2\n",
      "[Seed 133] TrainingError = 0.21, K = 1\n",
      "[Seed 134] TrainingError = 0.21, K = 2\n",
      "[Seed 135] TrainingError = 0.21, K = 3\n",
      "[Seed 136] TrainingError = 0.21, K = 2\n",
      "[Seed 137] TrainingError = 0.21, K = 2\n",
      "[Seed 138] TrainingError = 0.21, K = 2\n",
      "[Seed 139] TrainingError = 0.21, K = 1\n",
      "[Seed 140] TrainingError = 0.21, K = 2\n",
      "[Seed 141] TrainingError = 0.21, K = 3\n",
      "[Seed 142] TrainingError = 0.21, K = 2\n",
      "Optimal Model >> Seed 123, TrainingError = 0.21, K = 2\n",
      "Fit defragTrees time elapsed: 1331.9734 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.816456\n",
      "Coverage = 0.957278\n",
      "Overlap = 0.549051\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 2037\n",
      "Working on defragTrees for instance 698\n",
      "Working on defragTrees for instance 1516\n",
      "Working on defragTrees for instance 1758\n",
      "Working on defragTrees for instance 256\n",
      "Working on defragTrees for instance 1712\n",
      "Working on defragTrees for instance 711\n",
      "Working on defragTrees for instance 1021\n",
      "Working on defragTrees for instance 292\n",
      "Working on defragTrees for instance 868\n",
      "Working on defragTrees for instance 1835\n",
      "Working on defragTrees for instance 1873\n",
      "Working on defragTrees for instance 1476\n",
      "Working on defragTrees for instance 235\n",
      "Working on defragTrees for instance 2040\n",
      "Working on defragTrees for instance 356\n",
      "Working on defragTrees for instance 775\n",
      "Working on defragTrees for instance 1924\n",
      "Working on defragTrees for instance 1998\n",
      "Working on defragTrees for instance 1511\n",
      "Working on defragTrees for instance 1029\n",
      "Working on defragTrees for instance 182\n",
      "Working on defragTrees for instance 1171\n",
      "Working on defragTrees for instance 28\n",
      "Working on defragTrees for instance 615\n",
      "Working on defragTrees for instance 1613\n",
      "Working on defragTrees for instance 1077\n",
      "Working on defragTrees for instance 94\n",
      "Working on defragTrees for instance 679\n",
      "Working on defragTrees for instance 553\n",
      "Working on defragTrees for instance 1272\n",
      "Working on defragTrees for instance 204\n",
      "Working on defragTrees for instance 1432\n",
      "Working on defragTrees for instance 1730\n",
      "Working on defragTrees for instance 1364\n",
      "Working on defragTrees for instance 1327\n",
      "Working on defragTrees for instance 1193\n",
      "Working on defragTrees for instance 112\n",
      "Working on defragTrees for instance 1233\n",
      "Working on defragTrees for instance 306\n",
      "Working on defragTrees for instance 1813\n",
      "Working on defragTrees for instance 1466\n",
      "Working on defragTrees for instance 668\n",
      "Working on defragTrees for instance 914\n",
      "Working on defragTrees for instance 252\n",
      "Working on defragTrees for instance 772\n",
      "Working on defragTrees for instance 276\n",
      "Working on defragTrees for instance 537\n",
      "Working on defragTrees for instance 828\n",
      "Working on defragTrees for instance 203\n",
      "Working on defragTrees for instance 1975\n",
      "Working on defragTrees for instance 1738\n",
      "Working on defragTrees for instance 678\n",
      "Working on defragTrees for instance 374\n",
      "Working on defragTrees for instance 1735\n",
      "Working on defragTrees for instance 670\n",
      "Working on defragTrees for instance 1335\n",
      "Working on defragTrees for instance 838\n",
      "Working on defragTrees for instance 1756\n",
      "Working on defragTrees for instance 1645\n",
      "Working on defragTrees for instance 1799\n",
      "Working on defragTrees for instance 1214\n",
      "Working on defragTrees for instance 1121\n",
      "Working on defragTrees for instance 332\n",
      "Running experiment for nursery_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.66, K = 2\n",
      "[Seed 124] TrainingError = 0.66, K = 1\n",
      "[Seed 125] TrainingError = 0.64, K = 2\n",
      "[Seed 126] TrainingError = 0.64, K = 2\n",
      "[Seed 127] TrainingError = 0.66, K = 1\n",
      "[Seed 128] TrainingError = 0.66, K = 2\n",
      "[Seed 129] TrainingError = 0.63, K = 3\n",
      "[Seed 130] TrainingError = 0.64, K = 2\n",
      "[Seed 131] TrainingError = 0.65, K = 2\n",
      "[Seed 132] TrainingError = 0.64, K = 2\n",
      "[Seed 133] TrainingError = 0.65, K = 2\n",
      "[Seed 134] TrainingError = 0.64, K = 2\n",
      "[Seed 135] TrainingError = 0.66, K = 1\n",
      "[Seed 136] TrainingError = 0.66, K = 1\n",
      "[Seed 137] TrainingError = 0.65, K = 2\n",
      "[Seed 138] TrainingError = 0.66, K = 1\n",
      "[Seed 139] TrainingError = 0.64, K = 2\n",
      "[Seed 140] TrainingError = 0.64, K = 2\n",
      "[Seed 141] TrainingError = 0.66, K = 2\n",
      "[Seed 142] TrainingError = 0.64, K = 2\n",
      "Optimal Model >> Seed 129, TrainingError = 0.63, K = 3\n",
      "Fit defragTrees time elapsed: 2073.2457 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.367609\n",
      "Coverage = 1.000000\n",
      "Overlap = 0.000000\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 33\n",
      "Working on defragTrees for instance 2300\n",
      "Working on defragTrees for instance 379\n",
      "Working on defragTrees for instance 2347\n",
      "Working on defragTrees for instance 403\n",
      "Working on defragTrees for instance 440\n",
      "Working on defragTrees for instance 1501\n",
      "Working on defragTrees for instance 1951\n",
      "Working on defragTrees for instance 2325\n",
      "Working on defragTrees for instance 813\n",
      "Working on defragTrees for instance 673\n",
      "Working on defragTrees for instance 2423\n",
      "Working on defragTrees for instance 1000\n",
      "Working on defragTrees for instance 746\n",
      "Working on defragTrees for instance 252\n",
      "Working on defragTrees for instance 2330\n",
      "Working on defragTrees for instance 1628\n",
      "Working on defragTrees for instance 132\n",
      "Working on defragTrees for instance 2110\n",
      "Working on defragTrees for instance 2525\n",
      "Working on defragTrees for instance 649\n",
      "Working on defragTrees for instance 1185\n",
      "Working on defragTrees for instance 2362\n",
      "Working on defragTrees for instance 2358\n",
      "Working on defragTrees for instance 2349\n",
      "Working on defragTrees for instance 1791\n",
      "Working on defragTrees for instance 1533\n",
      "Working on defragTrees for instance 1801\n",
      "Working on defragTrees for instance 1729\n",
      "Working on defragTrees for instance 1338\n",
      "Working on defragTrees for instance 116\n",
      "Working on defragTrees for instance 270\n",
      "Working on defragTrees for instance 1113\n",
      "Working on defragTrees for instance 2567\n",
      "Working on defragTrees for instance 1481\n",
      "Working on defragTrees for instance 827\n",
      "Working on defragTrees for instance 1700\n",
      "Working on defragTrees for instance 2254\n",
      "Working on defragTrees for instance 1697\n",
      "Working on defragTrees for instance 1127\n",
      "Working on defragTrees for instance 2560\n",
      "Working on defragTrees for instance 380\n",
      "Working on defragTrees for instance 1952\n",
      "Working on defragTrees for instance 2562\n",
      "Working on defragTrees for instance 2117\n",
      "Working on defragTrees for instance 777\n",
      "Working on defragTrees for instance 1572\n",
      "Working on defragTrees for instance 2361\n",
      "Working on defragTrees for instance 1466\n",
      "Working on defragTrees for instance 2079\n",
      "Working on defragTrees for instance 1360\n",
      "Working on defragTrees for instance 891\n",
      "Working on defragTrees for instance 1815\n",
      "Working on defragTrees for instance 957\n",
      "Working on defragTrees for instance 326\n",
      "Working on defragTrees for instance 2445\n",
      "Working on defragTrees for instance 1730\n",
      "Working on defragTrees for instance 452\n",
      "Working on defragTrees for instance 2309\n",
      "Working on defragTrees for instance 1906\n",
      "Working on defragTrees for instance 645\n",
      "Working on defragTrees for instance 1834\n",
      "Working on defragTrees for instance 2395\n",
      "Working on defragTrees for instance 188\n",
      "Working on defragTrees for instance 914\n",
      "Working on defragTrees for instance 1624\n",
      "Working on defragTrees for instance 574\n",
      "Working on defragTrees for instance 767\n",
      "Working on defragTrees for instance 350\n",
      "Working on defragTrees for instance 1227\n",
      "Working on defragTrees for instance 2429\n",
      "Working on defragTrees for instance 1488\n",
      "Working on defragTrees for instance 1661\n",
      "Working on defragTrees for instance 2293\n",
      "Working on defragTrees for instance 1283\n",
      "Working on defragTrees for instance 2109\n",
      "Working on defragTrees for instance 1621\n",
      "Working on defragTrees for instance 1137\n",
      "Running experiment for rcdv_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n",
      "\n",
      "Running defragTrees\n",
      "\n",
      "[Seed 123] TrainingError = 0.38, K = 1\n",
      "[Seed 124] TrainingError = 0.38, K = 2\n",
      "[Seed 125] TrainingError = 0.38, K = 2\n",
      "[Seed 126] TrainingError = 0.38, K = 1\n",
      "[Seed 127] TrainingError = 0.38, K = 2\n",
      "[Seed 128] TrainingError = 0.38, K = 2\n",
      "[Seed 129] TrainingError = 0.38, K = 1\n",
      "[Seed 130] TrainingError = 0.38, K = 1\n",
      "[Seed 131] TrainingError = 0.38, K = 2\n",
      "[Seed 132] TrainingError = 0.38, K = 1\n",
      "[Seed 133] TrainingError = 0.38, K = 1\n",
      "[Seed 134] TrainingError = 0.38, K = 2\n",
      "[Seed 135] TrainingError = 0.38, K = 1\n",
      "[Seed 136] TrainingError = 0.38, K = 2\n",
      "[Seed 137] TrainingError = 0.38, K = 1\n",
      "[Seed 138] TrainingError = 0.38, K = 2\n",
      "[Seed 139] TrainingError = 0.38, K = 1\n",
      "[Seed 140] TrainingError = 0.38, K = 1\n",
      "[Seed 141] TrainingError = 0.38, K = 1\n",
      "[Seed 142] TrainingError = 0.38, K = 2\n",
      "Optimal Model >> Seed 123, TrainingError = 0.38, K = 1\n",
      "Fit defragTrees time elapsed: 926.9903 seconds\n",
      "\n",
      "defragTrees test accuracy\n",
      "Accuracy = 0.618375\n",
      "Coverage = 1.000000\n",
      "Overlap = 0.000000\n",
      "defragTrees benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on defragTrees for instance 1752\n",
      "Working on defragTrees for instance 1202\n",
      "Working on defragTrees for instance 1728\n",
      "Working on defragTrees for instance 512\n",
      "Working on defragTrees for instance 827\n",
      "Working on defragTrees for instance 637\n",
      "Working on defragTrees for instance 266\n",
      "Working on defragTrees for instance 1629\n",
      "Working on defragTrees for instance 717\n",
      "Working on defragTrees for instance 522\n",
      "Working on defragTrees for instance 328\n",
      "Working on defragTrees for instance 1518\n",
      "Working on defragTrees for instance 746\n",
      "Working on defragTrees for instance 958\n",
      "Working on defragTrees for instance 553\n",
      "Working on defragTrees for instance 600\n",
      "Working on defragTrees for instance 1587\n",
      "Working on defragTrees for instance 655\n",
      "Working on defragTrees for instance 1102\n",
      "Working on defragTrees for instance 668\n",
      "Working on defragTrees for instance 155\n",
      "Working on defragTrees for instance 1412\n",
      "Working on defragTrees for instance 1259\n",
      "Working on defragTrees for instance 1501\n",
      "Working on defragTrees for instance 382\n",
      "Working on defragTrees for instance 1026\n",
      "Working on defragTrees for instance 1502\n",
      "Working on defragTrees for instance 468\n",
      "Working on defragTrees for instance 310\n",
      "Working on defragTrees for instance 18\n",
      "Working on defragTrees for instance 962\n",
      "Working on defragTrees for instance 388\n",
      "Working on defragTrees for instance 912\n",
      "Working on defragTrees for instance 1829\n",
      "Working on defragTrees for instance 134\n",
      "Working on defragTrees for instance 1876\n",
      "Working on defragTrees for instance 196\n",
      "Working on defragTrees for instance 971\n",
      "Working on defragTrees for instance 546\n",
      "Working on defragTrees for instance 1181\n",
      "Working on defragTrees for instance 395\n",
      "Working on defragTrees for instance 1598\n",
      "Working on defragTrees for instance 161\n",
      "Working on defragTrees for instance 1060\n",
      "Working on defragTrees for instance 1290\n",
      "Working on defragTrees for instance 1174\n",
      "Working on defragTrees for instance 1067\n",
      "Working on defragTrees for instance 166\n",
      "Working on defragTrees for instance 1688\n",
      "Working on defragTrees for instance 1170\n",
      "Working on defragTrees for instance 110\n",
      "Working on defragTrees for instance 1375\n",
      "Working on defragTrees for instance 988\n",
      "Working on defragTrees for instance 1177\n",
      "Working on defragTrees for instance 1369\n",
      "Working on defragTrees for instance 784\n",
      "Working on defragTrees for instance 1735\n"
     ]
    }
   ],
   "source": [
    "run_CHIRPS = False\n",
    "run_Anchors = False\n",
    "run_defragTrees = True\n",
    "\n",
    "CHIRPS_sensitivity = False\n",
    "\n",
    "alpha_paths = np.tile([0.9, 0.5, 0.1], 24)\n",
    "disc_path_bins = np.tile(np.repeat([4, 8], 3), 12)\n",
    "score_func = np.tile(np.repeat([5, 3, 1], 6), 4)\n",
    "weighting = np.tile(np.repeat(['chisq', 'nothing'], 9), 2)\n",
    "support_paths = np.repeat([0.1, 0.05], 18)\n",
    "\n",
    "kwargs_grid = {k : {'alpha_paths' : ap, 'disc_path_bins' : dpb, 'score_func' : sf, 'weighting' : w, 'support_paths' : sp} \n",
    "    for k, ap, dpb, sf, w, sp in zip(range(36), alpha_paths, disc_path_bins, score_func, weighting, support_paths)}\n",
    "\n",
    "kwargs_default = {'support_paths' : 0.1, 'alpha_paths' : 0.5, 'disc_path_bins' : 4, 'score_func' : 1, 'weighting' : 'chisq' }\n",
    "\n",
    "for random_state in range(123, 124):\n",
    "    for d_constructor in rp.datasets:\n",
    "        print('Running experiment for ' + d_constructor.__name__ + ' with random state = ' + str(random_state))\n",
    "        print()\n",
    "        # 1. Data and Forest prep\n",
    "        print('Split data into main train-test and build RF') \n",
    "        mydata = d_constructor(random_state=random_state, project_dir=project_dir)\n",
    "        \n",
    "        meta_data = mydata.get_meta()\n",
    "        save_path = meta_data['get_save_path']()\n",
    "        train_index, test_index = mydata.get_tt_split_idx(random_state=random_state_splits)\n",
    "        tt = mydata.tt_split(train_index, test_index)\n",
    "        \n",
    "        # this will train and score the model\n",
    "        rf = rp.forest_prep(ds_container=tt,\n",
    "                            meta_data=meta_data,\n",
    "                            save_path=save_path)\n",
    "\n",
    "        print()\n",
    "        if run_CHIRPS:\n",
    "            if CHIRPS_sensitivity:\n",
    "                for kwg in kwargs_grid:\n",
    "                    \n",
    "                    rp.CHIRPS_benchmark(forest=rf, ds_container=tt, meta_data=meta_data,\n",
    "                                        batch_size=batch_size, n_instances=n_instances,\n",
    "                                        forest_walk_async=forest_walk_async,\n",
    "                                        chirps_explanation_async=chirps_explanation_async,\n",
    "                                        save_path=save_path,\n",
    "                                        save_sensitivity_path=extend_path(stem=save_path, \\\n",
    "                                                              extensions=['sensitivity', \\\n",
    "                                                                'sp_' + str(kwargs_grid[kwg]['support_paths']) + \\\n",
    "                                                                '_ap_' + str(kwargs_grid[kwg]['alpha_paths']) + \\\n",
    "                                                                '_dpb_' + str(kwargs_grid[kwg]['disc_path_bins']) + \\\n",
    "                                                                '_sf_' + str(kwargs_grid[kwg]['score_func']) + \\\n",
    "                                                                '_w_' + str(kwargs_grid[kwg]['weighting']) + '_']),\n",
    "                                        dataset_name=d_constructor.__name__,\n",
    "                                        random_state=random_state, **kwargs_grid[kwg])\n",
    "                    \n",
    "                    # create a new ds_container as the last one is used up\n",
    "                    tt = mydata.tt_split(train_index, test_index)\n",
    "            else:\n",
    "                rp.CHIRPS_benchmark(forest=rf, ds_container=tt, meta_data=meta_data,\n",
    "                                    batch_size=batch_size, n_instances=n_instances,\n",
    "                                    forest_walk_async=forest_walk_async,\n",
    "                                    chirps_explanation_async=chirps_explanation_async,\n",
    "                                    save_path=save_path,\n",
    "                                    dataset_name=d_constructor.__name__,\n",
    "                                    random_state=random_state, **kwargs_default)\n",
    "                    \n",
    "        if run_Anchors:\n",
    "            # new copy of ds_container (need to reset the row counters)\n",
    "            tt_anch = mydata.tt_split(train_index, test_index)\n",
    "            # preprocessing - discretised continuous X matrix has been added and also needs an updated var_dict \n",
    "            # plus returning the fitted explainer that holds the data distribution\n",
    "            tt_anch, anchors_explainer = rp.Anchors_preproc(ds_container=tt_anch,\n",
    "                                                             meta_data=meta_data)\n",
    "    \n",
    "            # re-fitting the random forest to the discretised data and evaluating\n",
    "            rf = rp.forest_prep(ds_container=tt_anch,\n",
    "                            meta_data=meta_data,\n",
    "                            save_path=save_path,\n",
    "                            identifier='Anchors')\n",
    "\n",
    "            rp.Anchors_benchmark(forest=rf, ds_container=tt_anch, meta_data=meta_data,\n",
    "                                anchors_explainer=anchors_explainer,\n",
    "                                batch_size=batch_size, n_instances=n_instances,\n",
    "                                save_path=save_path, dataset_name=d_constructor.__name__,\n",
    "                                random_state=meta_data['random_state'])\n",
    "        \n",
    "        if run_defragTrees:\n",
    "            # create a new copy of tt split, because each one keeps track of which instances it has given out.\n",
    "            # re-using the top one means different instances are passed\n",
    "            tt_dfrgtrs = mydata.tt_split(train_index, test_index)\n",
    "            \n",
    "            # some dfrgtrs specific parameters\n",
    "            Kmax = 10\n",
    "            restart = 20\n",
    "            maxitr = 100\n",
    "            dfrgtrs, eval_start_time, defTrees_elapsed_time = rp.defragTrees_prep(ds_container=tt_dfrgtrs,\n",
    "                                                                                meta_data=meta_data, forest=rf, \n",
    "                                                                                Kmax=Kmax, restart=restart, maxitr=maxitr,\n",
    "                                                                                identifier='defragTrees', save_path=save_path)\n",
    "            \n",
    "                        \n",
    "            rp.defragTrees_benchmark(forest=rf, ds_container=tt_dfrgtrs, meta_data=meta_data,\n",
    "                                    dfrgtrs=dfrgtrs, eval_start_time=eval_start_time,\n",
    "                                    defTrees_elapsed_time=defTrees_elapsed_time,\n",
    "                                    batch_size=batch_size, n_instances=n_instances,\n",
    "                                    save_path=save_path, dataset_name=d_constructor.__name__,\n",
    "                                    random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
