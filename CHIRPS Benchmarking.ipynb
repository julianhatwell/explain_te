{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up notebook and load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for notebook plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# load what we need\n",
    "import numpy as np\n",
    "import CHIRPS.datasets as ds\n",
    "import CHIRPS.reproducible as rp\n",
    "from CHIRPS.routines import extend_path\n",
    "\n",
    "# demo datasets that ship with package. all from UCI unless stated otherwise\n",
    "# ds.adult_data, ds.adult_samp_data, ds.adult_small_samp_data Large dataset ships with manageable sub samples\n",
    "# ds.bankmark_data, ds.bankmark_samp_data\n",
    "# ds.car_data\n",
    "# ds.cardio_data this is the cardiotocography dataset\n",
    "# ds.credit_data\n",
    "# ds.german_data\n",
    "# ds.lending_data, ds.lending_samp_data, ds.lending_small_samp_data, ds.lending_tiny_samp_data from Kaggle. see datasets_from_source file for links\n",
    "# ds.nursery_data, ds.nursery_samp_data\n",
    "# ds.rcdv_data, ds.rcdv_samp_data from US government see datasets_from_source file for links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common config - can be ommitted if defaults are OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'V:\\\\whiteboxing' # defaults to a directory \"whiteboxing\" in the working directory\n",
    "random_state_splits = 123 # one off for splitting the data into test / train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several datasets are available as pre-prepared containers that hold the data and some meta-data that is used in the algorithm\n",
    "Any dataset can be turned into a container by invoking the constructor found in the file structures.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function CHIRPS.datasets.adult_small_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.bankmark_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.car(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.cardio(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.credit(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.german(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.lending_tiny_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.nursery_samp(random_state=123, project_dir=None)>,\n",
       " <function CHIRPS.datasets.rcdv_samp(random_state=123, project_dir=None)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets might be down-sampled to make them easier to work with\n",
    "# the full sets are available too\n",
    "# this is a list of constructors that will be used in the benchmarking\n",
    "rp.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CHIRPS.structures.data_container at 0x264466789e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of one dataset\n",
    "# note: random_state propagates through other functions and is easily updated to allow alternative runs\n",
    "ds.cardio(random_state=123, project_dir=project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardising train-test splitting\n",
    "Some methods are not available in Python. We want to maintain the same dataset splits no matter which platform. So, the train test data is split with the one-time random seed and the splits are saved to csv in the project folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported train-test data for 9 datasets.\n"
     ]
    }
   ],
   "source": [
    "# writes external files\n",
    "rp.export_data_splits(datasets=rp.datasets, project_dir=project_dir, random_state_splits=random_state_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Runs\n",
    "Loop through datasets, actioning the functions in the package to execute a round of experiments and test evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Optional Memory and Computation Cost Management\n",
    "CHIRPS is time economical but memory intensive to compute for lots of instances at once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel processing\n",
    "Scikit takes care of parallel for the RF construction.\n",
    "We can parallelise the following:\n",
    "1. the walk of instances down each tree to collect the paths. The paths for many instances are returned in a single array. This parallelises across trees.\n",
    "2. building CHIRPS and the final explanation (rule). This is a search optimisation and we can parallelise each instance.\n",
    "\n",
    "This is expecially effective when running batches. For single instances, set both to false to avoid spinning up the parallel infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control for async processes - each tree walk can be done in its own core\n",
    "# and so can each explanation (e.g. rule conditions merge by hill-climbing)\n",
    "# these will default to false if not passed explicitly to the explainer function\n",
    "# on a multi-core machine there should be a good speed up for large batches\n",
    "# when the batch_size advantage exceeds the overhead of setting up multi-processing\n",
    "# timings will be printed to screen so you can see if it helps\n",
    "forest_walk_async=True\n",
    "chirps_explanation_async=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing unseen data\n",
    "\n",
    "Again note:\n",
    "test set has never been \"seen\" by random forest during training\n",
    "test set has been only used to assess model (random forest) accuracy - no additional tuning after this\n",
    "test set has not be involved in generating the explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching\n",
    "The memory space requirements for all the paths can be reduced by dividing the test set into batches. However this does take longer as there is an overhead to instantiate all the required objects, especially if coupled with parallel processing.\n",
    "Best compromise could be a small number of larger batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of instances can be controlled by\n",
    "# batch_size - how many instances to explain at one time\n",
    "# set these larger than the size of the test set and it will simply run the whole test set in one batch. Better do option 2\n",
    "batch_size = 10000\n",
    "# how many instances to explain in total from a test/unseen set\n",
    "n_instances = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data and Forest prep\n",
    "Use the random state splits to do a one-off data split.\n",
    "Fit the RF to training data, using the iterating random state.\n",
    "Save the performance metrics on the test set for later review.\n",
    "\n",
    "### 2. Prepare Unseen Data and Predictions\n",
    "Important to note:\n",
    "Test set never \"seen\" by RF during training.\n",
    "test set not involved in generating the explainer.\n",
    "Test set used to evaluate model (random forest) accuracy beyond OOBE scores - no additional tuning based on these results.\n",
    "Test set used to evaluate explanation scores by leave-one-out method removing the specific instance we're explaining.\n",
    "\n",
    "Important to note:\n",
    "We will explain predictions directly from the trained RF. Explanation system makes no compromise on model accuracy.\n",
    "\n",
    "### 3. CHIRPS algorithm\n",
    "1. Extract tree prediction paths\n",
    "2. Freqent pattern mining of paths\n",
    "3. Score and sort mined path segments\n",
    "4. Merge path segments into one rule\n",
    "\n",
    "#### CHIRPS 1\n",
    "Fit a forest_walker object to the dataset and decision forest. This is a wrapper that will extract the paths of all the given instances. Its main method delivers the instance paths for the remaining steps of the algorithm as a new object: a batch_paths_container. It can also report interesting statistics (treating the forest as a set of random tree-structured variables).\n",
    "\n",
    "#### CHIRPS 2-4\n",
    "A batch_CHIRPS_container is fitted with the batch_paths_container returned by the forest walker, and with a sample of data. For CHIRPS, we prefer a large sample. The whole training set or other representative sample will do. This is a wrapper object will execute steps 2-4 on all each the instance-paths in the batch_paths_container.\n",
    "\n",
    "Important to note:\n",
    "true_divide warnings are OK! It just means that a continuous variable is unbounded on one side i.e. no greater/less than inequality is used in the specific CHIRPS explanation.\n",
    "\n",
    "Important note: \n",
    "Here we are using the training set to create the explainers. We could use a different dataset as long as it is representative of the training set that built the decision forest. Most important that we don't use the dataset that we wish to explain, so never use the test set, for example.\n",
    "\n",
    "### 4. Evaluating CHIRPS Explanations\n",
    "Test set has been used to create an explainer *one instance at a time* and the rest of test set was not \"seen\" during this construction. To score each explainer, we use test set, leaving out the individual instance being explained. The data_split_container (tt) has a convenience funtion for doing this. All the results are saved to csv files in the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for adult_small_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepare Unseen Data and Predictions for CHIRPS benchmark\n",
      "Walking forest for 733 instances... (please wait)\n",
      "Forest Walk with async = True\n",
      "Forest Walk time elapsed: 16.2210 seconds\n",
      "\n",
      "Running CHIRPS on a batch of 733 instances... (please wait)\n",
      "CHIRPS time elapsed: 1241.2961 seconds\n",
      "CHIRPS with async = True\n",
      "\n",
      "Evaluating found explanations\n",
      "CHIRPS batch results eval time elapsed: 47.6721 seconds\n",
      "using previous tuning parameters\n",
      "Prepare Unseen Data and Predictions for Anchors benchmark\n",
      "Running Anchors on each instance and collecting results\n",
      "Working on Anchors for instance 263\n",
      "Working on Anchors for instance 905\n",
      "Working on Anchors for instance 1205\n",
      "Working on Anchors for instance 1727\n",
      "Working on Anchors for instance 1866\n",
      "Working on Anchors for instance 2087\n",
      "Working on Anchors for instance 2357\n",
      "Working on Anchors for instance 1935\n",
      "Working on Anchors for instance 742\n",
      "Working on Anchors for instance 1597\n",
      "Working on Anchors for instance 208\n",
      "Working on Anchors for instance 1012\n",
      "Working on Anchors for instance 1369\n",
      "Working on Anchors for instance 21\n",
      "Working on Anchors for instance 1383\n",
      "Working on Anchors for instance 1191\n",
      "Working on Anchors for instance 1234\n",
      "Working on Anchors for instance 1620\n",
      "Working on Anchors for instance 429\n",
      "Working on Anchors for instance 1074\n",
      "Working on Anchors for instance 1633\n",
      "Working on Anchors for instance 1678\n",
      "Working on Anchors for instance 1617\n",
      "Working on Anchors for instance 2209\n",
      "Working on Anchors for instance 1394\n",
      "Working on Anchors for instance 2419\n",
      "Working on Anchors for instance 1711\n",
      "Working on Anchors for instance 215\n",
      "Working on Anchors for instance 1844\n",
      "Working on Anchors for instance 553\n",
      "Working on Anchors for instance 1823\n",
      "Working on Anchors for instance 1796\n",
      "Working on Anchors for instance 1058\n",
      "Working on Anchors for instance 1565\n",
      "Working on Anchors for instance 72\n",
      "Working on Anchors for instance 803\n",
      "Working on Anchors for instance 116\n",
      "Working on Anchors for instance 1657\n",
      "Working on Anchors for instance 1469\n",
      "Working on Anchors for instance 2174\n",
      "Working on Anchors for instance 2165\n",
      "Working on Anchors for instance 2145\n",
      "Working on Anchors for instance 2157\n",
      "Working on Anchors for instance 318\n",
      "Working on Anchors for instance 2085\n",
      "Working on Anchors for instance 1065\n",
      "Working on Anchors for instance 1798\n",
      "Working on Anchors for instance 292\n",
      "Working on Anchors for instance 2074\n",
      "Working on Anchors for instance 1215\n",
      "Working on Anchors for instance 671\n",
      "Working on Anchors for instance 1166\n",
      "Working on Anchors for instance 188\n",
      "Working on Anchors for instance 1462\n",
      "Working on Anchors for instance 1458\n",
      "Working on Anchors for instance 2300\n",
      "Working on Anchors for instance 375\n",
      "Working on Anchors for instance 891\n",
      "Working on Anchors for instance 1563\n",
      "Working on Anchors for instance 1975\n",
      "Working on Anchors for instance 1026\n",
      "Working on Anchors for instance 831\n",
      "Working on Anchors for instance 1865\n",
      "Working on Anchors for instance 1296\n",
      "Working on Anchors for instance 1453\n",
      "Working on Anchors for instance 711\n",
      "Working on Anchors for instance 512\n",
      "Working on Anchors for instance 81\n",
      "Working on Anchors for instance 1882\n",
      "Working on Anchors for instance 265\n",
      "Working on Anchors for instance 35\n",
      "Working on Anchors for instance 1193\n",
      "Working on Anchors for instance 1604\n",
      "Working on Anchors for instance 119\n",
      "Running experiment for bankmark_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepare Unseen Data and Predictions for CHIRPS benchmark\n",
      "Walking forest for 680 instances... (please wait)\n",
      "Forest Walk with async = True\n",
      "Forest Walk time elapsed: 30.5164 seconds\n",
      "\n",
      "Running CHIRPS on a batch of 680 instances... (please wait)\n",
      "CHIRPS time elapsed: 222.1474 seconds\n",
      "CHIRPS with async = True\n",
      "\n",
      "Evaluating found explanations\n",
      "CHIRPS batch results eval time elapsed: 83.3918 seconds\n",
      "using previous tuning parameters\n",
      "Prepare Unseen Data and Predictions for Anchors benchmark\n",
      "Running Anchors on each instance and collecting results\n",
      "Working on Anchors for instance 141\n",
      "Working on Anchors for instance 890\n",
      "Working on Anchors for instance 1676\n",
      "Working on Anchors for instance 1665\n",
      "Working on Anchors for instance 1158\n",
      "Working on Anchors for instance 1765\n",
      "Working on Anchors for instance 2104\n",
      "Working on Anchors for instance 1573\n",
      "Working on Anchors for instance 1950\n",
      "Working on Anchors for instance 1014\n",
      "Working on Anchors for instance 691\n",
      "Working on Anchors for instance 701\n",
      "Working on Anchors for instance 1097\n",
      "Working on Anchors for instance 1394\n",
      "Working on Anchors for instance 417\n",
      "Working on Anchors for instance 1738\n",
      "Working on Anchors for instance 809\n",
      "Working on Anchors for instance 2067\n",
      "Working on Anchors for instance 43\n",
      "Working on Anchors for instance 1167\n",
      "Working on Anchors for instance 846\n",
      "Working on Anchors for instance 75\n",
      "Working on Anchors for instance 591\n",
      "Working on Anchors for instance 1694\n",
      "Working on Anchors for instance 1026\n",
      "Working on Anchors for instance 188\n",
      "Working on Anchors for instance 831\n",
      "Working on Anchors for instance 1976\n",
      "Working on Anchors for instance 2070\n",
      "Working on Anchors for instance 1522\n",
      "Working on Anchors for instance 108\n",
      "Working on Anchors for instance 1924\n",
      "Working on Anchors for instance 1642\n",
      "Working on Anchors for instance 961\n",
      "Working on Anchors for instance 1208\n",
      "Working on Anchors for instance 1762\n",
      "Working on Anchors for instance 1799\n",
      "Working on Anchors for instance 273\n",
      "Working on Anchors for instance 356\n",
      "Working on Anchors for instance 628\n",
      "Working on Anchors for instance 1518\n",
      "Working on Anchors for instance 1399\n",
      "Working on Anchors for instance 1313\n",
      "Working on Anchors for instance 1825\n",
      "Working on Anchors for instance 2135\n",
      "Working on Anchors for instance 265\n",
      "Working on Anchors for instance 679\n",
      "Working on Anchors for instance 1011\n",
      "Working on Anchors for instance 968\n",
      "Working on Anchors for instance 328\n",
      "Working on Anchors for instance 1067\n",
      "Working on Anchors for instance 2068\n",
      "Working on Anchors for instance 1601\n",
      "Working on Anchors for instance 633\n",
      "Working on Anchors for instance 2134\n",
      "Working on Anchors for instance 1701\n",
      "Working on Anchors for instance 1801\n",
      "Working on Anchors for instance 1600\n",
      "Working on Anchors for instance 1337\n",
      "Working on Anchors for instance 842\n",
      "Working on Anchors for instance 533\n",
      "Working on Anchors for instance 2110\n",
      "Working on Anchors for instance 226\n",
      "Working on Anchors for instance 822\n",
      "Working on Anchors for instance 357\n",
      "Working on Anchors for instance 602\n",
      "Working on Anchors for instance 1528\n",
      "Working on Anchors for instance 1716\n",
      "Running experiment for car with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepare Unseen Data and Predictions for CHIRPS benchmark\n",
      "Walking forest for 518 instances... (please wait)\n",
      "Forest Walk with async = True\n",
      "Forest Walk time elapsed: 3.6275 seconds\n",
      "\n",
      "Running CHIRPS on a batch of 518 instances... (please wait)\n",
      "CHIRPS time elapsed: 150.9578 seconds\n",
      "CHIRPS with async = True\n",
      "\n",
      "Evaluating found explanations\n",
      "CHIRPS batch results eval time elapsed: 11.8162 seconds\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare Unseen Data and Predictions for Anchors benchmark\n",
      "Running Anchors on each instance and collecting results\n",
      "Working on Anchors for instance 1633\n",
      "Working on Anchors for instance 1009\n",
      "Working on Anchors for instance 1663\n",
      "Working on Anchors for instance 120\n",
      "Working on Anchors for instance 1338\n",
      "Working on Anchors for instance 1008\n",
      "Working on Anchors for instance 1558\n",
      "Working on Anchors for instance 1661\n",
      "Working on Anchors for instance 1114\n",
      "Working on Anchors for instance 980\n",
      "Working on Anchors for instance 357\n",
      "Working on Anchors for instance 31\n",
      "Working on Anchors for instance 403\n",
      "Working on Anchors for instance 206\n",
      "Working on Anchors for instance 129\n",
      "Working on Anchors for instance 637\n",
      "Working on Anchors for instance 674\n",
      "Working on Anchors for instance 1198\n",
      "Working on Anchors for instance 1658\n",
      "Working on Anchors for instance 63\n",
      "Working on Anchors for instance 822\n",
      "Working on Anchors for instance 1373\n",
      "Working on Anchors for instance 410\n",
      "Working on Anchors for instance 1126\n",
      "Working on Anchors for instance 134\n",
      "Working on Anchors for instance 1501\n",
      "Working on Anchors for instance 249\n",
      "Working on Anchors for instance 700\n",
      "Working on Anchors for instance 841\n",
      "Working on Anchors for instance 327\n",
      "Working on Anchors for instance 1717\n",
      "Working on Anchors for instance 813\n",
      "Working on Anchors for instance 328\n",
      "Working on Anchors for instance 1259\n",
      "Working on Anchors for instance 1413\n",
      "Working on Anchors for instance 334\n",
      "Working on Anchors for instance 1265\n",
      "Working on Anchors for instance 535\n",
      "Working on Anchors for instance 597\n",
      "Working on Anchors for instance 75\n",
      "Working on Anchors for instance 932\n",
      "Working on Anchors for instance 1715\n",
      "Working on Anchors for instance 879\n",
      "Working on Anchors for instance 1474\n",
      "Working on Anchors for instance 684\n",
      "Working on Anchors for instance 1399\n",
      "Working on Anchors for instance 314\n",
      "Working on Anchors for instance 1515\n",
      "Working on Anchors for instance 85\n",
      "Working on Anchors for instance 1414\n",
      "Working on Anchors for instance 1183\n",
      "Working on Anchors for instance 1637\n",
      "Running experiment for cardio with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n",
      "\n",
      "Prepare Unseen Data and Predictions for CHIRPS benchmark\n",
      "Walking forest for 638 instances... (please wait)\n",
      "Forest Walk with async = True\n",
      "Forest Walk time elapsed: 5.1078 seconds\n",
      "\n",
      "Running CHIRPS on a batch of 638 instances... (please wait)\n",
      "CHIRPS time elapsed: 304.3383 seconds\n",
      "CHIRPS with async = True\n",
      "\n",
      "Evaluating found explanations\n",
      "CHIRPS batch results eval time elapsed: 18.0298 seconds\n",
      "using previous tuning parameters\n",
      "Prepare Unseen Data and Predictions for Anchors benchmark\n",
      "Running Anchors on each instance and collecting results\n",
      "Working on Anchors for instance 63\n",
      "Working on Anchors for instance 1726\n",
      "Working on Anchors for instance 594\n",
      "Working on Anchors for instance 772\n",
      "Working on Anchors for instance 1155\n",
      "Working on Anchors for instance 1503\n",
      "Working on Anchors for instance 1391\n",
      "Working on Anchors for instance 1286\n",
      "Working on Anchors for instance 1848\n",
      "Working on Anchors for instance 433\n",
      "Working on Anchors for instance 1298\n",
      "Working on Anchors for instance 1702\n",
      "Working on Anchors for instance 381\n",
      "Working on Anchors for instance 565\n",
      "Working on Anchors for instance 1737\n",
      "Working on Anchors for instance 1026\n",
      "Working on Anchors for instance 680\n",
      "Working on Anchors for instance 1640\n",
      "Working on Anchors for instance 556\n",
      "Working on Anchors for instance 1216\n",
      "Working on Anchors for instance 704\n",
      "Working on Anchors for instance 550\n",
      "Working on Anchors for instance 838\n",
      "Working on Anchors for instance 1659\n",
      "Working on Anchors for instance 72\n",
      "Working on Anchors for instance 265\n",
      "Working on Anchors for instance 914\n",
      "Working on Anchors for instance 1850\n",
      "Working on Anchors for instance 198\n",
      "Working on Anchors for instance 948\n",
      "Working on Anchors for instance 343\n",
      "Working on Anchors for instance 1273\n",
      "Working on Anchors for instance 2068\n",
      "Working on Anchors for instance 1057\n",
      "Working on Anchors for instance 1350\n",
      "Working on Anchors for instance 86\n",
      "Working on Anchors for instance 1948\n",
      "Working on Anchors for instance 944\n",
      "Working on Anchors for instance 218\n",
      "Working on Anchors for instance 1495\n",
      "Working on Anchors for instance 75\n",
      "Working on Anchors for instance 1587\n",
      "Working on Anchors for instance 822\n",
      "Working on Anchors for instance 35\n",
      "Working on Anchors for instance 1576\n",
      "Working on Anchors for instance 1467\n",
      "Working on Anchors for instance 875\n",
      "Working on Anchors for instance 996\n",
      "Working on Anchors for instance 31\n",
      "Working on Anchors for instance 1485\n",
      "Working on Anchors for instance 61\n",
      "Working on Anchors for instance 605\n",
      "Working on Anchors for instance 1067\n",
      "Working on Anchors for instance 627\n",
      "Working on Anchors for instance 1993\n",
      "Working on Anchors for instance 1963\n",
      "Working on Anchors for instance 1812\n",
      "Working on Anchors for instance 1422\n",
      "Working on Anchors for instance 610\n",
      "Working on Anchors for instance 15\n",
      "Working on Anchors for instance 1173\n",
      "Working on Anchors for instance 732\n",
      "Working on Anchors for instance 1215\n",
      "Working on Anchors for instance 1964\n",
      "Running experiment for credit with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepare Unseen Data and Predictions for CHIRPS benchmark\n",
      "Walking forest for 207 instances... (please wait)\n",
      "Forest Walk with async = True\n",
      "Forest Walk time elapsed: 11.8656 seconds\n",
      "\n",
      "Running CHIRPS on a batch of 207 instances... (please wait)\n",
      "CHIRPS time elapsed: 95.4730 seconds\n",
      "CHIRPS with async = True\n",
      "\n",
      "Evaluating found explanations\n",
      "CHIRPS batch results eval time elapsed: 23.3101 seconds\n",
      "using previous tuning parameters\n",
      "Prepare Unseen Data and Predictions for Anchors benchmark\n",
      "Running Anchors on each instance and collecting results\n",
      "Working on Anchors for instance 587\n",
      "Working on Anchors for instance 631\n",
      "Working on Anchors for instance 686\n",
      "Working on Anchors for instance 688\n",
      "Working on Anchors for instance 138\n",
      "Working on Anchors for instance 345\n",
      "Working on Anchors for instance 457\n",
      "Working on Anchors for instance 453\n",
      "Working on Anchors for instance 82\n",
      "Working on Anchors for instance 252\n",
      "Working on Anchors for instance 529\n",
      "Working on Anchors for instance 592\n",
      "Working on Anchors for instance 533\n",
      "Working on Anchors for instance 584\n",
      "Working on Anchors for instance 120\n",
      "Working on Anchors for instance 177\n",
      "Working on Anchors for instance 511\n",
      "Working on Anchors for instance 217\n",
      "Working on Anchors for instance 285\n",
      "Working on Anchors for instance 437\n",
      "Working on Anchors for instance 275\n",
      "Running experiment for german with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepare Unseen Data and Predictions for CHIRPS benchmark\n",
      "Walking forest for 300 instances... (please wait)\n",
      "Forest Walk with async = True\n",
      "Forest Walk time elapsed: 6.6053 seconds\n",
      "\n",
      "Running CHIRPS on a batch of 300 instances... (please wait)\n",
      "CHIRPS time elapsed: 213.3786 seconds\n",
      "CHIRPS with async = True\n",
      "\n",
      "Evaluating found explanations\n",
      "CHIRPS batch results eval time elapsed: 14.1467 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using previous tuning parameters\n",
      "Prepare Unseen Data and Predictions for Anchors benchmark\n",
      "Running Anchors on each instance and collecting results\n",
      "Working on Anchors for instance 131\n",
      "Working on Anchors for instance 195\n",
      "Working on Anchors for instance 372\n",
      "Working on Anchors for instance 721\n",
      "Working on Anchors for instance 770\n",
      "Working on Anchors for instance 161\n",
      "Working on Anchors for instance 470\n",
      "Working on Anchors for instance 345\n",
      "Working on Anchors for instance 437\n",
      "Working on Anchors for instance 992\n",
      "Working on Anchors for instance 538\n",
      "Working on Anchors for instance 827\n",
      "Working on Anchors for instance 829\n",
      "Working on Anchors for instance 952\n",
      "Working on Anchors for instance 298\n",
      "Working on Anchors for instance 922\n",
      "Working on Anchors for instance 204\n",
      "Working on Anchors for instance 758\n",
      "Working on Anchors for instance 816\n",
      "Working on Anchors for instance 388\n",
      "Working on Anchors for instance 511\n",
      "Working on Anchors for instance 75\n",
      "Working on Anchors for instance 880\n",
      "Working on Anchors for instance 13\n",
      "Working on Anchors for instance 719\n",
      "Working on Anchors for instance 893\n",
      "Working on Anchors for instance 273\n",
      "Working on Anchors for instance 107\n",
      "Working on Anchors for instance 670\n",
      "Working on Anchors for instance 913\n",
      "Running experiment for lending_tiny_samp with random state = 123\n",
      "\n",
      "Split data into main train-test and build RF\n",
      "using previous tuning parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepare Unseen Data and Predictions for CHIRPS benchmark\n",
      "Walking forest for 632 instances... (please wait)\n",
      "Forest Walk with async = True\n",
      "Forest Walk time elapsed: 46.6992 seconds\n",
      "\n",
      "Running CHIRPS on a batch of 632 instances... (please wait)\n"
     ]
    }
   ],
   "source": [
    "run_CHIRPS = True\n",
    "run_Anchors = True\n",
    "run_defragTrees = False\n",
    "\n",
    "CHIRPS_sensitivity = False\n",
    "\n",
    "alpha_paths = np.tile([0.9, 0.5, 0.1], 12)\n",
    "disc_path_bins = np.tile(np.repeat([4, 8], 3), 6)\n",
    "score_func = np.tile(np.repeat([5, 3, 1], 6), 2)\n",
    "weighting = np.repeat(['nothing', 'chisq'], 9)\n",
    "\n",
    "kwargs_grid = {k : {'alpha_paths' : ap, 'disc_path_bins' : dpb, 'score_func' : sf, 'weighting' : w } \n",
    "    for k, ap, dpb, sf, w in zip(range(18), alpha_paths, disc_path_bins, score_func, weighting)}\n",
    "\n",
    "kwargs_default = {'support_paths' : 0.1, 'alpha_paths' : 0.5, 'disc_path_bins' : 4, 'score_func' : 1, 'weighting' : 'chisq' }\n",
    "\n",
    "for random_state in range(123, 124):\n",
    "    for d_constructor in rp.datasets:\n",
    "        print('Running experiment for ' + d_constructor.__name__ + ' with random state = ' + str(random_state))\n",
    "        print()\n",
    "        # 1. Data and Forest prep\n",
    "        print('Split data into main train-test and build RF') \n",
    "        mydata = d_constructor(random_state=random_state, project_dir=project_dir)\n",
    "        \n",
    "        meta_data = mydata.get_meta()\n",
    "        save_path = meta_data['get_save_path']()\n",
    "        train_index, test_index = mydata.get_tt_split_idx(random_state=random_state_splits)\n",
    "        tt = mydata.tt_split(train_index, test_index)\n",
    "        \n",
    "        # this will train and score the model\n",
    "        rf = rp.forest_prep(ds_container=tt,\n",
    "                            meta_data=meta_data,\n",
    "                            save_path=save_path)\n",
    "\n",
    "        print()\n",
    "        if run_CHIRPS:\n",
    "            if CHIRPS_sensitivity:\n",
    "                for kwg in kwargs_grid:\n",
    "                    \n",
    "                    rp.CHIRPS_benchmark(forest=rf, ds_container=tt, meta_data=meta_data,\n",
    "                                        batch_size=batch_size, n_instances=n_instances,\n",
    "                                        forest_walk_async=forest_walk_async,\n",
    "                                        chirps_explanation_async=chirps_explanation_async,\n",
    "                                        save_path=extend_path(stem=save_path, \\\n",
    "                                                              extensions=['sensitivity', 'ap_' + \\\n",
    "                                                                str(kwargs_grid[kwg]['alpha_paths']) + \\\n",
    "                                                                '_dpb_' + str(kwargs_grid[kwg]['disc_path_bins']) + \\\n",
    "                                                                '_sf_' + str(kwargs_grid[kwg]['score_func']) + \\\n",
    "                                                                '_w_' + str(kwargs_grid[kwg]['weighting']) + '.csv']),\n",
    "                                        dataset_name=d_constructor.__name__,\n",
    "                                        random_state=random_state, **kwargs_grid[kwg])\n",
    "            else:\n",
    "                rp.CHIRPS_benchmark(forest=rf, ds_container=tt, meta_data=meta_data,\n",
    "                                    batch_size=batch_size, n_instances=n_instances,\n",
    "                                    forest_walk_async=forest_walk_async,\n",
    "                                    chirps_explanation_async=chirps_explanation_async,\n",
    "                                    save_path=save_path,\n",
    "                                    dataset_name=d_constructor.__name__,\n",
    "                                    random_state=random_state, **kwargs_default)\n",
    "                    \n",
    "        if run_Anchors:\n",
    "            # new copy of ds_container (need to reset the row counters)\n",
    "            tt_anch = mydata.tt_split(train_index, test_index)\n",
    "            # preprocessing - discretised continuous X matrix has been added and also needs an updated var_dict \n",
    "            # plus returning the fitted explainer that holds the data distribution\n",
    "            tt_anch, anchors_explainer = rp.Anchors_preproc(ds_container=tt_anch,\n",
    "                                                             meta_data=meta_data)\n",
    "    \n",
    "            # re-fitting the random forest to the discretised data and evaluating\n",
    "            rf = rp.forest_prep(ds_container=tt_anch,\n",
    "                            meta_data=meta_data,\n",
    "                            save_path=save_path,\n",
    "                            identifier='Anchors')\n",
    "\n",
    "            rp.Anchors_benchmark(forest=rf, ds_container=tt_anch, meta_data=meta_data,\n",
    "                                anchors_explainer=anchors_explainer,\n",
    "                                batch_size=batch_size, n_instances=n_instances,\n",
    "                                save_path=save_path, dataset_name=d_constructor.__name__,\n",
    "                                random_state=meta_data['random_state'])\n",
    "        \n",
    "        if run_defragTrees:\n",
    "            # create a new copy of tt split, because each one keeps track of which instances it has given out.\n",
    "            # re-using the top one means different instances are passed\n",
    "            tt_dfrgtrs = mydata.tt_split(train_index, test_index)\n",
    "            \n",
    "            # some dfrgtrs specific parameters\n",
    "            Kmax = 10\n",
    "            restart = 20\n",
    "            maxitr = 100\n",
    "            dfrgtrs = rp.defragTrees_prep(ds_container=tt_dfrgtrs, meta_data=meta_data, forest=rf, \n",
    "                                            Kmax=Kmax, restart=restart, maxitr=maxitr,\n",
    "                                            identifier='defragTrees', save_path=save_path)\n",
    "            \n",
    "                        \n",
    "            rp.defragTrees_benchmark(forest=rf, ds_container=tt_dfrgtrs, meta_data=meta_data, dfrgtrs=dfrgtrs,\n",
    "                                    batch_size=batch_size, n_instances=n_instances,\n",
    "                                    save_path=save_path, dataset_name=d_constructor.__name__,\n",
    "                                    random_state=random_state)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
