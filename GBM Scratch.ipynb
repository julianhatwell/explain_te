{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up notebook and load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\B3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\ProgramData\\Anaconda3\\envs\\B3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "# for notebook plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# load what we need\n",
    "import time\n",
    "import timeit\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.dummy as dummy\n",
    "import CHIRPS.structures as strcts\n",
    "import CHIRPS.datasets as ds\n",
    "import CHIRPS.datasets_proprietary as dsp\n",
    "import CHIRPS.routines as rt\n",
    "\n",
    "# demo datasets that ship with package. all from UCI unless stated otherwise\n",
    "# import CHIRPS.datasets as ds\n",
    "# ds.adult_data, ds.adult_samp_data, ds.adult_small_samp_data Large dataset ships with manageable sub samples\n",
    "# ds.bankmark_data, ds.bankmark_samp_data\n",
    "# ds.car_data\n",
    "# ds.cardio_data this is the cardiotocography dataset\n",
    "# ds.credit_data\n",
    "# ds.german_data\n",
    "# ds.lending_data, ds.lending_samp_data, ds.lending_small_samp_data, ds.lending_tiny_samp_data from Kaggle. see datasets_from_source file for links\n",
    "# ds.nursery_data, ds.nursery_samp_data\n",
    "# ds.rcdv_data, ds.rcdv_samp_data from US government see datasets_from_source file for links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common config - can be ommitted if defaults are OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location to save results\n",
    "# project_dir = '/datadisk/whiteboxing/2020'\n",
    "project_dir = 'V:\\\\whiteboxing\\\\2020' # defaults to a directory \"whiteboxing\" in the working directory\n",
    "# project_dir = 'C:\\\\Users\\\\Crutt\\\\Documents\\\\whiteboxing\\\\2020'\n",
    "\n",
    "random_state_splits = 123 # one off for splitting the data into test / train\n",
    "random_state = 123 # for everything else - e.g. building a new rf with same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Random Forest Model to Predict and Explain\n",
    "First, a wrapper is created for the dataset. Use one that ships with the package, or create your own.\n",
    "Then split the data into training and (hold out) test set using the convenience functions in the package. These return an object that contain the split data in various representations, such as Pandas DataFrames and encoded, sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\B3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using previous tuning parameters\n",
      "Best OOB Accuracy Estimate during tuning: 0.7614\n",
      "Best parameters:{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 1600, 'subsample': 0.5, 'random_state': 123}\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[ 53  35]\n",
      " [ 36 176]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.6  0.4 ]\n",
      " [0.17 0.83]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load one of the included datasets\n",
    "# project_dir will default to directory name CHIRPS in the working directory if not given\n",
    "# random_state will default to 123\n",
    "override_tuning = False\n",
    "mydata = ds.german(random_state=random_state_splits, project_dir=project_dir)\n",
    "\n",
    "meta_data = mydata.get_meta()\n",
    "save_path = meta_data['get_save_path']()\n",
    "\n",
    "# split the data. here using a basic sampling method.\n",
    "# the returned object is a wrapper class that contains\n",
    "# the train and test splits for X and y\n",
    "\n",
    "# also the the encoded versions of X_train and X_test that the rf will use\n",
    "# this is because we prefer onehot encoded over allowing categorical vars to be represented as integer\n",
    "# scikit would treat these as ordinal, which is inappropriate\n",
    "\n",
    "# also some meta-data: priors for y, the indexes from the input data\n",
    "\n",
    "# also some convenience functions for leave-one-out testing\n",
    "\n",
    "# train test split - one off hard-coded random state.\n",
    "# random state can be ommitted \n",
    "# and will default to the state held in the dataset container\n",
    "# which defaults to 123 if ommitted in the constructor\n",
    "train_index, test_index = mydata.get_tt_split_idx(random_state=random_state_splits)\n",
    "# optionally, indexes can be ommitted and will default to scikit's train_test_split method\n",
    "tt = mydata.tt_split(train_index, test_index)\n",
    "\n",
    "# CHOOSE ONE\n",
    "# model = 'RandomForest'\n",
    "# model = 'AdaBoost1' # SAMME\n",
    "# model = 'AdaBoost2' # SAMME.R\n",
    "model = 'GBM'\n",
    "\n",
    "# decide if to run the whole tuning routine again (long for Adaboost)\n",
    "# RF routine has a default tuning grid, so can leave as None, or come up with some other options\n",
    "tuning = {'grid' : None, 'override' : override_tuning}\n",
    "if model == 'RandomForest':\n",
    "    which_trees = 'majority'\n",
    "    tuning.update({'grid' : {'n_estimators': [(i + 1) * 200 for i in range(8)],\n",
    "                            'max_depth' : [32]}})\n",
    "\n",
    "elif model in ('AdaBoost1', 'AdaBoost2'):\n",
    "    if model == 'AdaBoost1':\n",
    "        # classic (and multi-class) AdaBoost\n",
    "        algo = 'SAMME'\n",
    "        which_trees = 'majority'\n",
    "    else:\n",
    "        algo = 'SAMME.R'\n",
    "        which_trees = 'conf_weighted'\n",
    "    max_depth = [i for i in range(1, 5)]\n",
    "    tuning.update({'grid' : {'base_estimator' : [rt.DecisionTreeClassifier(max_depth=d) for d in max_depth],\n",
    "                            'n_estimators': [(i + 1) * 200 for i in range(8)], 'algorithm': [algo]}})\n",
    "    \n",
    "else: # GBM - not fully implemented yet\n",
    "    tuning.update({'grid' : {'subsample' : [0.5],\n",
    "                        'n_estimators': [i * 200 for i in range(1, 9)],\n",
    "                        'max_depth' : [i for i in range(1, 5)],\n",
    "                        'learning_rate': np.full(4, 10.0)**[i for i in range(-3, 1)]}})\n",
    "\n",
    "rf = rt.forest_prep(ds_container=tt,\n",
    "                    meta_data=meta_data,\n",
    "                    override_tuning=override_tuning,\n",
    "                    model=model,\n",
    "                    tuning_grid=tuning['grid'],\n",
    "                    save_path=save_path,\n",
    "                    plot_cm=True, plot_cm_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8248495223467764\n",
      "[3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3x61 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 60 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at the tree level\n",
    "print(rf.estimators_[0][0].predict(tt.X_test_enc[0])[0])\n",
    "print(rf.estimators_[0][0].apply(tt.X_test_enc[0])) # the leaf position\n",
    "# the value in the leaf is the prediction\n",
    "rf.estimators_[0][0].tree_.value[4][0][0]\n",
    "tt.X_test_enc[0:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 0: choose an instance\n",
    "# instance = tt.X_test_enc[0:5]\n",
    "\n",
    "# # step 1: what is the initial guess f_0(x)\n",
    "# # prior probas\n",
    "# priors = mydata.data[meta_data['class_col']].value_counts(normalize=True)\n",
    "# print('prior probas')\n",
    "# print(priors)\n",
    "# print()\n",
    "\n",
    "# # all instances get the same init guess\n",
    "# # predict the priors\n",
    "# if type(rf.init_) == sklearn.dummy.DummyClassifier:\n",
    "#     prior = rf.init_.predict_proba(instance)[0]\n",
    "#     prior_odds = prior / (1 - prior)\n",
    "#     prior_lodds = np.log(prior_odds)\n",
    "# else:\n",
    "#     # this is some windows bullshit. should be a dummy classifier with prior\n",
    "#     # but instead it's a LogOddsClassifier\n",
    "#     prior_lodds = rf.init_.predict(instance)[0][0]\n",
    "#     prior_lodds = [-prior_lodds, prior_lodds] # lodds of class 1, needs to be symmetric for class 0\n",
    "#     prior_odds = np.exp(prior_lodds)\n",
    "#     prior = prior_odds / (1 + prior_odds)\n",
    "\n",
    "# print('prior lodds, odds, probas(check)')\n",
    "# print(prior_lodds)\n",
    "# print(prior_odds)\n",
    "# print(prior)\n",
    "# print()\n",
    "\n",
    "# # step 2: predicted results\n",
    "# print('predicted lodds, odds, probas(check)')\n",
    "# pred_proba = rf.predict_proba(instance)\n",
    "# pred_odds = pred_proba / (1 - pred_proba)\n",
    "# pred_lodds = np.log(pred_odds)\n",
    "# print(pred_lodds)\n",
    "# print(pred_odds)\n",
    "# print(pred_proba)\n",
    "# print()\n",
    "\n",
    "# # step 3: which direction compared to initial guess? and how big of a step was it?\n",
    "# print('diff predicted - prior')\n",
    "# print('if pred lodds 0/1 is bigger(+ve)/smaller(-ve) then p(y = 0 | x) has increased')\n",
    "# print('if pred lodds 0/1 is smaller(-ve)/bigger(+ve) then p(y = 1 | x) has increased')\n",
    "# diff_lodds = pred_lodds - prior_lodds\n",
    "# # diff_odds = np.exp(diff_lodds)\n",
    "# # diff_proba = diff_odds / (1 + diff_odds)\n",
    "# print(diff_lodds)\n",
    "# # print('diff odds')\n",
    "# # print(diff_odds)\n",
    "# # print('diff proba')\n",
    "# # print(diff_proba)\n",
    "# # print(prior*diff_proba)\n",
    "# print()\n",
    "\n",
    "# # step 4: get the individual tree increments\n",
    "# # a. staged decision function is the incremental change as the estimators are added, take the difference (include init)\n",
    "# staged_lodds = [np.diff(np.append(prior_lodds[0], [np.log(sp[0][0]/sp[0][1]) for sp in rf.staged_predict_proba(i)])) \\\n",
    "#                 for i in instance]\n",
    "# # b. get the predicted value from each individual estimator\n",
    "# # step_lodds = [-(rf.estimators_[i][0].predict(instance) * 0.1)[0] for i in range(rf.estimators_.shape[0])]\n",
    "# # delta_lodds = np.array([[stage, step] for stage, step in zip(staged_lodds, step_lodds)]).sum(axis=0) # these are the same (signed)\n",
    "\n",
    "# # print('calculated delta lodds')\n",
    "# # print(delta_lodds)\n",
    "# # print('calculated final lodds, odds, probas(check)')\n",
    "# # print([prior_lodds[0] + delta_lodds[0], prior_lodds[1] - delta_lodds[0]])\n",
    "\n",
    "# # step 6: filter by sign\n",
    "# print('indexer for the trees we want')\n",
    "# tree_agree_maj_vote = [np.sign(staged_lodds[i]) == np.sign(diff_lodds[i][0]) for i in range(len(staged_lodds))]\n",
    "# print(tree_agree_maj_vote[0])\n",
    "\n",
    "# # the move from prior to final is important here.\n",
    "# # final_lodds = prior_lodds + delta_lodds[1]  # this is where we end up with staged\n",
    "# # print(final_lodds)\n",
    "# # print(np.exp(final_lodds) / (1 + np.exp(final_lodds)))\n",
    "# # print(rf.predict_proba(instance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing unseen data\n",
    "\n",
    "Again note:\n",
    "test set has never been \"seen\" by random forest during training\n",
    "test set has been only used to assess model (random forest) accuracy - no additional tuning after this\n",
    "test set has not be involved in generating the explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optional: memory and computation cost management\n",
    "#### CHIRPS is time economical but memory intensive to compute for lots of instances at once\n",
    "option 1: choose a smaller number of instances to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control for async processes - each tree walk can be done in its own core\n",
    "# and so can each explanation (e.g. rule conditions merge by hill-climbing)\n",
    "# these will default to false if not passed explicitly to the explainer function\n",
    "# on a multi-core machine there should be a good speed up for large batches\n",
    "# when the batch_size advantage exceeds the overhead of setting up multi-processing\n",
    "# timings will be printed to screen so you can see if it helps\n",
    "forest_walk_async=False\n",
    "chirps_explanation_async=False\n",
    "\n",
    "# how many instances to explain in total from a test/unseen set\n",
    "# doesn't matter if you don't know how large the dataset is\n",
    "# this function prevents you maxing out, or put n_instances = None for whole dataset\n",
    "n_instances = rt.n_instance_ceiling(ds_container=tt, n_instances=10)\n",
    "\n",
    "# this gets the next batch out of the data_split_container according to the required number of instances\n",
    "# all formats can be extracted, depending on the requirement\n",
    "# unencoded, encoded (sparse matrix is the type returned by scikit), ordinary dense matrix also available\n",
    "tt.current_row_test = 0\n",
    "instances, _, instances_enc, instances_enc_matrix, labels = tt.get_next(n_instances, which_split='test') # default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 2: just run the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances = tt.X_test; instances_enc = tt.X_test_enc; instances_enc_matrix = tt.X_test_enc_matrix; labels = tt.y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions from the decision forest on the unseen data\n",
    "Important point, no compromise on model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the model predictions for the test instance(s) we're looking at\n",
    "preds_idx = labels.index\n",
    "preds = rf.predict(X=instances_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIRPS Step 1:\n",
    "## Extract Tree Prediction Paths\n",
    "### Fit a forest_walker object to the dataset and decision forest\n",
    "This is a wrapper will extracts the paths of all the given instances. For CHIRPS, we want a large sample. The whole training set or other representative sample will do.\n",
    "\n",
    "It can also report interesting statistics (treating the forest as a set of random tree-structured variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper object needs the decision forest itself and the dataset meta data (we have a convenience function for this)\n",
    "f_walker = strcts.regression_trees_walker(forest = rf, meta_data=meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the work of extracting all the paths for each instance is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walking forest for 10 instances... (please wait)\n",
      "in LogOddsEstimator\n",
      "[0 1 0 1 1 1 1 0 1 1]\n",
      "prior probas\n",
      "[0.30285714 0.69714286]\n",
      "pred probas\n",
      "[[0.90403784 0.09596216]\n",
      " [0.43380721 0.56619279]\n",
      " [0.53305065 0.46694935]\n",
      " [0.06875341 0.93124659]\n",
      " [0.04218767 0.95781233]\n",
      " [0.15363063 0.84636937]\n",
      " [0.43711157 0.56288843]\n",
      " [0.60976728 0.39023272]\n",
      " [0.23237599 0.76762401]\n",
      " [0.15977919 0.84022081]]\n",
      "prior lodds\n",
      "[-0.8337291311811347, 0.8337291311811347]\n",
      "pred_lodds\n",
      "[[ 2.24291733 -2.24291733]\n",
      " [-0.26633441  0.26633441]\n",
      " [ 0.13239567 -0.13239567]\n",
      " [-2.60599784  2.60599784]\n",
      " [-3.12252378  3.12252378]\n",
      " [-1.70640464  1.70640464]\n",
      " [-0.25289297  0.25289297]\n",
      " [ 0.44633411 -0.44633411]\n",
      " [-1.19494334  1.19494334]\n",
      " [-1.65987196  1.65987196]]\n",
      "delta_lodds\n",
      "[[ 3.07664646 -3.07664646]\n",
      " [ 0.56739472 -0.56739472]\n",
      " [ 0.9661248  -0.9661248 ]\n",
      " [-1.77226871  1.77226871]\n",
      " [-2.28879465  2.28879465]\n",
      " [-0.87267551  0.87267551]\n",
      " [ 0.58083616 -0.58083616]\n",
      " [ 1.28006324 -1.28006324]\n",
      " [-0.36121421  0.36121421]\n",
      " [-0.82614282  0.82614282]]\n",
      "[[ 0.0082485   0.0082485   0.0082485  ...  0.0082485   0.0082485\n",
      "   0.0082485 ]\n",
      " [ 0.01677263  0.00139083  0.00139083 ...  0.00139083  0.00139083\n",
      "   0.00139083]\n",
      " [ 0.02477228  0.00513637 -0.00427293 ...  0.00513637 -0.00427293\n",
      "  -0.00427293]\n",
      " ...\n",
      " [ 0.00079899  0.00079899  0.00079899 ... -0.00501019  0.00079899\n",
      "   0.00079899]\n",
      " [-0.0036053  -0.00253594 -0.0036053  ... -0.0036053   0.00285103\n",
      "   0.01082457]\n",
      " [-0.00138829  0.01726181 -0.00138829 ... -0.00138829 -0.00138829\n",
      "  -0.01312204]]\n",
      "[ 986  843  841 1000 1052  908  806  842  909  929]\n",
      "Forest Walk with async = False\n",
      "Forest Walk time elapsed: 0.9128 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Walking forest for ' + str(len(labels)) + ' instances... (please wait)')\n",
    "\n",
    "# set the timer\n",
    "forest_walk_start_time = timeit.default_timer()\n",
    "\n",
    "# do the walk - creates a paths_container (even for just one instance) as a new property\n",
    "# requires the X instances in a matrix (dense, ordinary numpy matrix) - this is available in the data_split_container\n",
    "f_walker.forest_walk(instances = instances_enc_matrix\n",
    "                    , labels = preds # we're explaining the prediction, not the true label!\n",
    "                    , forest_walk_async = forest_walk_async)\n",
    "\n",
    "# stop the timer\n",
    "forest_walk_end_time = timeit.default_timer()\n",
    "forest_walk_elapsed_time = forest_walk_end_time - forest_walk_start_time\n",
    "\n",
    "print('Forest Walk with async = ' + str(forest_walk_async))\n",
    "print('Forest Walk time elapsed:', \"{:0.4f}\".format(forest_walk_elapsed_time), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIRPS Steps 2-4: \n",
    "## Freqent pattern mining of paths.\n",
    "## Score and sort mined path segments.\n",
    "## Merge path segments into one rule.\n",
    "\n",
    "This is a wrapper object that will execute steps 2-4 on all the instance-paths in the batch_paths_container.\n",
    "\n",
    "Note that true_divide warnings are OK. It just means that a continuous variable is unbounded in some way i.e. no greater/less than discontinuity is used in the CHIRPS explanation.\n",
    "\n",
    "Note also, here we are using the training set to create the explainers. We could use a different dataset as long as it is representative of the training set that built the decision forest. Most important that we don't use the dataset that we wish to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': {'feature_idx': [3, 54],\n",
       "  'feature_name': ['chk_A14', 'dur'],\n",
       "  'feature_value': [0.0, 12.0],\n",
       "  'threshold': [0.5, 11.5],\n",
       "  'leq_threshold': [True, False]},\n",
       " 'estimator_weight': 0.8248495223467764,\n",
       " 'pred_class': 0,\n",
       " 'pred_value': -0.8248495223467764,\n",
       " 'agree_sign_delta': True,\n",
       " 'forest_pred_class': 1,\n",
       " 'forest_pred_probas': array([0.43380721, 0.56619279]),\n",
       " 'forest_pred_lodds': array([-0.26633441,  0.26633441]),\n",
       " 'prior_probas': array([0.30285714, 0.69714286]),\n",
       " 'prior_lodds': [-0.8337291311811347, 0.8337291311811347],\n",
       " 'delta_lodds': array([ 0.56739472, -0.56739472])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [(fw['agree_'],fw['pred_value']) for fw in f_walker.path_detail[0]]\n",
    "\n",
    "f_walker.path_detail[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CHIRPS on a batch of 10 instances... (please wait)\n",
      "Working on CHIRPS for instance 0 of 10\n",
      "986\n",
      "as_chirps for batch_idx 0\n",
      "start mining for batch_idx 0 with support = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1480: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1485: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 86 patterns from 986 for batch_idx 0\n",
      "start score sort for batch_idx 0 (86) patterns\n",
      "start merge rule for batch_idx 0 (86) patterns\n",
      "[('chk_A11', False, 0.5), ('dur', False, 24.96226), ('amt', True, 12678.70833)]\n",
      "0.6388888888888888 0.04738077896945491 0.13408829616553425 0.10372010630388394\n",
      "merge complete for batch_idx 0 (86) patterns\n",
      "start get explainer for batch_idx 0\n",
      "843\n",
      "as_chirps for batch_idx 1\n",
      "start mining for batch_idx 1 with support = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1485: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1480: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 80 patterns from 843 for batch_idx 1\n",
      "start score sort for batch_idx 1 (80) patterns\n",
      "start merge rule for batch_idx 1 (80) patterns\n",
      "[('emp_A72', True, 0.5), ('dur', True, 16.8125), ('crhis_A31', True, 0.5)]\n",
      "0.9123505976095617 0.3096433076572103 0.10493482830048168 0.10256009643360395\n",
      "merge complete for batch_idx 1 (80) patterns\n",
      "start get explainer for batch_idx 1\n",
      "841\n",
      "as_chirps for batch_idx 2\n",
      "start mining for batch_idx 2 with support = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1480: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1485: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 85 patterns from 841 for batch_idx 2\n",
      "start score sort for batch_idx 2 (85) patterns\n",
      "start merge rule for batch_idx 2 (85) patterns\n",
      "[('emp_A72', False, 0.5), ('dur', False, 21.16667), ('chk_A14', True, 0.5)]\n",
      "0.7878787878787878 0.04368917998648517 0.15104472544221706 0.11798959678503987\n",
      "merge complete for batch_idx 2 (85) patterns\n",
      "start get explainer for batch_idx 2\n",
      "1000\n",
      "as_chirps for batch_idx 3\n",
      "start mining for batch_idx 3 with support = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1485: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1480: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 83 patterns from 1000 for batch_idx 3\n",
      "start score sort for batch_idx 3 (83) patterns\n",
      "start merge rule for batch_idx 3 (83) patterns\n",
      "[('chk_A14', False, 0.5), ('dur', True, 27.71)]\n",
      "0.9752066115702479 0.33280549665852543 0.1362978668437506 0.1194027493119541\n",
      "merge complete for batch_idx 3 (83) patterns\n",
      "start get explainer for batch_idx 3\n",
      "1052\n",
      "as_chirps for batch_idx 4\n",
      "start mining for batch_idx 4 with support = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1480: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1485: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 85 patterns from 1052 for batch_idx 4\n",
      "start score sort for batch_idx 4 (85) patterns\n",
      "start merge rule for batch_idx 4 (85) patterns\n",
      "[('debt_A103', False, 0.5)]\n",
      "0.8823529411764706 0.044946634817538494 0.05725816681789224 0.036681411993035574\n",
      "merge complete for batch_idx 4 (85) patterns\n",
      "start get explainer for batch_idx 4\n",
      "Working on CHIRPS for instance 5 of 10\n",
      "908\n",
      "as_chirps for batch_idx 5\n",
      "start mining for batch_idx 5 with support = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1480: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1485: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 85 patterns from 908 for batch_idx 5\n",
      "start score sort for batch_idx 5 (85) patterns\n",
      "start merge rule for batch_idx 5 (85) patterns\n",
      "[('chk_A13', False, 0.5)]\n",
      "0.9464285714285714 0.0763305510078102 0.10152542810545029 0.07071430678211617\n",
      "merge complete for batch_idx 5 (85) patterns\n",
      "start get explainer for batch_idx 5\n",
      "806\n",
      "as_chirps for batch_idx 6\n",
      "start mining for batch_idx 6 with support = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1480: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1485: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 86 patterns from 806 for batch_idx 6\n",
      "start score sort for batch_idx 6 (86) patterns\n",
      "start merge rule for batch_idx 6 (86) patterns\n",
      "[('chk_A13', False, 0.5)]\n",
      "0.9464285714285714 0.0763305510078102 0.0702665728475835 0.045986214633868094\n",
      "merge complete for batch_idx 6 (86) patterns\n",
      "start get explainer for batch_idx 6\n",
      "842\n",
      "as_chirps for batch_idx 7\n",
      "start mining for batch_idx 7 with support = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1480: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1485: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 83 patterns from 842 for batch_idx 7\n",
      "start score sort for batch_idx 7 (83) patterns\n",
      "start merge rule for batch_idx 7 (83) patterns\n",
      "[('chk_A11', False, 0.5), ('age', True, 25.5051), ('crhis_A31', True, 0.5)]\n",
      "0.6666666666666666 0.055636919145042506 0.13161877521030513 0.10751581265496427\n",
      "merge complete for batch_idx 7 (83) patterns\n",
      "start get explainer for batch_idx 7\n",
      "909\n",
      "as_chirps for batch_idx 8\n",
      "start mining for batch_idx 8 with support = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1485: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1480: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 85 patterns from 909 for batch_idx 8\n",
      "start score sort for batch_idx 8 (85) patterns\n",
      "start merge rule for batch_idx 8 (85) patterns\n",
      "[('crhis_A34', False, 0.5), ('dur', True, 17.70833)]\n",
      "0.96875 0.1328716999024844 0.12629672902206818 0.10465424217368141\n",
      "merge complete for batch_idx 8 (85) patterns\n",
      "start get explainer for batch_idx 8\n",
      "929\n",
      "as_chirps for batch_idx 9\n",
      "start mining for batch_idx 9 with support = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1485: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n",
      "C:\\Users\\id126493\\Documents\\GitHub\\explain_te\\CHIRPS\\structures.py:1480: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 85 patterns from 929 for batch_idx 9\n",
      "start score sort for batch_idx 9 (85) patterns\n",
      "start merge rule for batch_idx 9 (85) patterns\n",
      "[('prop_A121', False, 0.5), ('chk_A11', True, 0.5)]\n",
      "0.9634146341463414 0.22464371024450466 0.1369091915720354 0.10474270201812098\n",
      "merge complete for batch_idx 9 (85) patterns\n",
      "start get explainer for batch_idx 9\n",
      "CHIRPS time elapsed: 18.5348 seconds\n",
      "CHIRPS with async = False\n"
     ]
    }
   ],
   "source": [
    "# get what the model predicts on the training sample\n",
    "sample_labels = rf.predict(tt.X_train_enc)\n",
    "\n",
    "# build CHIRPS and a rule for each instance represented in the path detail\n",
    "CHIRPS = strcts.GBHIPS_container(f_walker.path_detail,\n",
    "                                forest=rf,\n",
    "                                sample_instances=tt.X_train_enc, # any representative sample can be used\n",
    "                                # sample_labels=tt.y_train,  # any representative sample can be used\n",
    "                                sample_labels=sample_labels,\n",
    "                                meta_data=meta_data)\n",
    "\n",
    "print('Running CHIRPS on a batch of ' + str(len(labels)) + ' instances... (please wait)')\n",
    "# start a timer\n",
    "ce_start_time = timeit.default_timer()\n",
    "\n",
    "CHIRPS.batch_run_CHIRPS(target_classes=preds, # we're explaining the prediction, not the true label!\n",
    "                        chirps_explanation_async=chirps_explanation_async,\n",
    "                        random_state=random_state,\n",
    "                        paths_lengths_threshold=5,\n",
    "                        which_trees='signdelta',\n",
    "                        alpha_paths=0.0,\n",
    "                        support_paths=0.1,\n",
    "                        score_func=1,\n",
    "                        precis_threshold=0.99,\n",
    "                        disc_path_bins=4,\n",
    "                        merging_bootstraps=20,\n",
    "                        pruning_bootstraps=20,\n",
    "                        delta=0.09,\n",
    "                        weighting='kldiv')\n",
    "\n",
    "ce_end_time = timeit.default_timer()\n",
    "ce_elapsed_time = ce_end_time - ce_start_time\n",
    "print('CHIRPS time elapsed:', \"{:0.4f}\".format(ce_elapsed_time), 'seconds')\n",
    "print('CHIRPS with async = ' + str(chirps_explanation_async))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing and Evaluating CHIRPS explanations\n",
    "Evaluation is done using unseen data to see how well the explanations generalise. The data_split_container object (tt) has a  leave-one-out function that is used during the routine to ensure that the datum we are explaining is excluded from the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating found explanations\n",
      "\n",
      "INSTANCE RESULTS\n",
      "['instance id: 131 with true class label: 0 (bad)']\n",
      "\n",
      "Model Results for Instance\n",
      "['target (predicted) class: 0 (bad)']\n",
      "target class prior (training data): 0.22714285714285715\n",
      "forest vote share (unseen instance): 0.7484751194163434\n",
      "forest vote margin (unseen instance): 0.496950238832685\n",
      "confidence weighted forest vote share (unseen instance): 0.7484751194163434\n",
      "confidence weighted forest vote margin (unseen instance): 0.496950238832685\n",
      "\n",
      "rule: chk_A11 True AND dur > 24.96226 AND amt <= 12678.70833\n",
      "rule cardinality: 3\n",
      "Fraction of total points of rule: 0.13408829616553425\n",
      "Fraction of total weight of rule: 0.10372010630388394\n",
      "\n",
      "Estimated Results - Rule Training Sample. Algorithm: greedy_stab\n",
      "rule coverage (training data): 0.04850213980028531\n",
      "rule xcoverage (training data): 0.04836415362731152\n",
      "rule precision (training data): 0.6666666666666666\n",
      "rule stability (training data): 0.6388888888888888\n",
      "rule recall (training data): 0.13836477987421383\n",
      "rule f1 score (training data): 0.22916666666666669\n",
      "rule NPV (training data): 0.9796672828096118\n",
      "rule lift (training data): 62.2577981068547\n",
      "prior (training data): [0.22714286 0.77285714]\n",
      "prior counts (training data): [159. 541.]\n",
      "rule posterior (training data): [0.66666667 0.33333333]\n",
      "rule posterior counts (training data): [22. 11.]\n",
      "rule chisq p-value (training data): 3.48300400043968e-08\n",
      "rule Kullback-Leibler divergence (training data): 0.437490299887923\n",
      "\n",
      "Results - Previously Unseen Sample\n",
      "target class prior (unseen data): 0.705685618729097\n",
      "rule coverage (unseen data): 0.09666666666666666\n",
      "rule xcoverage (unseen data): 0.09602649006622517\n",
      "rule precision (unseen data): 0.6785714285714286\n",
      "rule stability (unseen data): 0.6451612903225806\n",
      "rule recall (unseen data): 0.2159090909090909\n",
      "rule f1 score (unseen data): 0.3275862068965517\n",
      "rule NPV (unseen data): 0.957345971563981\n",
      "rule lift (unseen data): 24.620521219851575\n",
      "prior (unseen data): [0.70568562 0.29431438]\n",
      "prior counts (unseen data): [ 88. 211.]\n",
      "rule posterior (unseen data): [0.67857143 0.32142857]\n",
      "rule posterior counts (unseen data): [19.  9.]\n",
      "rule chisq p-value (unseen data): 8.379738198806447e-05\n",
      "rule Kullback-Leibler divergence (unseen data): 0.3140689907976774\n",
      "Evaluation Time: 2.0152640999999676\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A11 False AND dur > 24.96226 AND amt <= 12678.70833\n",
      "rule coverage (training data): 0.14407988587731813\n",
      "rule xcoverage (training data): 0.14366998577524892\n",
      "rule precision (training data): 0.41\n",
      "rule stability (training data): 0.4077669902912621\n",
      "rule recall (training data): 0.19339622641509435\n",
      "rule f1 score (training data): 0.26282051282051283\n",
      "rule NPV (training data): 0.8790983606557377\n",
      "rule lift (training data): 9.476415094339622\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.41 0.59]\n",
      "rule posterior counts (training data): [41. 59.]\n",
      "rule chisq p-value (training data): 0.041317476596299085\n",
      "rule Kullback-Leibler divergence from original: 0.16789544350123614\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [299.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [289.  10.]\n",
      "proba: [0.96655518 0.03344482]\n",
      "\n",
      "Feature Reversed: dur_greater_than_lower_bound\n",
      "rule: chk_A11 True AND dur <= 24.96226 AND amt <= 12678.70833\n",
      "rule coverage (training data): 0.20399429386590584\n",
      "rule xcoverage (training data): 0.2034139402560455\n",
      "rule precision (training data): 0.45774647887323944\n",
      "rule stability (training data): 0.45517241379310347\n",
      "rule recall (training data): 0.30660377358490565\n",
      "rule f1 score (training data): 0.3672316384180791\n",
      "rule NPV (training data): 0.8422131147540983\n",
      "rule lift (training data): 7.45069673956575\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.45774648 0.54225352]\n",
      "rule posterior counts (training data): [65. 77.]\n",
      "rule chisq p-value (training data): 0.0004941656349498242\n",
      "rule Kullback-Leibler divergence from original: 0.11669084806744812\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [299.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [282.  17.]\n",
      "proba: [0.94314381 0.05685619]\n",
      "\n",
      "Feature Reversed: amt_less_than_upper_bound\n",
      "rule: chk_A11 True AND dur > 24.96226 AND amt > 12678.70833\n",
      "rule coverage (training data): 0.0042796005706134095\n",
      "rule xcoverage (training data): 0.004267425320056899\n",
      "rule precision (training data): 0.0\n",
      "rule stability (training data): 0.2\n",
      "rule recall (training data): 0.0\n",
      "rule f1 score (training data): 0.0\n",
      "rule NPV (training data): 0.9959016393442623\n",
      "rule lift (training data): 0.0\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0. 1.]\n",
      "rule posterior counts (training data): [0. 2.]\n",
      "rule chisq p-value (training data): 0.8725784799745128\n",
      "rule Kullback-Leibler divergence from original: 11.204043508609763\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [299.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [199. 100.]\n",
      "proba: [0.66555184 0.33444816]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "['instance id: 203 with true class label: 0 (bad)']\n",
      "\n",
      "Model Results for Instance\n",
      "['target (predicted) class: 1 (good)']\n",
      "target class prior (training data): 0.7728571428571429\n",
      "forest vote share (unseen instance): 0.45042716528031235\n",
      "forest vote margin (unseen instance): -0.09914566943937575\n",
      "confidence weighted forest vote share (unseen instance): 0.45042716528031235\n",
      "confidence weighted forest vote margin (unseen instance): -0.09914566943937575\n",
      "\n",
      "rule: emp_A72 False AND dur <= 16.8125 AND crhis_A31 False\n",
      "rule cardinality: 3\n",
      "Fraction of total points of rule: 0.10493482830048168\n",
      "Fraction of total weight of rule: 0.10256009643360395\n",
      "\n",
      "Estimated Results - Rule Training Sample. Algorithm: greedy_stab\n",
      "rule coverage (training data): 0.2582025677603424\n",
      "rule xcoverage (training data): 0.2574679943100996\n",
      "rule precision (training data): 0.9555555555555556\n",
      "rule stability (training data): 0.9453551912568307\n",
      "rule recall (training data): 0.3179297597042514\n",
      "rule f1 score (training data): 0.4771151178918169\n",
      "rule NPV (training data): 0.949685534591195\n",
      "rule lift (training data): 4.808196983181579\n",
      "prior (training data): [0.22714286 0.77285714]\n",
      "prior counts (training data): [159. 541.]\n",
      "rule posterior (training data): [0.04444444 0.95555556]\n",
      "rule posterior counts (training data): [  8. 172.]\n",
      "rule chisq p-value (training data): 4.535769795336651e-08\n",
      "rule Kullback-Leibler divergence (training data): 0.1302635746226114\n",
      "\n",
      "Results - Previously Unseen Sample\n",
      "target class prior (unseen data): 0.2976588628762542\n",
      "rule coverage (unseen data): 0.31666666666666665\n",
      "rule xcoverage (unseen data): 0.31456953642384106\n",
      "rule precision (unseen data): 0.8297872340425532\n",
      "rule stability (unseen data): 0.8144329896907216\n",
      "rule recall (unseen data): 0.37142857142857144\n",
      "rule f1 score (unseen data): 0.5131578947368421\n",
      "rule NPV (unseen data): 0.8202247191011236\n",
      "rule lift (unseen data): 3.758045010670633\n",
      "prior (unseen data): [0.70234114 0.29765886]\n",
      "prior counts (unseen data): [ 89. 210.]\n",
      "rule posterior (unseen data): [0.17021277 0.82978723]\n",
      "rule posterior counts (unseen data): [16. 78.]\n",
      "rule chisq p-value (unseen data): 0.021328190340815345\n",
      "rule Kullback-Leibler divergence (unseen data): 0.0432353649789652\n",
      "Evaluation Time: 2.2385629000000336\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: emp\n",
      "rule: emp_A72 True AND dur <= 16.8125 AND crhis_A31 False\n",
      "rule coverage (training data): 0.07275320970042796\n",
      "rule xcoverage (training data): 0.07254623044096728\n",
      "rule precision (training data): 0.74\n",
      "rule stability (training data): 0.7169811320754716\n",
      "rule recall (training data): 0.07581967213114754\n",
      "rule f1 score (training data): 0.137546468401487\n",
      "rule NPV (training data): 0.9386792452830188\n",
      "rule lift (training data): 14.860655737704917\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.26 0.74]\n",
      "rule posterior counts (training data): [13. 37.]\n",
      "rule chisq p-value (training data): 0.6318266406614919\n",
      "rule Kullback-Leibler divergence from original: 0.043437122520569055\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [299.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [146. 153.]\n",
      "proba: [0.48829431 0.51170569]\n",
      "\n",
      "Feature Reversed: dur_less_than_upper_bound\n",
      "rule: emp_A72 False AND dur > 16.8125 AND crhis_A31 False\n",
      "rule coverage (training data): 0.42938659058487877\n",
      "rule xcoverage (training data): 0.42816500711237554\n",
      "rule precision (training data): 0.6566666666666666\n",
      "rule stability (training data): 0.6534653465346535\n",
      "rule recall (training data): 0.4036885245901639\n",
      "rule f1 score (training data): 0.5\n",
      "rule NPV (training data): 0.5141509433962265\n",
      "rule lift (training data): 2.1978597449908928\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.34333333 0.65666667]\n",
      "rule posterior counts (training data): [103. 197.]\n",
      "rule chisq p-value (training data): 0.23465739378504405\n",
      "rule Kullback-Leibler divergence from original: 0.10770319604417664\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [299.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [270.  29.]\n",
      "proba: [0.90301003 0.09698997]\n",
      "\n",
      "Feature Reversed: crhis\n",
      "rule: emp_A72 False AND dur <= 16.8125 AND crhis_A31 True\n",
      "rule coverage (training data): 0.019971469329529243\n",
      "rule xcoverage (training data): 0.01991465149359886\n",
      "rule precision (training data): 0.46153846153846156\n",
      "rule stability (training data): 0.4375\n",
      "rule recall (training data): 0.012295081967213115\n",
      "rule f1 score (training data): 0.023952095808383235\n",
      "rule NPV (training data): 0.9669811320754716\n",
      "rule lift (training data): 35.64846250848773\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.53846154 0.46153846]\n",
      "rule posterior counts (training data): [7. 6.]\n",
      "rule chisq p-value (training data): 0.12821117512416386\n",
      "rule Kullback-Leibler divergence from original: 0.34883863959317046\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [299.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [299.   0.]\n",
      "proba: [1. 0.]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE RESULTS\n",
      "['instance id: 50 with true class label: 1 (good)']\n",
      "\n",
      "Model Results for Instance\n",
      "['target (predicted) class: 0 (bad)']\n",
      "target class prior (training data): 0.22714285714285715\n",
      "forest vote share (unseen instance): 0.6044054441630025\n",
      "forest vote margin (unseen instance): 0.20881088832600447\n",
      "confidence weighted forest vote share (unseen instance): 0.6044054441630025\n",
      "confidence weighted forest vote margin (unseen instance): 0.20881088832600447\n",
      "\n",
      "rule: emp_A72 True AND dur > 21.16667 AND chk_A14 False\n",
      "rule cardinality: 3\n",
      "Fraction of total points of rule: 0.15104472544221706\n",
      "Fraction of total weight of rule: 0.11798959678503987\n",
      "\n",
      "Estimated Results - Rule Training Sample. Algorithm: greedy_stab\n",
      "rule coverage (training data): 0.0442225392296719\n",
      "rule xcoverage (training data): 0.044096728307254626\n",
      "rule precision (training data): 0.8333333333333334\n",
      "rule stability (training data): 0.7878787878787878\n",
      "rule recall (training data): 0.15723270440251572\n",
      "rule f1 score (training data): 0.2645502645502646\n",
      "rule NPV (training data): 0.9907578558225508\n",
      "rule lift (training data): 85.60447239692523\n",
      "prior (training data): [0.22714286 0.77285714]\n",
      "prior counts (training data): [159. 541.]\n",
      "rule posterior (training data): [0.83333333 0.16666667]\n",
      "rule posterior counts (training data): [25.  5.]\n",
      "rule chisq p-value (training data): 3.504112847270732e-13\n",
      "rule Kullback-Leibler divergence (training data): 0.8275288410818928\n",
      "\n",
      "Results - Previously Unseen Sample\n",
      "target class prior (unseen data): 0.705685618729097\n",
      "rule coverage (unseen data): 0.06666666666666667\n",
      "rule xcoverage (unseen data): 0.06622516556291391\n",
      "rule precision (unseen data): 0.7368421052631579\n",
      "rule stability (unseen data): 0.6818181818181818\n",
      "rule recall (unseen data): 0.1590909090909091\n",
      "rule f1 score (unseen data): 0.2616822429906542\n",
      "rule NPV (unseen data): 0.976303317535545\n",
      "rule lift (unseen data): 39.398577184588255\n",
      "prior (unseen data): [0.70568562 0.29431438]\n",
      "prior counts (unseen data): [ 88. 211.]\n",
      "rule posterior (unseen data): [0.73684211 0.26315789]\n",
      "rule posterior counts (unseen data): [14.  5.]\n",
      "rule chisq p-value (unseen data): 0.00017420999735959594\n",
      "rule Kullback-Leibler divergence (unseen data): 0.41663526808442924\n",
      "Evaluation Time: 2.0001702000000705\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: emp\n",
      "rule: emp_A72 False AND dur > 21.16667 AND chk_A14 False\n",
      "rule coverage (training data): 0.19686162624821682\n",
      "rule xcoverage (training data): 0.19630156472261737\n",
      "rule precision (training data): 0.5109489051094891\n",
      "rule stability (training data): 0.5071428571428571\n",
      "rule recall (training data): 0.330188679245283\n",
      "rule f1 score (training data): 0.40114613180515757\n",
      "rule NPV (training data): 0.8627049180327869\n",
      "rule lift (training data): 8.620195685981603\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.51094891 0.48905109]\n",
      "rule posterior counts (training data): [70. 67.]\n",
      "rule chisq p-value (training data): 3.955224235321802e-06\n",
      "rule Kullback-Leibler divergence from original: 0.04957234734231444\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [120. 179.]\n",
      "proba: [0.40133779 0.59866221]\n",
      "\n",
      "Feature Reversed: dur_greater_than_lower_bound\n",
      "rule: emp_A72 True AND dur <= 21.16667 AND chk_A14 False\n",
      "rule coverage (training data): 0.07417974322396577\n",
      "rule xcoverage (training data): 0.07396870554765292\n",
      "rule precision (training data): 0.45098039215686275\n",
      "rule stability (training data): 0.4444444444444444\n",
      "rule recall (training data): 0.10849056603773585\n",
      "rule f1 score (training data): 0.17490494296577946\n",
      "rule NPV (training data): 0.9426229508196722\n",
      "rule lift (training data): 20.438438046324706\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.45098039 0.54901961]\n",
      "rule posterior counts (training data): [23. 28.]\n",
      "rule chisq p-value (training data): 0.040745241651466396\n",
      "rule Kullback-Leibler divergence from original: 0.09424714961709996\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [ 13. 286.]\n",
      "proba: [0.04347826 0.95652174]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [ 43. 256.]\n",
      "proba: [0.14381271 0.85618729]\n",
      "\n",
      "Feature Reversed: chk\n",
      "rule: emp_A72 True AND dur > 21.16667 AND chk_A14 True\n",
      "rule coverage (training data): 0.018544935805991442\n",
      "rule xcoverage (training data): 0.01849217638691323\n",
      "rule precision (training data): 0.4166666666666667\n",
      "rule stability (training data): 0.4\n",
      "rule recall (training data): 0.02358490566037736\n",
      "rule f1 score (training data): 0.04464285714285715\n",
      "rule NPV (training data): 0.985655737704918\n",
      "rule lift (training data): 80.2541928721174\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.41666667 0.58333333]\n",
      "rule posterior counts (training data): [5. 7.]\n",
      "rule chisq p-value (training data): 0.5940404372657628\n",
      "rule Kullback-Leibler divergence from original: 0.12679714397157085\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "['instance id: 584 with true class label: 1 (good)']\n",
      "\n",
      "Model Results for Instance\n",
      "['target (predicted) class: 1 (good)']\n",
      "target class prior (training data): 0.7728571428571429\n",
      "forest vote share (unseen instance): 0.6937908910888455\n",
      "forest vote margin (unseen instance): 0.3875817821776912\n",
      "confidence weighted forest vote share (unseen instance): 0.6937908910888455\n",
      "confidence weighted forest vote margin (unseen instance): 0.3875817821776912\n",
      "\n",
      "rule: chk_A14 True AND dur <= 27.71\n",
      "rule cardinality: 2\n",
      "Fraction of total points of rule: 0.1362978668437506\n",
      "Fraction of total weight of rule: 0.1194027493119541\n",
      "\n",
      "Estimated Results - Rule Training Sample. Algorithm: greedy_stab\n",
      "rule coverage (training data): 0.289586305278174\n",
      "rule xcoverage (training data): 0.2887624466571835\n",
      "rule precision (training data): 0.995049504950495\n",
      "rule stability (training data): 0.9853658536585366\n",
      "rule recall (training data): 0.37153419593345655\n",
      "rule f1 score (training data): 0.5410497981157469\n",
      "rule NPV (training data): 0.9937106918238994\n",
      "rule lift (training data): 4.461615430041018\n",
      "prior (training data): [0.22714286 0.77285714]\n",
      "prior counts (training data): [159. 541.]\n",
      "rule posterior (training data): [0.0049505 0.9950495]\n",
      "rule posterior counts (training data): [  1. 201.]\n",
      "rule chisq p-value (training data): 7.063347706198069e-13\n",
      "rule Kullback-Leibler divergence (training data): 0.2325058136841003\n",
      "\n",
      "Results - Previously Unseen Sample\n",
      "target class prior (unseen data): 0.2976588628762542\n",
      "rule coverage (unseen data): 0.27666666666666667\n",
      "rule xcoverage (unseen data): 0.27483443708609273\n",
      "rule precision (unseen data): 1.0\n",
      "rule stability (unseen data): 0.9764705882352941\n",
      "rule recall (unseen data): 0.3904761904761905\n",
      "rule f1 score (unseen data): 0.5616438356164384\n",
      "rule NPV (unseen data): 1.0\n",
      "rule lift (unseen data): 5.191695702671313\n",
      "prior (unseen data): [0.70234114 0.29765886]\n",
      "prior counts (unseen data): [ 89. 210.]\n",
      "rule posterior (unseen data): [0. 1.]\n",
      "rule posterior counts (unseen data): [ 0. 82.]\n",
      "rule chisq p-value (unseen data): 3.8839990193208056e-08\n",
      "rule Kullback-Leibler divergence (unseen data): 0.35333540007819425\n",
      "Evaluation Time: 2.0495687999999745\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A14 False AND dur <= 27.71\n",
      "rule coverage (training data): 0.47503566333808844\n",
      "rule xcoverage (training data): 0.47368421052631576\n",
      "rule precision (training data): 0.6295180722891566\n",
      "rule stability (training data): 0.6268656716417911\n",
      "rule recall (training data): 0.42827868852459017\n",
      "rule f1 score (training data): 0.5097560975609755\n",
      "rule NPV (training data): 0.419811320754717\n",
      "rule lift (training data): 1.903909832496091\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.37048193 0.62951807]\n",
      "rule posterior counts (training data): [123. 209.]\n",
      "rule chisq p-value (training data): 0.036067078508179855\n",
      "rule Kullback-Leibler divergence from original: 0.22796208214250357\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "Feature Reversed: dur_less_than_upper_bound\n",
      "rule: chk_A14 True AND dur > 27.71\n",
      "rule coverage (training data): 0.06704707560627675\n",
      "rule xcoverage (training data): 0.06685633001422475\n",
      "rule precision (training data): 0.717391304347826\n",
      "rule stability (training data): 0.6938775510204082\n",
      "rule recall (training data): 0.06762295081967214\n",
      "rule f1 score (training data): 0.12359550561797754\n",
      "rule NPV (training data): 0.9386792452830188\n",
      "rule lift (training data): 15.65937897052899\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.2826087 0.7173913]\n",
      "rule posterior counts (training data): [13. 33.]\n",
      "rule chisq p-value (training data): 0.901289528210379\n",
      "rule Kullback-Leibler divergence from original: 0.12909008659369367\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "['instance id: 138 with true class label: 1 (good)']\n",
      "\n",
      "Model Results for Instance\n",
      "['target (predicted) class: 1 (good)']\n",
      "target class prior (training data): 0.7728571428571429\n",
      "forest vote share (unseen instance): 0.7078455045604447\n",
      "forest vote margin (unseen instance): 0.41569100912089124\n",
      "confidence weighted forest vote share (unseen instance): 0.7078455045604447\n",
      "confidence weighted forest vote margin (unseen instance): 0.41569100912089124\n",
      "\n",
      "rule: debt_A103 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.05725816681789224\n",
      "Fraction of total weight of rule: 0.036681411993035574\n",
      "\n",
      "Estimated Results - Rule Training Sample. Algorithm: greedy_stab\n",
      "rule coverage (training data): 0.0456490727532097\n",
      "rule xcoverage (training data): 0.04551920341394026\n",
      "rule precision (training data): 0.9354838709677419\n",
      "rule stability (training data): 0.8823529411764706\n",
      "rule recall (training data): 0.053604436229205174\n",
      "rule f1 score (training data): 0.10139860139860139\n",
      "rule NPV (training data): 0.9874213836477987\n",
      "rule lift (training data): 27.33212669335123\n",
      "prior (training data): [0.22714286 0.77285714]\n",
      "prior counts (training data): [159. 541.]\n",
      "rule posterior (training data): [0.06451613 0.93548387]\n",
      "rule posterior counts (training data): [ 2. 29.]\n",
      "rule chisq p-value (training data): 0.055280458355662344\n",
      "rule Kullback-Leibler divergence (training data): 0.09744489000291512\n",
      "\n",
      "Results - Previously Unseen Sample\n",
      "target class prior (unseen data): 0.2976588628762542\n",
      "rule coverage (unseen data): 0.07\n",
      "rule xcoverage (unseen data): 0.0695364238410596\n",
      "rule precision (unseen data): 0.9\n",
      "rule stability (unseen data): 0.8260869565217391\n",
      "rule recall (unseen data): 0.08571428571428572\n",
      "rule f1 score (unseen data): 0.1565217391304348\n",
      "rule NPV (unseen data): 0.9775280898876404\n",
      "rule lift (unseen data): 19.157357142857144\n",
      "prior (unseen data): [0.70234114 0.29765886]\n",
      "prior counts (unseen data): [ 89. 210.]\n",
      "rule posterior (unseen data): [0.1 0.9]\n",
      "rule posterior counts (unseen data): [ 2. 18.]\n",
      "rule chisq p-value (unseen data): 0.10110247338486272\n",
      "rule Kullback-Leibler divergence (unseen data): 0.1141000802406772\n",
      "Evaluation Time: 0.9991216000000804\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: debt\n",
      "rule: debt_A103 False\n",
      "rule coverage (training data): 0.9557774607703281\n",
      "rule xcoverage (training data): 0.9530583214793741\n",
      "rule precision (training data): 0.6905829596412556\n",
      "rule stability (training data): 0.6889880952380952\n",
      "rule recall (training data): 0.9467213114754098\n",
      "rule f1 score (training data): 0.7986171132238548\n",
      "rule NPV (training data): 0.02358490566037736\n",
      "rule lift (training data): 1.0364921041443529\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.30941704 0.69058296]\n",
      "rule posterior counts (training data): [207. 462.]\n",
      "rule chisq p-value (training data): 0.8378814963234229\n",
      "rule Kullback-Leibler divergence from original: 0.05790708723904725\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "['instance id: 834 with true class label: 0 (bad)']\n",
      "\n",
      "Model Results for Instance\n",
      "['target (predicted) class: 1 (good)']\n",
      "target class prior (training data): 0.7728571428571429\n",
      "forest vote share (unseen instance): 0.5977681734036446\n",
      "forest vote margin (unseen instance): 0.19553634680728876\n",
      "confidence weighted forest vote share (unseen instance): 0.5977681734036446\n",
      "confidence weighted forest vote margin (unseen instance): 0.19553634680728876\n",
      "\n",
      "rule: chk_A13 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.10152542810545029\n",
      "Fraction of total weight of rule: 0.07071430678211617\n",
      "\n",
      "Estimated Results - Rule Training Sample. Algorithm: greedy_stab\n",
      "rule coverage (training data): 0.07703281027104136\n",
      "rule xcoverage (training data): 0.07681365576102418\n",
      "rule precision (training data): 0.9811320754716981\n",
      "rule stability (training data): 0.9464285714285714\n",
      "rule recall (training data): 0.09611829944547134\n",
      "rule f1 score (training data): 0.17508417508417504\n",
      "rule NPV (training data): 0.9937106918238994\n",
      "rule lift (training data): 16.766809088031668\n",
      "prior (training data): [0.22714286 0.77285714]\n",
      "prior counts (training data): [159. 541.]\n",
      "rule posterior (training data): [0.01886792 0.98113208]\n",
      "rule posterior counts (training data): [ 1. 52.]\n",
      "rule chisq p-value (training data): 0.0006746082443635705\n",
      "rule Kullback-Leibler divergence (training data): 0.1871650093479036\n",
      "\n",
      "Results - Previously Unseen Sample\n",
      "target class prior (unseen data): 0.2976588628762542\n",
      "rule coverage (unseen data): 0.03333333333333333\n",
      "rule xcoverage (unseen data): 0.033112582781456956\n",
      "rule precision (unseen data): 1.0\n",
      "rule stability (unseen data): 0.8333333333333334\n",
      "rule recall (unseen data): 0.04285714285714286\n",
      "rule f1 score (unseen data): 0.0821917808219178\n",
      "rule NPV (unseen data): 1.0\n",
      "rule lift (unseen data): 47.3021164021164\n",
      "prior (unseen data): [0.70234114 0.29765886]\n",
      "prior counts (unseen data): [ 89. 210.]\n",
      "rule posterior (unseen data): [0. 1.]\n",
      "rule posterior counts (unseen data): [0. 9.]\n",
      "rule chisq p-value (unseen data): 0.11691511567067776\n",
      "rule Kullback-Leibler divergence (unseen data): 0.353334226291432\n",
      "Evaluation Time: 1.5620785999999498\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A13 False\n",
      "rule coverage (training data): 0.9243937232524965\n",
      "rule xcoverage (training data): 0.9217638691322901\n",
      "rule precision (training data): 0.6908809891808346\n",
      "rule stability (training data): 0.6892307692307692\n",
      "rule recall (training data): 0.9159836065573771\n",
      "rule f1 score (training data): 0.7876651982378855\n",
      "rule NPV (training data): 0.05660377358490566\n",
      "rule lift (training data): 1.07219856050184\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.30911901 0.69088099]\n",
      "rule posterior counts (training data): [200. 447.]\n",
      "rule chisq p-value (training data): 0.8492985920392707\n",
      "rule Kullback-Leibler divergence from original: 0.016971803310329714\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "['instance id: 328 with true class label: 1 (good)']\n",
      "\n",
      "Model Results for Instance\n",
      "['target (predicted) class: 1 (good)']\n",
      "target class prior (training data): 0.7728571428571429\n",
      "forest vote share (unseen instance): 0.43707792493830966\n",
      "forest vote margin (unseen instance): -0.12584415012338146\n",
      "confidence weighted forest vote share (unseen instance): 0.43707792493830966\n",
      "confidence weighted forest vote margin (unseen instance): -0.12584415012338146\n",
      "\n",
      "rule: chk_A13 True\n",
      "rule cardinality: 1\n",
      "Fraction of total points of rule: 0.0702665728475835\n",
      "Fraction of total weight of rule: 0.045986214633868094\n",
      "\n",
      "Estimated Results - Rule Training Sample. Algorithm: greedy_stab\n",
      "rule coverage (training data): 0.07703281027104136\n",
      "rule xcoverage (training data): 0.07681365576102418\n",
      "rule precision (training data): 0.9811320754716981\n",
      "rule stability (training data): 0.9464285714285714\n",
      "rule recall (training data): 0.09611829944547134\n",
      "rule f1 score (training data): 0.17508417508417504\n",
      "rule NPV (training data): 0.9937106918238994\n",
      "rule lift (training data): 16.766809088031668\n",
      "prior (training data): [0.22714286 0.77285714]\n",
      "prior counts (training data): [159. 541.]\n",
      "rule posterior (training data): [0.01886792 0.98113208]\n",
      "rule posterior counts (training data): [ 1. 52.]\n",
      "rule chisq p-value (training data): 0.0006746082443635705\n",
      "rule Kullback-Leibler divergence (training data): 0.1871650093479036\n",
      "\n",
      "Results - Previously Unseen Sample\n",
      "target class prior (unseen data): 0.2976588628762542\n",
      "rule coverage (unseen data): 0.03333333333333333\n",
      "rule xcoverage (unseen data): 0.033112582781456956\n",
      "rule precision (unseen data): 1.0\n",
      "rule stability (unseen data): 0.8333333333333334\n",
      "rule recall (unseen data): 0.04285714285714286\n",
      "rule f1 score (unseen data): 0.0821917808219178\n",
      "rule NPV (unseen data): 1.0\n",
      "rule lift (unseen data): 47.3021164021164\n",
      "prior (unseen data): [0.70234114 0.29765886]\n",
      "prior counts (unseen data): [ 89. 210.]\n",
      "rule posterior (unseen data): [0. 1.]\n",
      "rule posterior counts (unseen data): [0. 9.]\n",
      "rule chisq p-value (unseen data): 0.11691511567067776\n",
      "rule Kullback-Leibler divergence (unseen data): 0.3533344965481276\n",
      "Evaluation Time: 1.5384774000000334\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A13 False\n",
      "rule coverage (training data): 0.9243937232524965\n",
      "rule xcoverage (training data): 0.9217638691322901\n",
      "rule precision (training data): 0.6908809891808346\n",
      "rule stability (training data): 0.6892307692307692\n",
      "rule recall (training data): 0.9159836065573771\n",
      "rule f1 score (training data): 0.7876651982378855\n",
      "rule NPV (training data): 0.05660377358490566\n",
      "rule lift (training data): 1.07219856050184\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.30911901 0.69088099]\n",
      "rule posterior counts (training data): [200. 447.]\n",
      "rule chisq p-value (training data): 0.8492985920392707\n",
      "rule Kullback-Leibler divergence from original: 0.016971801921228838\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [205.  94.]\n",
      "proba: [0.68561873 0.31438127]\n",
      "['allowed values. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [205.  94.]\n",
      "proba: [0.68561873 0.31438127]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE RESULTS\n",
      "['instance id: 655 with true class label: 1 (good)']\n",
      "\n",
      "Model Results for Instance\n",
      "['target (predicted) class: 0 (bad)']\n",
      "target class prior (training data): 0.22714285714285715\n",
      "forest vote share (unseen instance): 0.6187544693954266\n",
      "forest vote margin (unseen instance): 0.2375089387908525\n",
      "confidence weighted forest vote share (unseen instance): 0.6187544693954266\n",
      "confidence weighted forest vote margin (unseen instance): 0.2375089387908525\n",
      "\n",
      "rule: chk_A11 True AND age <= 25.5051 AND crhis_A31 False\n",
      "rule cardinality: 3\n",
      "Fraction of total points of rule: 0.13161877521030513\n",
      "Fraction of total weight of rule: 0.10751581265496427\n",
      "\n",
      "Estimated Results - Rule Training Sample. Algorithm: greedy_stab\n",
      "rule coverage (training data): 0.05706134094151213\n",
      "rule xcoverage (training data): 0.05689900426742532\n",
      "rule precision (training data): 0.6923076923076923\n",
      "rule stability (training data): 0.6666666666666666\n",
      "rule recall (training data): 0.16981132075471697\n",
      "rule f1 score (training data): 0.27272727272727276\n",
      "rule NPV (training data): 0.977818853974122\n",
      "rule lift (training data): 54.70581667969186\n",
      "prior (training data): [0.22714286 0.77285714]\n",
      "prior counts (training data): [159. 541.]\n",
      "rule posterior (training data): [0.69230769 0.30769231]\n",
      "rule posterior counts (training data): [27. 12.]\n",
      "rule chisq p-value (training data): 2.5307038864593746e-10\n",
      "rule Kullback-Leibler divergence (training data): 0.48816042347581967\n",
      "\n",
      "Results - Previously Unseen Sample\n",
      "target class prior (unseen data): 0.705685618729097\n",
      "rule coverage (unseen data): 0.08\n",
      "rule xcoverage (unseen data): 0.07947019867549669\n",
      "rule precision (unseen data): 0.6521739130434783\n",
      "rule stability (unseen data): 0.6153846153846154\n",
      "rule recall (unseen data): 0.17045454545454544\n",
      "rule f1 score (unseen data): 0.2702702702702703\n",
      "rule NPV (unseen data): 0.9620853080568721\n",
      "rule lift (unseen data): 28.80681818181818\n",
      "prior (unseen data): [0.70568562 0.29431438]\n",
      "prior counts (unseen data): [ 88. 211.]\n",
      "rule posterior (unseen data): [0.65217391 0.34782609]\n",
      "rule posterior counts (unseen data): [15.  8.]\n",
      "rule chisq p-value (unseen data): 0.0009206419983908208\n",
      "rule Kullback-Leibler divergence (unseen data): 0.27283490773758123\n",
      "Evaluation Time: 2.023020900000006\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: chk\n",
      "rule: chk_A11 False AND age <= 25.5051 AND crhis_A31 False\n",
      "rule coverage (training data): 0.12268188302425106\n",
      "rule xcoverage (training data): 0.12233285917496443\n",
      "rule precision (training data): 0.3411764705882353\n",
      "rule stability (training data): 0.3409090909090909\n",
      "rule recall (training data): 0.13679245283018868\n",
      "rule f1 score (training data): 0.19528619528619526\n",
      "rule NPV (training data): 0.8852459016393442\n",
      "rule lift (training data): 9.277273617549127\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.34117647 0.65882353]\n",
      "rule posterior counts (training data): [29. 56.]\n",
      "rule chisq p-value (training data): 0.5493305904750596\n",
      "rule Kullback-Leibler divergence from original: 0.18630445743777535\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [156. 143.]\n",
      "proba: [0.52173913 0.47826087]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [ 95. 204.]\n",
      "proba: [0.31772575 0.68227425]\n",
      "\n",
      "Feature Reversed: age_less_than_upper_bound\n",
      "rule: chk_A11 True AND age > 25.5051 AND crhis_A31 False\n",
      "rule coverage (training data): 0.1754636233951498\n",
      "rule xcoverage (training data): 0.17496443812233287\n",
      "rule precision (training data): 0.4262295081967213\n",
      "rule stability (training data): 0.424\n",
      "rule recall (training data): 0.24528301886792453\n",
      "rule f1 score (training data): 0.31137724550898205\n",
      "rule NPV (training data): 0.8565573770491803\n",
      "rule lift (training data): 8.075025480064701\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.42622951 0.57377049]\n",
      "rule posterior counts (training data): [52. 70.]\n",
      "rule chisq p-value (training data): 0.009650380441058584\n",
      "rule Kullback-Leibler divergence from original: 0.09324583686163138\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [ 10. 289.]\n",
      "proba: [0.03344482 0.96655518]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [ 16. 283.]\n",
      "proba: [0.05351171 0.94648829]\n",
      "\n",
      "Feature Reversed: crhis\n",
      "rule: chk_A11 True AND age <= 25.5051 AND crhis_A31 True\n",
      "rule coverage (training data): 0.007132667617689016\n",
      "rule xcoverage (training data): 0.007112375533428165\n",
      "rule precision (training data): 0.25\n",
      "rule stability (training data): 0.2857142857142857\n",
      "rule recall (training data): 0.0047169811320754715\n",
      "rule f1 score (training data): 0.009259259259259259\n",
      "rule NPV (training data): 0.9938524590163934\n",
      "rule lift (training data): 144.4575471698113\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.25 0.75]\n",
      "rule posterior counts (training data): [1. 3.]\n",
      "rule chisq p-value (training data): 0.7517705319188606\n",
      "rule Kullback-Leibler divergence from original: 0.33909477706976343\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [299.   0.]\n",
      "proba: [1. 0.]\n",
      "['allowed values. expected class: 0 (bad)']\n",
      "classes: [0, 1]\n",
      "counts: [299.   0.]\n",
      "proba: [1. 0.]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "['instance id: 581 with true class label: 1 (good)']\n",
      "\n",
      "Model Results for Instance\n",
      "['target (predicted) class: 1 (good)']\n",
      "target class prior (training data): 0.7728571428571429\n",
      "forest vote share (unseen instance): 0.5364933764330403\n",
      "forest vote margin (unseen instance): 0.0729867528660802\n",
      "confidence weighted forest vote share (unseen instance): 0.5364933764330403\n",
      "confidence weighted forest vote margin (unseen instance): 0.0729867528660802\n",
      "\n",
      "rule: crhis_A34 True AND dur <= 17.70833\n",
      "rule cardinality: 2\n",
      "Fraction of total points of rule: 0.12629672902206818\n",
      "Fraction of total weight of rule: 0.10465424217368141\n",
      "\n",
      "Estimated Results - Rule Training Sample. Algorithm: greedy_stab\n",
      "rule coverage (training data): 0.1340941512125535\n",
      "rule xcoverage (training data): 0.1337126600284495\n",
      "rule precision (training data): 0.989247311827957\n",
      "rule stability (training data): 0.96875\n",
      "rule recall (training data): 0.17005545286506468\n",
      "rule f1 score (training data): 0.2902208201892744\n",
      "rule NPV (training data): 0.9937106918238994\n",
      "rule lift (training data): 9.634312857426487\n",
      "prior (training data): [0.22714286 0.77285714]\n",
      "prior counts (training data): [159. 541.]\n",
      "rule posterior (training data): [0.01075269 0.98924731]\n",
      "rule posterior counts (training data): [ 1. 92.]\n",
      "rule chisq p-value (training data): 2.0551740486393677e-06\n",
      "rule Kullback-Leibler divergence (training data): 0.21139544149966888\n",
      "\n",
      "Results - Previously Unseen Sample\n",
      "target class prior (unseen data): 0.2976588628762542\n",
      "rule coverage (unseen data): 0.15\n",
      "rule xcoverage (unseen data): 0.1490066225165563\n",
      "rule precision (unseen data): 0.9772727272727273\n",
      "rule stability (unseen data): 0.9361702127659575\n",
      "rule recall (unseen data): 0.20476190476190476\n",
      "rule f1 score (unseen data): 0.33858267716535434\n",
      "rule NPV (unseen data): 0.9887640449438202\n",
      "rule lift (unseen data): 9.455536698150334\n",
      "prior (unseen data): [0.70234114 0.29765886]\n",
      "prior counts (unseen data): [ 89. 210.]\n",
      "rule posterior (unseen data): [0.02272727 0.97727273]\n",
      "rule posterior counts (unseen data): [ 1. 43.]\n",
      "rule chisq p-value (unseen data): 0.00022704408342518782\n",
      "rule Kullback-Leibler divergence (unseen data): 0.2643753461672264\n",
      "Evaluation Time: 1.8435829999999669\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: crhis\n",
      "rule: crhis_A34 False AND dur <= 17.70833\n",
      "rule coverage (training data): 0.3166904422253923\n",
      "rule xcoverage (training data): 0.3157894736842105\n",
      "rule precision (training data): 0.746606334841629\n",
      "rule stability (training data): 0.7410714285714286\n",
      "rule recall (training data): 0.33811475409836067\n",
      "rule f1 score (training data): 0.4654442877291961\n",
      "rule NPV (training data): 0.7358490566037735\n",
      "rule lift (training data): 3.3921547369668255\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.25339367 0.74660633]\n",
      "rule posterior counts (training data): [ 56. 165.]\n",
      "rule chisq p-value (training data): 0.18470153401039355\n",
      "rule Kullback-Leibler divergence from original: 0.1064928686952035\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [ 11. 288.]\n",
      "proba: [0.0367893 0.9632107]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "Feature Reversed: dur_less_than_upper_bound\n",
      "rule: crhis_A34 True AND dur > 17.70833\n",
      "rule coverage (training data): 0.15691868758915833\n",
      "rule xcoverage (training data): 0.15647226173541964\n",
      "rule precision (training data): 0.7247706422018348\n",
      "rule stability (training data): 0.7142857142857143\n",
      "rule recall (training data): 0.16188524590163936\n",
      "rule f1 score (training data): 0.2646566164154104\n",
      "rule NPV (training data): 0.8584905660377359\n",
      "rule lift (training data): 6.676523061341913\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.27522936 0.72477064]\n",
      "rule posterior counts (training data): [30. 79.]\n",
      "rule chisq p-value (training data): 0.6358293333296091\n",
      "rule Kullback-Leibler divergence from original: 0.12771972293657535\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [ 35. 264.]\n",
      "proba: [0.11705686 0.88294314]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [ 35. 264.]\n",
      "proba: [0.11705686 0.88294314]\n",
      "\n",
      "INSTANCE RESULTS\n",
      "['instance id: 478 with true class label: 1 (good)']\n",
      "\n",
      "Model Results for Instance\n",
      "['target (predicted) class: 1 (good)']\n",
      "target class prior (training data): 0.7728571428571429\n",
      "forest vote share (unseen instance): 0.5935836171394796\n",
      "forest vote margin (unseen instance): 0.18716723427895865\n",
      "confidence weighted forest vote share (unseen instance): 0.5935836171394796\n",
      "confidence weighted forest vote margin (unseen instance): 0.18716723427895865\n",
      "\n",
      "rule: prop_A121 True AND chk_A11 False\n",
      "rule cardinality: 2\n",
      "Fraction of total points of rule: 0.1369091915720354\n",
      "Fraction of total weight of rule: 0.10474270201812098\n",
      "\n",
      "Estimated Results - Rule Training Sample. Algorithm: greedy_stab\n",
      "rule coverage (training data): 0.1398002853067047\n",
      "rule xcoverage (training data): 0.13940256045519203\n",
      "rule precision (training data): 1.0\n",
      "rule stability (training data): 0.98\n",
      "rule recall (training data): 0.17929759704251386\n",
      "rule f1 score (training data): 0.30407523510971785\n",
      "rule NPV (training data): 1.0\n",
      "rule lift (training data): 9.337424014330088\n",
      "prior (training data): [0.22714286 0.77285714]\n",
      "prior counts (training data): [159. 541.]\n",
      "rule posterior (training data): [0. 1.]\n",
      "rule posterior counts (training data): [ 0. 97.]\n",
      "rule chisq p-value (training data): 3.2086712966496586e-07\n",
      "rule Kullback-Leibler divergence (training data): 0.25765958533948674\n",
      "\n",
      "Results - Previously Unseen Sample\n",
      "target class prior (unseen data): 0.2976588628762542\n",
      "rule coverage (unseen data): 0.17\n",
      "rule xcoverage (unseen data): 0.16887417218543047\n",
      "rule precision (unseen data): 0.96\n",
      "rule stability (unseen data): 0.9245283018867925\n",
      "rule recall (unseen data): 0.22857142857142856\n",
      "rule f1 score (unseen data): 0.3692307692307692\n",
      "rule NPV (unseen data): 0.9775280898876404\n",
      "rule lift (unseen data): 8.173805714285715\n",
      "prior (unseen data): [0.70234114 0.29765886]\n",
      "prior counts (unseen data): [ 89. 210.]\n",
      "rule posterior (unseen data): [0.04 0.96]\n",
      "rule posterior counts (unseen data): [ 2. 48.]\n",
      "rule chisq p-value (unseen data): 0.00024538574519947866\n",
      "rule Kullback-Leibler divergence (unseen data): 0.2197305625942371\n",
      "Evaluation Time: 2.213937099999953\n",
      "\n",
      "COUNTER FACTUAL RESULTS\n",
      "Feature Reversed: prop\n",
      "rule: prop_A121 False AND chk_A11 False\n",
      "rule coverage (training data): 0.5178316690442225\n",
      "rule xcoverage (training data): 0.5163584637268848\n",
      "rule precision (training data): 0.7320441988950276\n",
      "rule stability (training data): 0.7287671232876712\n",
      "rule recall (training data): 0.5430327868852459\n",
      "rule f1 score (training data): 0.6235294117647059\n",
      "rule NPV (training data): 0.5424528301886793\n",
      "rule lift (training data): 2.0305093371216576\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.2679558 0.7320442]\n",
      "rule posterior counts (training data): [ 97. 265.]\n",
      "rule chisq p-value (training data): 0.2645587407761658\n",
      "rule Kullback-Leibler divergence from original: 0.11003145332532807\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "Feature Reversed: chk\n",
      "rule: prop_A121 True AND chk_A11 True\n",
      "rule coverage (training data): 0.06990014265335236\n",
      "rule xcoverage (training data): 0.06970128022759602\n",
      "rule precision (training data): 0.6041666666666666\n",
      "rule stability (training data): 0.5882352941176471\n",
      "rule recall (training data): 0.05942622950819672\n",
      "rule f1 score (training data): 0.10820895522388058\n",
      "rule NPV (training data): 0.910377358490566\n",
      "rule lift (training data): 12.638390824225862\n",
      "prior (training data): [0.30285714 0.69714286]\n",
      "prior counts (training data): [212. 488.]\n",
      "rule posterior (training data): [0.39583333 0.60416667]\n",
      "rule posterior counts (training data): [19. 29.]\n",
      "rule chisq p-value (training data): 0.23510701766611725\n",
      "rule Kullback-Leibler divergence from original: 0.25400870084164806\n",
      "predictions for this rule complement\n",
      "['instance specific. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "['allowed values. expected class: 1 (good)']\n",
      "classes: [0, 1]\n",
      "counts: [  0. 299.]\n",
      "proba: [0. 1.]\n",
      "\n",
      "CHIRPS batch results eval time elapsed: 0.6299 seconds\n"
     ]
    }
   ],
   "source": [
    "# iterate over all the test instances to determine the various scores using leave-one-out testing\n",
    "print('evaluating found explanations')\n",
    "print()\n",
    "results_start_time = timeit.default_timer()\n",
    "\n",
    "save_results_file = model + '_CHIRPS_rnst_' + str(random_state)\n",
    "\n",
    "rt.evaluate_explainers(CHIRPS, tt, labels.index, # for full batch runs: tt.y_test.index,\n",
    "                              forest=rf,\n",
    "                              meta_data=meta_data,\n",
    "                              model=model,\n",
    "                              eval_start_time=results_start_time,\n",
    "                              print_to_screen=True, # set True when running single instances\n",
    "                              eval_alt_labelings=True,\n",
    "                              eval_rule_complements=True,\n",
    "                              save_results_path=save_path,\n",
    "                              dataset_name='test',\n",
    "                              save_results_file=save_results_file,\n",
    "                              save_CHIRPS=False)\n",
    "\n",
    "results_end_time = timeit.default_timer()\n",
    "results_elapsed_time = results_end_time - results_start_time\n",
    "print('CHIRPS batch results eval time elapsed:', \"{:0.4f}\".format(results_elapsed_time), 'seconds')\n",
    "# this completes the CHIRPS runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
