{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up notebook and load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for notebook plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# load what we need\n",
    "import time\n",
    "import timeit\n",
    "import CHIRPS.structures as strcts\n",
    "import CHIRPS.datasets as ds\n",
    "import CHIRPS.datasets_proprietary as dsp\n",
    "import CHIRPS.routines as rt\n",
    "\n",
    "# demo datasets that ship with package. all from UCI unless stated otherwise\n",
    "# import CHIRPS.datasets as ds\n",
    "# ds.adult_data, ds.adult_samp_data, ds.adult_small_samp_data Large dataset ships with manageable sub samples\n",
    "# ds.bankmark_data, ds.bankmark_samp_data\n",
    "# ds.car_data\n",
    "# ds.cardio_data this is the cardiotocography dataset\n",
    "# ds.credit_data\n",
    "# ds.german_data\n",
    "# ds.lending_data, ds.lending_samp_data, ds.lending_small_samp_data, ds.lending_tiny_samp_data from Kaggle. see datasets_from_source file for links\n",
    "# ds.nursery_data, ds.nursery_samp_data\n",
    "# ds.rcdv_data, ds.rcdv_samp_data from US government see datasets_from_source file for links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common config - can be ommitted if defaults are OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/datadisk/whiteboxing/examples'\n",
    "# project_dir = 'V:\\\\whiteboxing\\\\examples' # defaults to a directory \"whiteboxing\" in the working directory\n",
    "# project_dir = 'C:\\\\Users\\\\Crutt\\\\Documents\\\\whiteboxing\\\\exampada'\n",
    "\n",
    "random_state_splits = 123 # one off for splitting the data into test / train\n",
    "random_state = 123 # for everything else - e.g. building a new rf with same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Random Forest Model to Predict and Explain\n",
    "First, a wrapper is created for the dataset. Use one that ships with the package, or create your own.\n",
    "Then split the data into training and (hold out) test set using the convenience functions in the package. These return an object that contain the split data in various representations, such as Pandas DataFrames and encoded, sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one of the included datasets\n",
    "# project_dir will default to directory name CHIRPS in the working directory if not given\n",
    "# random_state will default to 123\n",
    "#mydata = dsp.usoc2(random_state=random_state_splits, project_dir=project_dir)\n",
    "\n",
    "# class imbalance\n",
    "#import pandas_ml\n",
    "#meta_data['get_label'](meta_data['class_col'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New grid tuning... (please wait)\n",
      "Finding best params with 10-fold CV\n",
      "0.648 (+/-0.088) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 200}\n",
      "0.654 (+/-0.087) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 400}\n",
      "0.653 (+/-0.083) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 600}\n",
      "0.656 (+/-0.064) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 800}\n",
      "0.656 (+/-0.057) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1000}\n",
      "0.654 (+/-0.061) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1200}\n",
      "0.654 (+/-0.061) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1400}\n",
      "0.655 (+/-0.073) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1600}\n",
      "0.642 (+/-0.097) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 200}\n",
      "0.653 (+/-0.094) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 400}\n",
      "0.651 (+/-0.089) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 600}\n",
      "0.644 (+/-0.088) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 800}\n",
      "0.641 (+/-0.095) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1000}\n",
      "0.639 (+/-0.091) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1200}\n",
      "0.639 (+/-0.094) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1400}\n",
      "0.636 (+/-0.103) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1600}\n",
      "0.632 (+/-0.072) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 200}\n",
      "0.623 (+/-0.082) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 400}\n",
      "0.619 (+/-0.088) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 600}\n",
      "0.619 (+/-0.084) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 800}\n",
      "0.621 (+/-0.071) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1000}\n",
      "0.630 (+/-0.071) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1200}\n",
      "0.625 (+/-0.074) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1400}\n",
      "0.628 (+/-0.068) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1600}\n",
      "0.626 (+/-0.077) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 200}\n",
      "0.616 (+/-0.106) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 400}\n",
      "0.622 (+/-0.097) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 600}\n",
      "0.620 (+/-0.079) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 800}\n",
      "0.616 (+/-0.088) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1000}\n",
      "0.611 (+/-0.094) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1200}\n",
      "0.615 (+/-0.075) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1400}\n",
      "0.613 (+/-0.087) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 1600}\n",
      "CV time: 441.3123404200014\n",
      "\n",
      "{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 800, 'score': 0.6558245083207261}\n",
      "Tuning time elapsed: 441.3138seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best OOB Accuracy Estimate during tuning: 0.6558\n",
      "Best parameters:{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'n_estimators': 800, 'random_state': 123}\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[291  59]\n",
      " [160  56]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.83 0.17]\n",
      " [0.74 0.26]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load one of the included datasets\n",
    "# project_dir will default to directory name CHIRPS in the working directory if not given\n",
    "# random_state will default to 123\n",
    "#mydata = dsp.usoc2(random_state=random_state_splits, project_dir=project_dir)\n",
    "mydata = ds.rcdv_samp(random_state=random_state_splits, project_dir=project_dir)\n",
    "\n",
    "meta_data = mydata.get_meta()\n",
    "save_path = meta_data['get_save_path']()\n",
    "\n",
    "# split the data. here using a basic sampling method.\n",
    "# the returned object is a wrapper class that contains\n",
    "# the train and test splits for X and y\n",
    "\n",
    "# also the the encoded versions of X_train and X_test that the rf will use\n",
    "# this is because we prefer onehot encoded over allowing categorical vars to be represented as integer\n",
    "# scikit would treat these as ordinal, which is inappropriate\n",
    "\n",
    "# also some meta-data: priors for y, the indexes from the input data\n",
    "\n",
    "# also some convenience functions for leave-one-out testing\n",
    "\n",
    "# train test split - one off hard-coded random state.\n",
    "# random state can be ommitted \n",
    "# and will default to the state held in the dataset container\n",
    "# which defaults to 123 if ommitted in the constructor\n",
    "train_index, test_index = mydata.get_tt_split_idx(random_state=random_state_splits)\n",
    "# optionally, indexes can be ommitted and will default to scikit's train_test_split method\n",
    "tt = mydata.tt_split(train_index, test_index)\n",
    "\n",
    "# build model, tuned for high accuracy\n",
    "# model = 'RandomForest'\n",
    "model = 'AdaBoost1'\n",
    "# model = 'AdaBoost2'\n",
    "# model = 'GBM'\n",
    "\n",
    "# decide if to run the whole tuning routine again (long for Adaboost)\n",
    "# RF routine has a default tuning grid, so can leave as None, or come up with some other options\n",
    "tuning = {'grid' : None, 'override' : False}\n",
    "if model == 'RandomForest':\n",
    "    tuning.update({'grid' : None}) # defaults to n_trees [200, 400, ..., 1600]\n",
    "\n",
    "elif model in ('AdaBoost1', 'AdaBoost2'):\n",
    "    if model == 'AdaBoost1':\n",
    "        # classic (and multi-class) AdaBoost\n",
    "        algo = 'SAMME'\n",
    "    else:\n",
    "        algo = 'SAMME.R'\n",
    "    max_depth = [i for i in range(1, 5)]\n",
    "    tuning.update({'grid' : {'base_estimator' : [rt.DecisionTreeClassifier(max_depth=d) for d in max_depth],\n",
    "                            'n_estimators': [(i + 1) * 200 for i in range(8)], 'algorithm': [algo]}})\n",
    "    \n",
    "else: # GBM - not fully implemented yet\n",
    "    stop # ValueError\n",
    "\n",
    "rf = rt.forest_prep(ds_container=tt,\n",
    "                    meta_data=meta_data,\n",
    "                    # override_tuning=True,\n",
    "                    model=model,\n",
    "                    tuning_grid=tuning['grid'],\n",
    "                    save_path=save_path,\n",
    "                    plot_cm=True, plot_cm_norm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing unseen data\n",
    "\n",
    "Again note:\n",
    "test set has never been \"seen\" by random forest during training\n",
    "test set has been only used to assess model (random forest) accuracy - no additional tuning after this\n",
    "test set has not be involved in generating the explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optional: memory and computation cost management\n",
    "#### CHIRPS is time economical but memory intensive to compute for lots of instances at once\n",
    "option 1: choose a smaller number of instances to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control for async processes - each tree walk can be done in its own core\n",
    "# and so can each explanation (e.g. rule conditions merge by hill-climbing)\n",
    "# these will default to false if not passed explicitly to the explainer function\n",
    "# on a multi-core machine there should be a good speed up for large batches\n",
    "# when the batch_size advantage exceeds the overhead of setting up multi-processing\n",
    "# timings will be printed to screen so you can see if it helps\n",
    "forest_walk_async=True\n",
    "chirps_explanation_async=True\n",
    "\n",
    "# how many instances to explain in total from a test/unseen set\n",
    "# doesn't matter if you don't know how large the dataset is\n",
    "# this function prevents you maxing out, or put n_instances = None for whole dataset\n",
    "n_instances = rt.n_instance_ceiling(ds_container=tt, n_instances=1)\n",
    "\n",
    "# this gets the next batch out of the data_split_container according to the required number of instances\n",
    "# all formats can be extracted, depending on the requirement\n",
    "# unencoded, encoded (sparse matrix is the type returned by scikit), ordinary dense matrix also available\n",
    "# tt.current_row_test = 0\n",
    "instances, _, instances_enc, instances_enc_matrix, labels = tt.get_next(n_instances, which_split='test') # default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 2: just run the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances = tt.X_test; instances_enc = tt.X_test_enc; instances_enc_matrix = tt.X_test_enc_matrix; labels = tt.y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions from the decision forest on the unseen data\n",
    "Important point, no compromise on model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the model predictions for the test instance(s) we're looking at\n",
    "preds_idx = labels.index\n",
    "preds = rf.predict(X=instances_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIRPS Step 1:\n",
    "## Extract Tree Prediction Paths\n",
    "### Fit a forest_walker object to the dataset and decision forest\n",
    "This is a wrapper will extracts the paths of all the given instances. For CHIRPS, we want a large sample. The whole training set or other representative sample will do.\n",
    "\n",
    "It can also report interesting statistics (treating the forest as a set of random tree-structured variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper object needs the decision forest itself and the dataset meta data (we have a convenience function for this)\n",
    "f_walker = strcts.forest_walker(forest = rf, meta_data=meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the work of extracting all the paths for each instance is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walking forest for 1 instances... (please wait)\n",
      "Forest Walk with async = True\n",
      "Forest Walk time elapsed: 0.2616 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Walking forest for ' + str(len(labels)) + ' instances... (please wait)')\n",
    "\n",
    "# set the timer\n",
    "forest_walk_start_time = timeit.default_timer()\n",
    "\n",
    "# do the walk - creates a paths_container (even for just one instance) as a new property\n",
    "# requires the X instances in a matrix (dense, ordinary numpy matrix) - this is available in the data_split_container\n",
    "f_walker.forest_walk(instances = instances_enc_matrix\n",
    "                    , labels = preds # we're explaining the prediction, not the true label!\n",
    "                    , forest_walk_async = forest_walk_async)\n",
    "\n",
    "# stop the timer\n",
    "forest_walk_end_time = timeit.default_timer()\n",
    "forest_walk_elapsed_time = forest_walk_end_time - forest_walk_start_time\n",
    "\n",
    "print('Forest Walk with async = ' + str(forest_walk_async))\n",
    "print('Forest Walk time elapsed:', \"{:0.4f}\".format(forest_walk_elapsed_time), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIRPS Steps 2-4: \n",
    "## Freqent pattern mining of paths.\n",
    "## Score and sort mined path segments.\n",
    "## Merge path segments into one rule.\n",
    "\n",
    "This is a wrapper object that will execute steps 2-4 on all the instance-paths in the batch_paths_container.\n",
    "\n",
    "Note that true_divide warnings are OK. It just means that a continuous variable is unbounded in some way i.e. no greater/less than discontinuity is used in the CHIRPS explanation.\n",
    "\n",
    "Note also, here we are using the training set to create the explainers. We could use a different dataset as long as it is representative of the training set that built the decision forest. Most important that we don't use the dataset that we wish to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CHIRPS on a batch of 1 instances... (please wait)\n",
      "Working on CHIRPS for instance 0 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1338: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(uppers, upper_bins)[0]).round(5) # can result in nans if no value falls into bin\n",
      "/home/julianhatwell/Documents/github/explain_te/CHIRPS/structures.py:1343: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.histogram(lowers, lower_bins)[0]).round(5) # can result in nans\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-14fe23a86a51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0mpruning_bootstraps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                         weighting='chisq')\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mce_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/explain_te/CHIRPS/structures.py\u001b[0m in \u001b[0;36mbatch_run_CHIRPS\u001b[0;34m(self, target_classes, chirps_explanation_async, random_state, **kwargs)\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'disc_path_bins'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'disc_path_eqcounts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_func'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weighting'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'algorithm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'merging_bootstraps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pruning_bootstraps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2068\u001b[0;31m                     options['delta'], options['precis_threshold'], i)\n\u001b[0m\u001b[1;32m   2069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m                 \u001b[0;31m# add the finished rule accumulator to the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/explain_te/CHIRPS/async_structures.py\u001b[0m in \u001b[0;36mas_CHIRPS\u001b[0;34m(c_runner, sample_instances, sample_labels, forest, forest_walk_mean_elapsed_time, paths_lengths_threshold, support_paths, alpha_paths, disc_path_bins, disc_path_eqcounts, score_func, weighting, algorithm, merging_bootstraps, pruning_bootstraps, delta, precis_threshold, batch_idx)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mpruning_bootstraps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpruning_bootstraps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 precis_threshold=precis_threshold)\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mcr_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/explain_te/CHIRPS/structures.py\u001b[0m in \u001b[0;36mmerge_rule\u001b[0;34m(self, forest, sample_instances, sample_labels, precis_threshold, fixed_length, target_class, algorithm, merging_bootstraps, pruning_bootstraps, bootstrap_confidence, delta, random_state)\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m                     b_eval_rule = self.evaluate_rule(rule=candidate, sample_instances=b_sample_instances,\n\u001b[0;32m-> 1758\u001b[0;31m                                                 sample_labels=b_sample_labels)\n\u001b[0m\u001b[1;32m   1759\u001b[0m                     \u001b[0mb_curr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_eval_rule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_rule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/explain_te/CHIRPS/structures.py\u001b[0m in \u001b[0;36mevaluate_rule\u001b[0;34m(self, rule, features, class_names, sample_instances, sample_labels, target_class)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         \u001b[0;31m# collect metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/explain_te/CHIRPS/structures.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, prior_labels, post_idx, class_names)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m#     rfhc.append((cc - ic) / (cc + ic) + cc / (ic + 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mchisq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchisq_indep_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# p-value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0mkl_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropy_corrected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p_counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/explain_te/CHIRPS/__init__.py\u001b[0m in \u001b[0;36mchisq_indep_test\u001b[0;34m(counts, prior_counts)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mobserved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# previous_counts.sum() == 0 is impossible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mchisq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchi2_contingency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "chirps_explanation_async=False\n",
    "# get what the model predicts on the training sample\n",
    "sample_labels = rf.predict(tt.X_train_enc)\n",
    "\n",
    "# build CHIRPS and a rule for each instance represented in the path detail\n",
    "CHIRPS = strcts.CHIRPS_container(f_walker.path_detail,\n",
    "                                forest=rf,\n",
    "                                sample_instances=tt.X_train_enc, # any representative sample can be used\n",
    "                                # sample_labels=tt.y_train,  # any representative sample can be used\n",
    "                                sample_labels=sample_labels,\n",
    "                                meta_data=meta_data)\n",
    "\n",
    "print('Running CHIRPS on a batch of ' + str(len(labels)) + ' instances... (please wait)')\n",
    "# start a timer\n",
    "ce_start_time = timeit.default_timer()\n",
    "\n",
    "CHIRPS.batch_run_CHIRPS(target_classes=preds, # we're explaining the prediction, not the true label!\n",
    "                        chirps_explanation_async=chirps_explanation_async,\n",
    "                        random_state=random_state,\n",
    "                        unweighted_trees=False,\n",
    "                        alpha_paths=0.0,\n",
    "                        support_paths=0.01,\n",
    "                        score_func=1,\n",
    "                        disc_path_bins=4,\n",
    "                        merging_bootstraps=20,\n",
    "                        pruning_bootstraps=20,\n",
    "                        delta=0.1,\n",
    "                        weighting='chisq')\n",
    "\n",
    "ce_end_time = timeit.default_timer()\n",
    "ce_elapsed_time = ce_end_time - ce_start_time\n",
    "print('CHIRPS time elapsed:', \"{:0.4f}\".format(ce_elapsed_time), 'seconds')\n",
    "print('CHIRPS with async = ' + str(chirps_explanation_async))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing and Evaluating CHIRPS explanations\n",
    "Evaluation is done using unseen data to see how well the explanations generalise. The data_split_container object (tt) has a  leave-one-out function that is used during the routine to ensure that the datum we are explaining is excluded from the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# iterate over all the test instances to determine the various scores using leave-one-out testing\n",
    "print('evaluating found explanations')\n",
    "print()\n",
    "results_start_time = timeit.default_timer()\n",
    "\n",
    "save_results_file = model + '_CHIRPS_rnst_' + str(random_state)\n",
    "\n",
    "rt.evaluate_CHIRPS_explainers(CHIRPS, tt, labels.index, # for full batch runs: tt.y_test.index,\n",
    "                              forest=rf,\n",
    "                              meta_data=meta_data,\n",
    "                              model=model,\n",
    "                              eval_start_time=results_start_time,\n",
    "                              print_to_screen=True, # set True when running single instances\n",
    "                              eval_alt_labelings=True,\n",
    "                              eval_rule_complements=True,\n",
    "                              save_results_path=save_path,\n",
    "                              dataset_name='test',\n",
    "                              save_results_file=save_results_file,\n",
    "                              save_CHIRPS=False)\n",
    "\n",
    "results_end_time = timeit.default_timer()\n",
    "results_elapsed_time = results_end_time - results_start_time\n",
    "print('CHIRPS batch results eval time elapsed:', \"{:0.4f}\".format(results_elapsed_time), 'seconds')\n",
    "# this completes the CHIRPS runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
